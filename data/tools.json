[
  {
    "tool_id": "upload1",
    "name": "Upload File",
    "description": "from your computer",
    "categories": [
      "Get Data"
    ],
    "version": "1.1.7",
    "help": "**Auto-detect** The system will attempt to detect Axt, Fasta, Fastqsolexa, Gff, Gff3, Html, Lav, Maf, Tabular, Wiggle, Bed and Interval (Bed with headers) formats. If your file is not detected properly as one of the known formats, it most likely means that it has some format problems (e.g., different number of columns on different rows). You can still coerce the system to set your data to the format you think it should be. You can also upload compressed files, which will automatically be decompressed. ----- **Ab1** A binary sequence file in 'ab1' format with a '.ab1' file extension. You must manually select this 'File Format' when uploading the file. ----- **Axt** blastz pairwise alignment format. Each alignment block in an axt file contains three lines: a summary line and 2 sequence lines. Blocks are separated from one another by blank lines. The summary line contains chromosomal position and size information about the alignment. It consists of 9 required fields. ----- **Bam** A binary file compressed in the BGZF format with a '.bam' file extension. ----- **Bed** * Tab delimited format (tabular) * Does not require header line * Contains 3 required fields: - chrom - The name of the chromosome (e.g. chr3, chrY, chr2_random) or contig (e.g. ctgY1). - chromStart - The starting position of the feature in the chromosome or contig. The first base in a chromosome is numbered 0. - chromEnd - The ending position of the feature in the chromosome or contig. The chromEnd base is not included in the display of the feature. For example, the first 100 bases of a chromosome are defined as chromStart=0, chromEnd=100, and span the bases numbered 0-99. * May contain 9 additional optional BED fields: - name - Defines the name of the BED line. This label is displayed to the left of the BED line in the Genome Browser window when the track is open to full display mode or directly to the left of the item in pack mode. - score - A score between 0 and 1000. If the track line useScore attribute is set to 1 for this annotation data set, the score value will determine the level of gray in which this feature is displayed (higher numbers = darker gray). - strand - Defines the strand - either '+' or '-'. - thickStart - The starting position at which the feature is drawn thickly (for example, the start codon in gene displays). - thickEnd - The ending position at which the feature is drawn thickly (for example, the stop codon in gene displays). - itemRgb - An RGB value of the form R,G,B (e.g. 255,0,0). If the track line itemRgb attribute is set to \"On\", this RBG value will determine the display color of the data contained in this BED line. NOTE: It is recommended that a simple color scheme (eight colors or less) be used with this attribute to avoid overwhelming the color resources of the Genome Browser and your Internet browser. - blockCount - The number of blocks (exons) in the BED line. - blockSizes - A comma-separated list of the block sizes. The number of items in this list should correspond to blockCount. - blockStarts - A comma-separated list of block starts. All of the blockStart positions should be calculated relative to chromStart. The number of items in this list should correspond to blockCount. * Example:: chr22 1000 5000 cloneA 960 + 1000 5000 0 2 567,488, 0,3512 chr22 2000 6000 cloneB 900 - 2000 6000 0 2 433,399, 0,3601 ----- **Fasta** A sequence in FASTA format consists of a single-line description, followed by lines of sequence data. The first character of the description line is a greater-than (\">\") symbol in the first column. All lines should be shorter than 80 characters:: >sequence1 atgcgtttgcgtgc gtcggtttcgttgc >sequence2 tttcgtgcgtatag tggcgcggtga ----- **FastqSolexa** FastqSolexa is the Illumina (Solexa) variant of the Fastq format, which stores sequences and quality scores in a single file:: @seq1 GACAGCTTGGTTTTTAGTGAGTTGTTCCTTTCTTT +seq1 hhhhhhhhhhhhhhhhhhhhhhhhhhPW@hhhhhh @seq2 GCAATGACGGCAGCAATAAACTCAACAGGTGCTGG +seq2 hhhhhhhhhhhhhhYhhahhhhWhAhFhSIJGChO Or:: @seq1 GAATTGATCAGGACATAGGACAACTGTAGGCACCAT +seq1 40 40 40 40 35 40 40 40 25 40 40 26 40 9 33 11 40 35 17 40 40 33 40 7 9 15 3 22 15 30 11 17 9 4 9 4 @seq2 GAGTTCTCGTCGCCTGTAGGCACCATCAATCGTATG +seq2 40 15 40 17 6 36 40 40 40 25 40 9 35 33 40 14 14 18 15 17 19 28 31 4 24 18 27 14 15 18 2 8 12 8 11 9 ----- **Gff** GFF lines have nine required fields that must be tab-separated. ----- **Gff3** The GFF3 format addresses the most common extensions to GFF, while preserving backward compatibility with previous formats. ----- **Interval (Genomic Intervals)** - Tab delimited format (tabular) - File must start with definition line in the following format (columns may be in any order).:: #CHROM START END STRAND - CHROM - The name of the chromosome (e.g. chr3, chrY, chr2_random) or contig (e.g. ctgY1). - START - The starting position of the feature in the chromosome or contig. The first base in a chromosome is numbered 0. - END - The ending position of the feature in the chromosome or contig. The chromEnd base is not included in the display of the feature. For example, the first 100 bases of a chromosome are defined as chromStart=0, chromEnd=100, and span the bases numbered 0-99. - STRAND - Defines the strand - either '+' or '-'. - Example:: #CHROM START END STRAND NAME COMMENT chr1 10 100 + exon myExon chrX 1000 10050 - gene myGene ----- **Lav** Lav is the primary output format for BLASTZ. The first line of a .lav file begins with #:lav.. ----- **MAF** TBA and multiz multiple alignment format. The first line of a .maf file begins with ##maf. This word is followed by white-space-separated \"variable=value\" pairs. There should be no white space surrounding the \"=\". ----- **Scf** A binary sequence file in 'scf' format with a '.scf' file extension. You must manually select this 'File Format' when uploading the file. ----- **Sff** A binary file in 'Standard Flowgram Format' with a '.sff' file extension. ----- **Tabular (tab delimited)** Any data in tab delimited format (tabular) ----- **Table (delimiter-separated)** Any delimiter-separated tabular data (CSV or TSV). ----- **Wig** The wiggle format is line-oriented. Wiggle data is preceded by a track definition line, which adds a number of options for controlling the default display of this track. ----- **Other text type** Any text file",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "ucsc_table_direct1",
    "name": "UCSC Main",
    "description": "table browser",
    "categories": [
      "Get Data"
    ],
    "version": "1.0.0",
    "help": "",
    "input_formats": [],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "ebi_sra_main",
    "name": "EBI SRA",
    "description": "ENA SRA",
    "categories": [
      "Get Data"
    ],
    "version": "1.0.1",
    "help": "",
    "input_formats": [],
    "output_formats": [
      "auto"
    ]
  },
  {
    "tool_id": "export_remote",
    "name": "Export datasets",
    "description": "to repositories",
    "categories": [
      "Send Data"
    ],
    "version": "0.1.0",
    "help": "",
    "input_formats": [
      "data"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "__UNZIP_COLLECTION__",
    "name": "Unzip collection",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets). Description Given a paired collection of forward and reverse reads this tool will \"unzip\" it into two collections containing forward and reverse reads, respectively: .. image:: ${static_path}/images/tools/collection_ops/unzip.svg :width: 500 :alt: Unzipping operation ----- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__ZIP_COLLECTION__",
    "name": "Zip collections",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Takes two collections and creates a paired collection from them. Description If you have one collection containing only forward reads and one containing only reverse, this tools will \"zip\" them together into a simple paired collection. For example, given two collections with `forward` and `reverse` reads they can be \"zipped\" into a single paired collection: .. image:: ${static_path}/images/tools/collection_ops/zip.svg :width: 500 :alt: Zipping operation ----- .. class:: infomark This tool will create new history datasets for your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__FILTER_FAILED_DATASETS__",
    "name": "Filter failed datasets",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Removes datasets in error (red) from a collection. Description This tool takes a dataset collection and filters out (removes) datasets in the failed (red) state. This is useful for continuing a multi-sample analysis when one or more of the samples fails at some point. .. image:: ${static_path}/images/tools/collection_ops/filter_error.svg :width: 500 :alt: Filter failed datasets ----- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__FILTER_EMPTY_DATASETS__",
    "name": "Filter empty datasets",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Removes empty elements from a collection. This tool takes a dataset collection and filters out (removes) empty datasets. This is useful for continuing a multi-sample analysis when downstream tools require datasets to have content. .. image:: ${static_path}/images/tools/collection_ops/filter_empty.svg :width: 500 :alt: Filtering empty datasets ----- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__KEEP_SUCCESS_DATASETS__",
    "name": "Keep success",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Keep datasets in success (green) from a collection. Description This tool takes a dataset collection and filters in (keep) datasets in the success (green) state. This is useful for continuing a multi-sample analysis when one of more of the samples fails or is in paused state. .. image:: ${static_path}/images/tools/collection_ops/keep_success.svg :width: 500 :alt: Keep success datasets ----- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__FLATTEN__",
    "name": "Flatten collection",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Flattens nested collection into a simple list. Description This tool takes nested collections such as a list of lists or a list of dataset pairs and produces a flat list from the inputs. It effectively \"flattens\" the hierarchy. The collection identifiers are merged together (using \"_\" as default) to create new collection identifiers in the flattened result: .. image:: ${static_path}/images/tools/collection_ops/flatten.svg :width: 500 :alt: Flattening operation ---- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__MERGE_COLLECTION__",
    "name": "Merge collections",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Takes two or more collections and creates a single collection from them. Description By default the tool assumes that collections that are being merged have unique dataset names. If it not the case only one (the first) of the datasets with a repeated name will be included in the merged collection. For example, suppose you have two collections. Each has two datasets named \"A\" and \"B\":: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Merging them will produce a single collection with only two datasets:: Merged Collection: [Dataset A] [Dataset B] [Dataset X] [Dataset Y] This behavior can be changed by clicking on \"*Advanced Options*\" link. The following options are available: **Keep first instance (Default behavior)** Input:: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Output:: Merged Collection: [Dataset A] [Dataset B] [Dataset X] [Dataset Y] Here if two collection have identical dataset names, a dataset is chosen from the *first* collection. ----- **Keep first instance** Input:: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Output:: Merged Collection: [Dataset A] [Dataset B] [Dataset X] [Dataset Y] Here if two collection have identical dataset names, a dataset is chosen from the *last* collection. ----- **Append suffix to conflicted element identifiers** Input:: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Output:: Merged Collection: [Dataset A_1] [Dataset B_1] [Dataset A_2] [Dataset B_2] [Dataset X] [Dataset Y] ---- **Append suffix to conflicted element identifiers after first on encountered** Input:: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Output:: Merged Collection: [Dataset A] [Dataset B] [Dataset A_2] [Dataset B_2] [Dataset X] [Dataset Y] ------ **Append suffix to every element identifier** Input:: Collection 1: [Dataset A] [Dataset B] [Dataset X] Collection 2: [Dataset A] [Dataset B] [Dataset Y] Output:: Merged Collection: [Dataset A_1] [Dataset B_2] [Dataset A_2] [Dataset B_2] [Dataset X_1] [Dataset Y_2] ----- **Fail collection creation** This option will simply trigger an error. ------ .. class:: infomark This tool will create new history datasets for your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__RELABEL_FROM_FILE__",
    "name": "Relabel identifiers",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.1.0",
    "help": "Synopsis Changes identifiers of datasets within a collection using identifiers from a supplied file. Description New identifiers can be supplied as either a simple list or a tab-delimited file mapping old identifiers to new ones. This is controlled using **How should the new identifiers be specified?** drop-down: **Use lines in a simple text file as new identifiers** Given a collection:: Collection: [Dataset A] [Dataset B] [Dataset X] and a simple text file:: Alpha Beta Gamma the tool will return:: Collection: [Dataset Alpha] [Dataset Beta] [Dataset Gamma] .. class:: infomark **Note** that the order and number of entries in the text file must match the order of the items you want to rename in your dataset collection. ------- **Map original identifiers to new ones using a two-column table** Given a collection:: Collection: [Dataset A] [Dataset B] [Dataset X] and a simple tabular file (you can see that entries do not have to be in order here):: B Beta X Gamma A Alpha the tool will return:: Collection: [Dataset Alpha] [Dataset Beta] [Dataset Gamma] ------- **Map original identifiers to new ones using a two-column table** This mode works exactly as the previous one, but the tabular mapping file is allowed to have more than two columns, and you can specify which of them holds the original and new element identifiers, respectively. ------- .. class:: warningmark Valid identifiers must contain only characters (a-z, A-Z), numbers (0-9), dash (-), underscore (_), dot (.), space ( ) and comma (,). Other characters are not allowed. .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [
      "txt",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "__FILTER_FROM_FILE__",
    "name": "Filter collection",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Filters elements from a collection using a list supplied in a file. Description This tools allow filtering elements from a data collection. It takes an input collection and a text file with names (i.e. identifiers). The tool behavious is controlled by **How should the elements to remove be determined?** drop-down. It has the following options: **Remove if identifiers are ABSENT from file** Given a collection:: Collection: [Dataset A] [Dataset B] [Dataset X] and a text file:: A B Z the tool will return two collections:: (filtered): [Dataset A] [Dataset B] (discarded): [Dataset X] ------ **Remove if identifiers are PRESENT in file** Given a collection:: Collection: [Dataset A] [Dataset B] [Dataset X] and a text file:: A B Z the tool will return two collections:: (filtered): [Dataset X] (discarded): [Dataset A] [Dataset B] .. class:: warningmark **Note** how the tool deals with the ``Z`` entry. .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "__SORTLIST__",
    "name": "Sort collection",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Sorts dataset collection alphabetically, numerically, or using predetermined order from a supplied file. Description **Numeric sort** The tool sort in ascending order. When *numeric* sort is chosen, the tool ignores non-numeric characters. For example, if a collection contains the following elements:: Collection: [Horse123] [Donkey543] [Mule176] The tool will output:: Collection: [Horse123] [Mule176] [Donkey543] ------- **Sorting from file** Alternative, one can supply a single column text file containing elements identifiers in the desired sort order. For example, suppose there a collection:: Collection: [Horse123] [Donkey543] [Mule176] and a file specifying sort order:: Donkey543 Horse123 Mule176 the output will predictably look like this:: Collection: [Donkey543] [Horse123] [Mule176] ------- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "__HARMONIZELISTS__",
    "name": "Harmonize two collections",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Harmonize 2 collections: Inputs are 2 collections. Outputs are 2 collections with: - Same identifiers (identifiers which are specific to one or the other are removed) - Identifiers are in the same order Example If the inputs are:: Collection1: [Horse123] [Donkey543] [Mule176] Collection2: [Horse] [Mule176] [Donkey543] The tool will output:: Collection1: [Donkey543] [Mule176] Collection2: [Donkey543] [Mule176] ------- .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__CROSS_PRODUCT_FLAT__",
    "name": "Flat Cross Product",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis This tool organizes two dataset lists so that Galaxy's normal collection processing produces an all-vs-all style analyses of the initial inputs when applied to the outputs of this tool. While a description of what it does standalone is technical and math heavy, how it works within an ad-hoc analysis or workflow can be quite straight forward and hopefully is easier to understand. For this reason, the next section describes how to use this tool in context and the technical details follow after that. Hopefully, the \"how it works\" details aren't nessecary to understand the \"how to use it\" details of this tool - at least for simple things. How to use this tool This tool can be used in and out of workflows, but workflows will be used to illustrate the ordering of tools and connections between them. Imagine a tool that compares two individual datasets and how that might be connected to list inputs in a workflow. This simiple case is shown below: .. image:: ${static_path}/images/tools/collection_ops/dot_product.png :alt: The Dot Product of Two Collections :width: 500 In this configuration - the two datasets will be matched and compared element-wise. So the first dataset of \"Input List 1\" will be compared to the first dataset in \"Input List 2\" and the resulting dataset will be the first dataset in the output list generated using this comparison tool. In this configuration the lists need to have the same number of elements and ideally matching element identifiers. This matching up of elements is a very natural way to \"map\" an operation (or in Galaxy parlance, a tool) over two lists. However, sometimes the desire is to compare each element of the first list to each element of the second list. This tool enables that. Running input lists through this tool produces new dataset lists (described in detail below) that when using the same natural element-wise matching \"map over\" semantics described above produce every combination of the elements of the two lists compared against each other. Running a tool with these two outputs instead of the inital two input produces a list of the comparison of each combination of pairs from the respective inputs. .. image:: ${static_path}/images/tools/collection_ops/flat_crossproduct_output.png :alt: The Flat Cartesian Product of Two Collections :width: 500 The result of running a subsequent tool with the outputs produced by this tool will be a much larger list whose element identifiers are the concatenation of the combinations of the elements identifiers from the two input lists. .. image:: ${static_path}/images/tools/collection_ops/flat_crossproduct_separator.png :alt: Flat Cross Product Identifier Separator :width: 500 What this tool does (technical details) This tool consumes two lists - we will call them ``input_a`` and ``input_b``. If ``input_a`` has length ``n`` and dataset elements identified as ``a1``, ``a2``, ... ``an`` and ``input_b`` has length ``m`` and dataset elements identified as ``b1``, ``b2``, ... ``bm``, then this tool produces a pair of larger lists - each of size ``n*m``. Both output lists will be the same length and contain the same set of element identifiers in the same order. If the kth input can be described as ``(i-1)*n + (j-1)`` where ``1 <= i <= m`` and ``1 <= j <= n`` then the element identifier for this kth element is the concatenation of the element identifier for the ith item of ``input_a`` and the jth item of ``input_b``. In the first output list, this kth element will be the ith element of ``input_a``. In the second output list, the kth element will be the jth element of ``input_b``. .. image:: ${static_path}/images/tools/collection_ops/flat_cross_product_outputs.png :alt: Flat Cross Product Outputs :width: 500 These list structures might appear to be a little odd, but they have the very useful property that if you match up corresponding elements of the lists the result is each combination of elements in ``input_a`` and ``input_b`` are matched up once. .. image:: ${static_path}/images/tools/collection_ops/flat_cross_product_matched.png :alt: Flat Cross Product Matching Datasets :width: 500 Running a downstream comparison tool that compares two datasets with these two lists produces a new list with every combination of comparisons. .. image:: ${static_path}/images/tools/collection_ops/flat_cross_product_downstream.png :alt: Flat Cross Product All-vs-All Result :width: 500 ---- .. class:: infomark This tool will create new history datasets copied from your input collections but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__CROSS_PRODUCT_NESTED__",
    "name": "Nested Cross Product",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis This tool organizes two dataset lists so that Galaxy's normal collection processing produces an all-vs-all style analyses of the initial inputs when applied to the outputs of this tool. While a description of what it does standalone is technical and math heavy, how it works within an ad-hoc analysis or workflow can be quite straight forward and hopefully is easier to understand. For this reason, the next section describes how to use this tool in context and the technical details follow after that. Hopefully, the \"how it works\" details aren't nessecary to understand the \"how to use it\" details of this tool - at least for simple things. How to use this tool This tool can be used in and out of workflows, but workflows will be used to illustrate the ordering of tools and connections between them. Imagine a tool that compares two individual datasets and how that might be connected to list inputs in a workflow. This simiple case is shown below: .. image:: ${static_path}/images/tools/collection_ops/dot_product.png :alt: The Dot Product of Two Collections :width: 500 In this configuration - the two datasets will be matched and compared element-wise. So the first dataset of \"Input List 1\" will be compared to the first dataset in \"Input List 2\" and the resulting dataset will be the first dataset in the output list generated using this comparison tool. In this configuration the lists need to have the same number of elements and ideally matching element identifiers. This matching up of elements is a very natural way to \"map\" an operation (or in Galaxy parlance, a tool) over two lists. However, sometimes the desire is to compare each element of the first list to each element of the second list. This tool enables that. Running input lists through this tool produces new list structures (described in detail below) that when using the same natural element-wise matching \"map over\" semantics described above produce every combination of the elements of the two lists compared against each other. Running a tool with these two outputs instead of the inital two input produces a nested list structure where the jth element of the inner list of the ith element of the outer list is a comparison of the ith element of the first list to the jth element of the second list. Put more simply, the result is a nested list where the identifiers of an element describe which inputs were matched to produce the comparison output found at that element. .. image:: ${static_path}/images/tools/collection_ops/nested_crossproduct_output.png :alt: The Cartesian Product of Two Collections :width: 500 What this tool does (technical details) This tool consumes two flat lists. We will call the input collections ``input_a`` and ``input_b``. If ``input_a`` has length ``n`` and dataset elements identified as ``a1``, ``a2``, ... ``an`` and ``input_b`` has length ``m`` and dataset elements identified as ``b1``, ``b2``, ... ``bm``, then this tool produces a pair of output nested lists (specifically of the ``list:list`` collection type) where the outer list is of length ``n`` and each inner list has a length of ``m`` (a ``n X m`` nested list). The jth element inside the outer list's ith element is a pseudo copy of the ith dataset of ``inputa``. One way to think about the output nested lists is as matrices. Here is a diagram of the first output showing the element identifiers of the outer and inner lists along with the what dataset is being \"copied\" into this new collection. .. image:: ${static_path}/images/tools/collection_ops/nested_cross_product_out_1.png :alt: Nested Cross Product First Output :width: 500 The second output is a nested list of pseudo copies of the elements of ``input_b`` instead of ``input_a``. In particular the outer list is again of length ``n`` and each inner list is again of lenth ``m`` but this time the jth element inside the outer list's ith element is a pseudo copy of the jth dataset of ``inputb``. Here is the matrix of these outputs. .. image:: ${static_path}/images/tools/collection_ops/nested_cross_product_out_2.png :alt: Nested Cross Product Second Output :width: 500 These nested list structures might appear to be a little odd, but they have the very useful property that if you match up corresponding elements of the nested lists the result is each combination of elements in ``input_a`` and ``input_b`` are matched up once. The following diagram describes these matching datasets. .. image:: ${static_path}/images/tools/collection_ops/nested_cross_product_matching.png :alt: Matching Inputs :width: 500 Running a tool that compares two datasets with these two nested lists produces a new nested list as described above. The following diagram shows the structure of this output and how the element identifiers are preserved and indicate what comparison was performed. .. image:: ${static_path}/images/tools/collection_ops/nested_cross_product_output.png :alt: Matching Inputs :width: 500 ---- .. class:: infomark This tool will create new history datasets copied from your input collections but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__TAG_FROM_FILE__",
    "name": "Tag elements",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Adds tags (including name: and group: tags) to collection elements. Description The relationship between element names and tags is specified in a two column tab-delimited file. This file may contain less entries than elements in the collection. In that case only matching list identifiers will be tagged. To create name: or group: tags prepend them with ``#`` (you can also use ``name:``) or ``group:``, respectively. More about tags Galaxy allows tagging datasets to facilitate analyses. There are several types of tags including simple tags, name tags, and group tags. **Simple** tags allow you to attach an alternative label to a dataset, which will make it easier to find it later. **Name** tags allow you to track propagation of a dataset through the analyses: all datasets derived from the initial dataset labeled with a name tag will inherit it. Finally, **group** tags allow you to label group of datasets. This is useful. for example, for differential expression analysis where you can have two groups of datasets labeled as \"treatment\" and \"control\". To learn mote about tags go to `our training site`_. .. _our training site: https://training.galaxyproject.org/training-material/search?query=tags",
    "input_formats": [
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "__APPLY_RULES__",
    "name": "Apply rules",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.1.0",
    "help": "Synopsis This tool allows one to process an existing Galaxy dataset collection's metadata as tabular data, apply a series of rules to it, and generate a new collection. Description When used interactively in the tool form, a dynamic preview of the processing will be available in a tabular data viewer but this tool may be used in workflows as well where no such preview can be generated. This tool is an advanced feature but has a lot of flexibility - it can be used to process collections with arbitrary nesting and can do many kinds of filtering, re-sorting, nesting, flattening, and arbitrary combinations thereof not possible with Galaxy's other, more simple collection operation tools. More information about the rule processor in general can be found at `our training site`_. .. _our training site: https://training.galaxyproject.org/training-material/search?query=rule+builder .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__BUILD_LIST__",
    "name": "Build list",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.2.0",
    "help": "Synopsis Builds a new list collection from individual datasets or collections. Description This tool combines individual datasets or collections into a new collection. The simplest scenario is building a new colection from individual datasets (case **A** in the image below). You can merge a collection with individual dataset(s). In this case (see **B** in the image below) the individual dataset(s) will be merged with each element of the input collection to create a nested collection. Finally, two or more collection can be merged together creating a nested collection (case **C** in the image below). .. class:: warningmark **Note**: When merging collections (e.g., case **C** below) the input collection **must** have equal number of elements. ------ .. image:: ${static_path}/images/tools/collection_ops/build_list.svg :width: 800 :alt: Unzipping operation ------- .. class:: infomark This tool will create a new collection from your history datasets but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__EXTRACT_DATASET__",
    "name": "Extract dataset",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.2",
    "help": "Synopsis Extracts datasets from a collection based on either position or identifier. Description The tool allow extracting datasets based on position (**The first dataset** and **Select by index** options) or name (**Select by element identifier** option). This tool effectively collapses the inner-most collection into a dataset. For nested collections (e.g a list of lists of lists: outer:middle:inner, extracting the inner dataset element) a new list is created where the selected element takes the position of the inner-most collection (so outer:middle, where middle is not a collection but the inner dataset element). .. class:: warningmark **Note**: Dataset index (numbering) begins with 0 (zero). .. class:: infomark This tool will create new history datasets from your collection but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__DUPLICATE_FILE_TO_COLLECTION__",
    "name": "Duplicate file to collection",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Creates a collection of arbitrary size by duplicating an input dataset N times, where N is a user-specified integer. Description This tool allows creation of a dataset collection of arbitrary size. It takes an input dataset and an integer parameter, which specifies the number of times to duplicate the dataset in the output collection. In addition, the user can specify the base name for the element identifier to use in the output. For example, if `Number` is specified as 3 and `Element identifier` as 'Element', the output collection will contain three identical datasets, with the identifiers `Element 1`, `Element 2` and `Element 3`. .. class:: infomark This tool will create new history datasets but your quota usage will not increase.",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "__SAMPLE_SHEET_TO_TABULAR__",
    "name": "Sample sheet to tabular",
    "description": "",
    "categories": [
      "Collection Operations"
    ],
    "version": "1.0.0",
    "help": "Synopsis Takes a sample sheet dataset collection and converts the sample sheet metadata into a tabular dataset.",
    "input_formats": [],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "param_value_from_file",
    "name": "Parse parameter value",
    "description": "from dataset",
    "categories": [
      "Expression Tools"
    ],
    "version": "0.1.0",
    "help": "",
    "input_formats": [],
    "output_formats": []
  },
  {
    "tool_id": "addValue",
    "name": "Add column",
    "description": "to an existing dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **What it does** You can enter any value and it will be added as a new column to your dataset ----- **Example** If your original data looks like this:: chr1 10 100 geneA chr2 200 300 geneB chr2 400 500 geneC Typing **+** in the text box will generate:: chr1 10 100 geneA + chr2 200 300 geneB + chr2 400 500 geneC + You can also add line numbers by selecting **Iterate: YES**. In this case if you enter **1** in the text box you will get:: chr1 10 100 geneA 1 chr2 200 300 geneB 2 chr2 400 500 geneC 3",
    "input_formats": [
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "cat1",
    "name": "Concatenate multiple datasets or collections",
    "description": "",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": ".. class:: warningmark **WARNING:** Be careful not to concatenate datasets of different kinds (e.g., sequences with intervals). This tool does not check if the datasets being concatenated are in the same format. ----- **What it does** Concatenates datasets ----- **Example** Concatenating Dataset:: chrX 151087187 151087355 A 0 - chrX 151572400 151572481 B 0 + with Dataset1:: chr1 151242630 151242955 X 0 + chr1 151271715 151271999 Y 0 + chr1 151278832 151279227 Z 0 - and with Dataset2:: chr2 100000030 200000955 P 0 + chr2 100000015 200000999 Q 0 + will result in the following:: chrX 151087187 151087355 A 0 - chrX 151572400 151572481 B 0 + chr1 151242630 151242955 X 0 + chr1 151271715 151271999 Y 0 + chr1 151278832 151279227 Z 0 - chr2 100000030 200000955 P 0 + chr2 100000015 200000999 Q 0 +",
    "input_formats": [
      "data"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Condense characters1",
    "name": "Condense",
    "description": "consecutive characters",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool condenses all consecutive characters of a specified type. ----- **Example** - Input file:: geneX,,,10,,,,,20 geneY,,5,,,,,12,15,9, - Condense all consecutive commas. The above file will be converted into:: geneX,10,20 geneY,5,12,15,9",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Convert characters1",
    "name": "Convert",
    "description": "delimiters to TAB",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.1",
    "help": "**What it does** Converts all delimiters of a specified type into TABs. Consecutive delimiters can be condensed in a single TAB. ----- **Example** - Input file:: chrX||151283558|151283724|NM_000808_exon_8_0_chrX_151283559_r|0|- chrX|151370273|151370486|NM_000808_exon_9_0_chrX_151370274_r|0|- chrX|151559494|151559583|NM_018558_exon_1_0_chrX_151559495_f|0|+ chrX|151564643|151564711|NM_018558_exon_2_0_chrX_151564644_f||||0|+ - Converting all pipe delimiters of the above file to TABs and condensing delimiters will get:: chrX 151283558 151283724 NM_000808_exon_8_0_chrX_151283559_r 0 - chrX 151370273 151370486 NM_000808_exon_9_0_chrX_151370274_r 0 - chrX 151559494 151559583 NM_018558_exon_1_0_chrX_151559495_f 0 + chrX 151564643 151564711 NM_018558_exon_2_0_chrX_151564644_f 0 +",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "mergeCols1",
    "name": "Merge Columns",
    "description": "together",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.1",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **What it does** This tool merges columns together. Any number of valid columns can be merged in any order. ----- **Example** Input dataset (five columns: c1, c2, c3, c4, and c5):: 1 10 1000 gene1 chr 2 100 1500 gene2 chr merging columns \"**c5,c1**\" will return:: 1 10 1000 gene1 chr chr1 2 100 1500 gene2 chr chr2 .. class:: warningmark Note that all original columns are preserved and the result of merge is added as the rightmost column.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "createInterval",
    "name": "Create single interval",
    "description": "as a new dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": ".. class:: warningmark **TIP**. Once your interval appears in history, you must tell Galaxy which genome it belongs to by clicking pencil icon or the \"?\" link in the history item. ----- **What it does** This tool allows you to create a single genomic interval. The resulting history item will be in the BED format. ----- **Example** Typing the following values in the form:: Chromosome: chrX Start position: 151087187 End position: 151370486 Name: NM_000808 Strand: minus will create a single interval:: chrX 151087187 151370486 NM_000808 0 -",
    "input_formats": [],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "Cut1",
    "name": "Cut",
    "description": "columns from a table",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.2",
    "help": ".. class:: warningmark **WARNING: This tool breaks column assignments.** To re-establish column assignments run the tools and click on the pencil icon in the latest history item. .. class:: infomark The output of this tool is always in tabular format (e.g., if your original delimiters are commas, they will be replaced with tabs). For example: Cutting columns 1 and 3 from:: apple,is,good windows,is,bad will give:: apple good windows bad ----- **What it does** This tool selects (cuts out) specified columns from the dataset. - Columns are specified as **c1**, **c2**, and so on. Column count begins with **1** - Columns can be specified in any order (e.g., **c2,c1,c6**) - If you specify more columns than actually present - empty spaces will be filled with dots ----- **Example** Input dataset (six columns: c1, c2, c3, c4, c5, and c6):: chr1 10 1000 gene1 0 + chr2 100 1500 gene2 0 + **cut** on columns \"**c1,c4,c6**\" will return:: chr1 gene1 + chr2 gene2 + **cut** on columns \"**c6,c5,c4,c1**\" will return:: + 0 gene1 chr1 + 0 gene2 chr2 **cut** on columns \"**c1-c3**\" will return:: chr1 10 1000 chr2 100 1500 **cut** on columns \"**c8,c7,c4**\" will return:: . . gene1 . . gene2",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "ChangeCase",
    "name": "Change Case",
    "description": "of selected columns",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": ".. class:: warningmark **This tool breaks column assignments.** To re-establish column assignments run the tool and click on the pencil icon in the resulting history item. .. class:: warningmark The format of the resulting dataset from this tool is always tabular. ----- **What it does** This tool selects specified columns from a dataset and converts the values of those columns to upper or lower case. - Columns are specified as **c1**, **c2**, and so on. - Columns can be specified in any order (e.g., **c2,c1,c6**) ----- **Example** Changing columns 1 and 3 ( delimited by Comma ) to upper case in:: apple,is,good windows,is,bad will result in:: APPLE is GOOD WINDOWS is BAD",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "Paste1",
    "name": "Paste",
    "description": "two files side by side",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": ".. class:: infomark Paste preserves column assignments of the first dataset. ----- **What it does** This tool merges two datasets side by side. If the first (left) dataset contains column assignments such as chromosome, start, end and strand, these will be preserved. However, if you would like to change column assignments, click the pencil icon in the history item. ----- **Example** First dataset:: a 1 a 2 a 3 Second dataset:: 20 30 40 Pasting them together will produce:: a 1 20 a 2 30 a 3 40",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Remove beginning1",
    "name": "Remove beginning",
    "description": "of a file",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool removes a specified number of lines from the beginning of a dataset. ----- **Example** Input File:: chr7 56632 56652 D17003_CTCF_R6 310 + chr7 56736 56756 D17003_CTCF_R7 354 + chr7 56761 56781 D17003_CTCF_R4 220 + chr7 56772 56792 D17003_CTCF_R7 372 + chr7 56775 56795 D17003_CTCF_R4 207 + After removing the first 3 lines the dataset will look like this:: chr7 56772 56792 D17003_CTCF_R7 372 + chr7 56775 56795 D17003_CTCF_R4 207 +",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "random_lines1",
    "name": "Select random lines",
    "description": "from a file",
    "categories": [
      "Text Manipulation"
    ],
    "version": "2.0.2",
    "help": "**What it does** This tool selects N random lines from a file, with no repeats, and preserving ordering. ----- **Example** Input File:: chr7 56632 56652 D17003_CTCF_R6 310 + chr7 56736 56756 D17003_CTCF_R7 354 + chr7 56761 56781 D17003_CTCF_R4 220 + chr7 56772 56792 D17003_CTCF_R7 372 + chr7 56775 56795 D17003_CTCF_R4 207 + Selecting 2 random lines might return this:: chr7 56736 56756 D17003_CTCF_R7 354 + chr7 56775 56795 D17003_CTCF_R4 207 +",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "input"
    ]
  },
  {
    "tool_id": "Show beginning1",
    "name": "Select first",
    "description": "lines from a dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.2",
    "help": "**What it does** This tool outputs specified number of lines from the **beginning** of a dataset ----- **Example** Selecting 2 lines from this:: chr7 56632 56652 D17003_CTCF_R6 310 + chr7 56736 56756 D17003_CTCF_R7 354 + chr7 56761 56781 D17003_CTCF_R4 220 + chr7 56772 56792 D17003_CTCF_R7 372 + chr7 56775 56795 D17003_CTCF_R4 207 + will produce:: chr7 56632 56652 D17003_CTCF_R6 310 + chr7 56736 56756 D17003_CTCF_R7 354 +",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Show tail1",
    "name": "Select last",
    "description": "lines from a dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool outputs specified number of lines from the **end** of a dataset ----- **Example** - Input File:: chr7 57134 57154 D17003_CTCF_R7 356 - chr7 57247 57267 D17003_CTCF_R4 207 + chr7 57314 57334 D17003_CTCF_R5 269 + chr7 57341 57361 D17003_CTCF_R7 375 + chr7 57457 57477 D17003_CTCF_R3 188 + - Show last two lines of above file. The result is:: chr7 57341 57361 D17003_CTCF_R7 375 + chr7 57457 57477 D17003_CTCF_R3 188 +",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "trimmer",
    "name": "Trim",
    "description": "leading or trailing characters",
    "categories": [
      "Text Manipulation"
    ],
    "version": "0.0.2",
    "help": "**What it does** Trims specified number of characters from a dataset or a given column (if dataset is tab-delimited). ----- **Example 1** Trimming this dataset:: 1234567890 abcdefghijk by setting **Trim from the beginning up to this position** to *2* and **Remove everything from this position to the end** to *6* will produce:: 23456 bcdef ----- **Example 2** Trimming column 2 of this dataset:: abcde 12345 fghij 67890 fghij 67890 abcde 12345 by setting **Trim content of this column only** to *2*, **Trim from the beginning up to this position** to *2*, and **Remove everything from this position to the end** to *4* will produce:: abcde 234 fghij 67890 fghij 789 abcde 12345 ----- **Example 3** Trimming column 2 of this dataset:: abcde 12345 fghij 67890 fghij 67890 abcde 12345 by setting **Trim content of this column only** to *2*, **Trim from the beginning up to this position** to *2*, and **Remove everything from this position to the end** to *-2* will produce:: abcde 23 fghij 67890 fghij 78 abcde 12345 ---- **Trimming FASTQ datasets** This tool can be used to trim sequences and quality strings in FASTQ datasets. This is done by selected *Yes* from the **Is input dataset in FASTQ format?** dropdown. If set to *Yes*, the tool will skip all even numbered lines (see warning below). For example, trimming last 5 bases of this dataset:: @081017-and-081020:1:1:1715:1759 GGACTCAGATAGTAATCCACGCTCCTTTAAAATATC + II#IIIIIII$5+.(9IIIIIII$%*$G$A31I&&B can be done by setting **Remove everything from this position to the end** to 31:: @081017-and-081020:1:1:1715:1759 GGACTCAGATAGTAATCCACGCTCCTTTAAA + II#IIIIIII$5+.(9IIIIIII$%*$G$A3 **Note** that headers are skipped. .. class:: warningmark **WARNING:** This tool will only work on properly formatted FASTQ datasets where (1) each read and quality string occupy one line and (2) '@' (read header) and \"+\" (quality header) lines are evenly numbered like in the above example.",
    "input_formats": [
      "tabular",
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "wc_gnu",
    "name": "Line/Word/Character count",
    "description": "of a dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool outputs counts of specified attributes (lines, words, characters) of a dataset. ----- **Example Output** :: #lines words characters 7499 41376 624971 ------ **Citation** If you use this tool in Galaxy, please cite Blankenberg D, et al. *In preparation.*",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "secure_hash_message_digest",
    "name": "Secure Hash / Message Digest",
    "description": "on a dataset",
    "categories": [
      "Text Manipulation"
    ],
    "version": "0.0.2",
    "help": "**What it does** This tool outputs Secure Hashes / Message Digests of a dataset using the user selected algorithms. ------ **Citation** If you use this tool in Galaxy, please cite Blankenberg D, et al. *In preparation.*",
    "input_formats": [
      "data"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "Filter1",
    "name": "Filter",
    "description": "data on any column using simple expressions",
    "categories": [
      "Filter and Sort"
    ],
    "version": "1.1.1",
    "help": ".. class:: warningmark Double equal signs, , must be used as *\"equal to\"* (e.g., **c1 'chr22'**) .. class:: infomark **TIP:** Attempting to apply a filtering condition may throw exceptions if the data type (e.g., string, integer) in every line of the columns being filtered is not appropriate for the condition (e.g., attempting certain numerical calculations on strings). If an exception is thrown when applying the condition to a line, that line is skipped as invalid for the filter condition. The number of invalid skipped lines is documented in the resulting history item as a \"Condition/data issue\". .. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** The filter tool allows you to restrict the dataset using simple conditional statements. - Columns are referenced with **c** and a **number**. For example, **c1** refers to the first column of a tab-delimited file - Make sure that multi-character operators contain no white space ( e.g., ** =1** selects lines in which the value of column 2 is greater than or equal to 1 - Numbers should not contain commas - **c2<=44,554,350** will not work, but **c2<=44554350** will - Some words in the data can be used, but must be single or double quoted ( e.g., **c3 'exon'** )",
    "input_formats": [
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Grep1",
    "name": "Select",
    "description": "lines that match an expression",
    "categories": [
      "Filter and Sort"
    ],
    "version": "1.0.4",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** The select tool searches the data for lines containing or not containing a match to the given pattern. Regular Expression is introduced in this tool. A Regular Expression is a pattern describing a certain amount of text. - **( ) { } [ ] . * ? + \\ ^ $** are all special characters. **\\\\** can be used to \"escape\" a special character, allowing that special character to be searched for. - **\\\\A** matches the beginning of a string(but not an internal line). - **\\\\d** matches a digit, same as [0-9]. - **\\\\D** matches a non-digit. - **\\\\s** matches a whitespace character. - **\\\\S** matches anything BUT a whitespace. - **\\\\t** matches a tab. - **\\\\w** matches an alphanumeric character. - **\\\\W** matches anything but an alphanumeric character. - **(** .. **)** groups a particular pattern. - **\\\\Z** matches the end of a string(but not a internal line). - **{** n or n, or n,m **}** specifies an expected number of repetitions of the preceding pattern. - **{n}** The preceding item is matched exactly n times. - **{n,}** The preceding item is matched n or more times. - **{n,m}** The preceding item is matched at least n times but not more than m times. - **[** ... **]** creates a character class. Within the brackets, single characters can be placed. A dash (-) may be used to indicate a range such as **a-z**. - **.** Matches any single character except a newline. - ***** The preceding item will be matched zero or more times. - **?** The preceding item is optional and matched at most once. - **+** The preceding item will be matched one or more times. - **^** has two meaning: - matches the beginning of a line or string. - indicates negation in a character class. For example, [^...] matches every character except the ones inside brackets. - **$** matches the end of a line or string. - **\\|** Separates alternate possibilities. ----- **Example** - **^chr([0-9A-Za-z])+** would match lines that begin with chromosomes, such as lines in a BED format file. - **(ACGT){1,5}** would match at least 1 \"ACGT\" and at most 5 \"ACGT\" consecutively. - **([^,][0-9]{1,3})(,[0-9]{3})\\*** would match a large integer that is properly separated with commas such as 23,078,651. - **(abc)|(def)** would match either \"abc\" or \"def\". - **^\\\\W+#** would match any line that is a comment.",
    "input_formats": [
      "txt"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Extract_features1",
    "name": "Extract features",
    "description": "from GFF data",
    "categories": [
      "Filter and Sort"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool extracts selected features from GFF data. ----- **Example** Selecting **promoter** from the following GFF data:: chr22 GeneA enhancer 10000000 10001000 500 + . TGA chr22 GeneA promoter 10010000 10010100 900 + . TGA chr22 GeneB promoter 10020000 10025000 400 - . TGB chr22 GeneB CCDS2220 10030000 10065000 800 - . TGB will produce the following output:: chr22 GeneA promoter 10010000 10010100 900 + . TGA chr22 GeneB promoter 10020000 10025000 400 - . TGB ---- .. class:: infomark **About formats** **GFF format** General Feature Format is a format for describing genes and other features associated with DNA, RNA and Protein sequences. GFF lines have nine tab-separated fields:: 1. seqname - Must be a chromosome or scaffold. 2. source - The program that generated this feature. 3. feature - The name of this type of feature. Some examples of standard feature types are \"CDS\", \"start_codon\", \"stop_codon\", and \"exon\". 4. start - The starting position of the feature in the sequence. The first base is numbered 1. 5. end - The ending position of the feature (inclusive). 6. score - A score between 0 and 1000. If there is no score value, enter \".\". 7. strand - Valid entries include '+', '-', or '.' (for don't know/care). 8. frame - If the feature is a coding exon, frame should be a number between 0-2 that represents the reading frame of the first base. If the feature is not a coding exon, the value should be '.'. 9. group - All lines with the same group are linked together into a single item.",
    "input_formats": [
      "gff"
    ],
    "output_formats": []
  },
  {
    "tool_id": "gff_filter_by_attribute",
    "name": "Filter GFF data by attribute",
    "description": "using simple expressions",
    "categories": [
      "Filter and Sort"
    ],
    "version": "0.2",
    "help": ".. class:: warningmark Double equal signs, , must be used as *\"equal to\"* (e.g., **c1 'chr22'**) .. class:: infomark **TIP:** Attempting to apply a filtering condition may throw exceptions if the data type (e.g., string, integer) in every line of the attribute being filtered is not appropriate for the condition (e.g., attempting certain numerical calculations on strings). If an exception is thrown when applying the condition to a line, that line is skipped as invalid for the filter condition. The number of invalid skipped lines is documented in the resulting history item as a \"Condition/data issue\". .. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** The filter tool allows you to restrict the dataset using simple conditional statements. - Make sure that multi-character operators contain no white space ( e.g., **<=** is valid while **< =** is not valid ) - When using 'equal-to' operator **double equal sign ' ' must be used** ( e.g., **attribute_name 'chr1'** ) - Non-numerical values must be included in single or double quotes ( e.g., **attribute_name 'XX22'** ) - You can combine multiple conditional statements using **and** or **or** ( e.g., **attribute_name 'XX22' or attribute_name 'XX21'** )",
    "input_formats": [
      "gff"
    ],
    "output_formats": []
  },
  {
    "tool_id": "gff_filter_by_feature_count",
    "name": "Filter GFF data by feature count",
    "description": "using simple expressions",
    "categories": [
      "Filter and Sort"
    ],
    "version": "0.1.1",
    "help": ".. class:: infomark Valid comparison operators are: > =, <=, !=, and ----- **Syntax** The filter tool allows you to restrict the dataset based on transcripts' feature counts.",
    "input_formats": [
      "gff"
    ],
    "output_formats": []
  },
  {
    "tool_id": "gtf_filter_by_attribute_values_list",
    "name": "Filter GTF data by attribute values_list",
    "description": "",
    "categories": [
      "Filter and Sort"
    ],
    "version": "0.2",
    "help": "This tool filters a GTF file using a list of attribute values. The attribute values are taken from the first column in the file; additional columns in the file are ignored. An example use of this tool is to filter a GTF file using a list of transcript_ids or gene_ids obtained from Cuffdiff.",
    "input_formats": [
      "gtf",
      "tabular",
      "txt"
    ],
    "output_formats": [
      "gtf"
    ]
  },
  {
    "tool_id": "join1",
    "name": "Join two Datasets",
    "description": "side by side on a specified field",
    "categories": [
      "Join, Subtract and Group"
    ],
    "version": "2.1.3",
    "help": ".. class:: warningmark **This tool will force the ouput datatype to tabular.** To change metadata assignments click on the \"edit attributes\" link of the history item generated by this tool. .. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** This tool joins lines of two datasets on a common field. An empty string (\"\") is not a valid identifier. You may choose to include lines of your first input that do not join with your second input. - Columns are referenced with a **number**. For example, **3** refers to the 3rd column of a tab-delimited file. ----- **Example** Dataset1:: chr1 10 20 geneA chr1 50 80 geneB chr5 10 40 geneL Dataset2:: geneA tumor-supressor geneB Foxp2 geneC Gnas1 geneE INK4a Joining the 4th column of Dataset1 with the 1st column of Dataset2 will yield:: chr1 10 20 geneA geneA tumor-suppressor chr1 50 80 geneB geneB Foxp2 Joining the 4th column of Dataset1 with the 1st column of Dataset2, while keeping all lines from Dataset1, will yield:: chr1 10 20 geneA geneA tumor-suppressor chr1 50 80 geneB geneB Foxp2 chr5 10 40 geneL",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "comp1",
    "name": "Compare two Datasets",
    "description": "to find common or distinct rows",
    "categories": [
      "Join, Subtract and Group"
    ],
    "version": "1.0.2",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** This tool finds lines in one dataset that HAVE or DO NOT HAVE a common field with another dataset. ----- **Example** If this is **First dataset**:: chr1 10 20 geneA chr1 50 80 geneB chr5 10 40 geneL and this is **Second dataset**:: geneA tumor-suppressor geneB Foxp2 geneC Gnas1 geneE INK4a Finding lines of the **First dataset** whose 4th column matches the 1st column of the **Second dataset** yields:: chr1 10 20 geneA chr1 50 80 geneB Conversely, using option **Non Matching rows of First dataset** on the same fields will yield:: chr5 10 40 geneL",
    "input_formats": [
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "Grouping1",
    "name": "Group",
    "description": "data by a column and perform aggregate operation on other columns.",
    "categories": [
      "Join, Subtract and Group"
    ],
    "version": "2.1.4",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** This tool allows you to group the input dataset by a particular column and perform aggregate functions: Mean, Median, Mode, Sum, Max, Min, Count, Concatenate, and Randomly pick on any column(s). The Concatenate function will take, for each group, each item in the specified column and build a comma delimited list. Concatenate Unique will do the same but will build a list of unique items with no repetition. Count and Count Unique are equivalent to Concatenate and Concatenate Unique, but will only count the number of items and will return an integer. - If multiple modes are present, all are reported. ----- **Example** - For the following input:: chr22 1000 1003 TTT chr22 2000 2003 aaa chr10 2200 2203 TTT chr10 1200 1203 ttt chr22 1600 1603 AAA - **Grouping on column 4** while ignoring case, and performing operation **Count on column 1** will return:: AAA 2 TTT 3 - **Grouping on column 4** while not ignoring case, and performing operation **Count on column 1** will return:: aaa 1 AAA 1 ttt 1 TTT 2",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "bed2gff1",
    "name": "BED-to-GFF",
    "description": "converter",
    "categories": [
      "Convert Formats"
    ],
    "version": "2.0.0",
    "help": "**What it does** This tool converts data from BED format to GFF format (scroll down for format description). -------- **Example** The following data in BED format:: chr28 346187 388197 BC114771 0 + 346187 388197 0 9 144,81,115,63,155,96,134,105,112, 0,24095,26190,31006,32131,33534,36994,41793,41898, Will be converted to GFF (**note** that the start coordinate is incremented by 1):: ##gff-version 2 ##bed_to_gff_converter.py chr28 bed2gff mRNA 346188 388197 0 + . mRNA BC114771; chr28 bed2gff exon 346188 346331 0 + . exon BC114771; chr28 bed2gff exon 370283 370363 0 + . exon BC114771; chr28 bed2gff exon 372378 372492 0 + . exon BC114771; chr28 bed2gff exon 377194 377256 0 + . exon BC114771; chr28 bed2gff exon 378319 378473 0 + . exon BC114771; chr28 bed2gff exon 379722 379817 0 + . exon BC114771; chr28 bed2gff exon 383182 383315 0 + . exon BC114771; chr28 bed2gff exon 387981 388085 0 + . exon BC114771; chr28 bed2gff exon 388086 388197 0 + . exon BC114771; ------ .. class:: informark **About formats** **BED format** Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser. It has three required fields and several additional optional ones: The first three BED fields (required) are:: 1. chrom - The name of the chromosome (e.g. chr1, chrY_random). 2. chromStart - The starting position in the chromosome. (The first base in a chromosome is numbered 0.) 3. chromEnd - The ending position in the chromosome, plus 1 (i.e., a half-open interval). The additional BED fields (optional) are:: 4. name - The name of the BED line. 5. score - A score between 0 and 1000. 6. strand - Defines the strand - either '+' or '-'. 7. thickStart - The starting position where the feature is drawn thickly at the Genome Browser. 8. thickEnd - The ending position where the feature is drawn thickly at the Genome Browser. 9. reserved - This should always be set to zero. 10. blockCount - The number of blocks (exons) in the BED line. 11. blockSizes - A comma-separated list of the block sizes. The number of items in this list should correspond to blockCount. 12. blockStarts - A comma-separated list of block starts. All of the blockStart positions should be calculated relative to chromStart. The number of items in this list should correspond to blockCount. 13. expCount - The number of experiments. 14. expIds - A comma-separated list of experiment ids. The number of items in this list should correspond to expCount. 15. expScores - A comma-separated list of experiment scores. All of the expScores should be relative to expIds. The number of items in this list should correspond to expCount. **GFF format** General Feature Format is a format for describing genes and other features associated with DNA, RNA and Protein sequences. GFF lines have nine tab-separated fields:: 1. seqname - Must be a chromosome or scaffold. 2. source - The program that generated this feature. 3. feature - The name of this type of feature. Some examples of standard feature types are \"CDS\", \"start_codon\", \"stop_codon\", and \"exon\". 4. start - The starting position of the feature in the sequence. The first base is numbered 1. 5. end - The ending position of the feature (inclusive). 6. score - A score between 0 and 1000. If there is no score value, enter \".\". 7. strand - Valid entries include '+', '-', or '.' (for don't know/care). 8. frame - If the feature is a coding exon, frame should be a number between 0-2 that represents the reading frame of the first base. If the feature is not a coding exon, the value should be '.'. 9. group - All lines with the same group are linked together into a single item.",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "gff"
    ]
  },
  {
    "tool_id": "gff2bed1",
    "name": "GFF-to-BED",
    "description": "converter",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool converts data from GFF format to BED format (scroll down for format description). -------- **Example** The following data in GFF format:: chr22 GeneA enhancer 10000000 10001000 500 + . TGA chr22 GeneA promoter 10010000 10010100 900 + . TGA Will be converted to BED (**note** that 1 is subtracted from the start coordinate):: chr22 9999999 10001000 enhancer 0 + chr22 10009999 10010100 promoter 0 + ------ .. class:: infomark **About formats** **BED format** Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser. It has three required fields and several additional optional ones: The first three BED fields (required) are:: 1. chrom - The name of the chromosome (e.g. chr1, chrY_random). 2. chromStart - The starting position in the chromosome. (The first base in a chromosome is numbered 0.) 3. chromEnd - The ending position in the chromosome, plus 1 (i.e., a half-open interval). The additional BED fields (optional) are:: 4. name - The name of the BED line. 5. score - A score between 0 and 1000. 6. strand - Defines the strand - either '+' or '-'. 7. thickStart - The starting position where the feature is drawn thickly at the Genome Browser. 8. thickEnd - The ending position where the feature is drawn thickly at the Genome Browser. 9. reserved - This should always be set to zero. 10. blockCount - The number of blocks (exons) in the BED line. 11. blockSizes - A comma-separated list of the block sizes. The number of items in this list should correspond to blockCount. 12. blockStarts - A comma-separated list of block starts. All of the blockStart positions should be calculated relative to chromStart. The number of items in this list should correspond to blockCount. 13. expCount - The number of experiments. 14. expIds - A comma-separated list of experiment ids. The number of items in this list should correspond to expCount. 15. expScores - A comma-separated list of experiment scores. All of the expScores should be relative to expIds. The number of items in this list should correspond to expCount. **GFF format** General Feature Format is a format for describing genes and other features associated with DNA, RNA and Protein sequences. GFF lines have nine tab-separated fields:: 1. seqname - Must be a chromosome or scaffold. 2. source - The program that generated this feature. 3. feature - The name of this type of feature. Some examples of standard feature types are \"CDS\", \"start_codon\", \"stop_codon\", and \"exon\". 4. start - The starting position of the feature in the sequence. The first base is numbered 1. 5. end - The ending position of the feature (inclusive). 6. score - A score between 0 and 1000. If there is no score value, enter \".\". 7. strand - Valid entries include '+', '-', or '.' (for don't know/care). 8. frame - If the feature is a coding exon, frame should be a number between 0-2 that represents the reading frame of the first base. If the feature is not a coding exon, the value should be '.'. 9. group - All lines with the same group are linked together into a single item.",
    "input_formats": [
      "gff"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "MAF_To_BED1",
    "name": "MAF to BED",
    "description": "Converts a MAF formatted file to the BED format",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool converts every MAF block to an interval line (in BED format; scroll down for description of MAF and BED formats) describing position of that alignment block within a corresponding genome. The interface for this tool contains two pages (steps): * **Step 1 of 2**. Choose multiple alignments from history to be converted to BED format. * **Step 2 of 2**. Choose species from the alignment to be included in the output and specify how to deal with alignment blocks that lack one or more species: * **Choose species** - the tool reads the alignment provided during Step 1 and generates a list of species contained within that alignment. Using checkboxes you can specify taxa to be included in the output (only reference genome, shown in **bold**, is selected by default). If you select more than one species, then more than one history item will be created. * **Choose to include/exclude blocks with missing species** - if an alignment block does not contain any one of the species you selected within **Choose species** menu and this option is set to **exclude blocks with missing species**, then coordinates of such a block **will not** be included in the output (see **Example 2** below). ----- **Example 1**: **Include only reference genome** (hg18 in this case) and **include blocks with missing species**: For the following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG the tool will create **a single** history item containing the following (**note** that field 4 is added to the output and is numbered iteratively: hg18_0, hg18_1 etc.):: chr20 56827368 56827443 hg18_0 0 + chr20 56827443 56827480 hg18_1 0 + ----- **Example 2**: **Include hg18 and mm8** and **exclude blocks with missing species**: For the following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG the tool will create **two** history items (one for hg18 and one fopr mm8) containing the following (**note** that both history items contain only one line describing the first alignment block. The second MAF block is not included in the output because it does not contain mm8): History item **1** (for hg18):: chr20 56827368 56827443 hg18_0 0 + History item **2** (for mm8):: chr2 173910832 173910893 mm8_0 0 + ------- .. class:: infomark **About formats** **MAF format** multiple alignment format file. This format stores multiple alignments at the DNA level between entire genomes. - The .maf format is line-oriented. Each multiple alignment ends with a blank line. - Each sequence in an alignment is on a single line. - Lines starting with # are considered to be comments. - Each multiple alignment is in a separate paragraph that begins with an \"a\" line and contains an \"s\" line for each sequence in the multiple alignment. - Some MAF files may contain two optional line types: - An \"i\" line containing information about what is in the aligned species DNA before and after the immediately preceding \"s\" line; - An \"e\" line containing information about the size of the gap between the alignments that span the current block. **BED format** Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser. It has three required fields and a number of additional optional ones: The first three BED fields (required) are:: 1. chrom - The name of the chromosome (e.g. chr1, chrY_random). 2. chromStart - The starting position in the chromosome. (The first base in a chromosome is numbered 0.) 3. chromEnd - The ending position in the chromosome, plus 1 (i.e., a half-open interval). Additional (optional) fields are:: 4. name - The name of the BED line. 5. score - A score between 0 and 1000. 6. strand - Defines the strand - either '+' or '-'.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "MAF_To_Interval1",
    "name": "MAF to Interval",
    "description": "Converts a MAF formatted file to the Interval format",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool converts every MAF block to a set of genomic intervals describing the position of that alignment block within a corresponding genome. Sequences from aligning species are also included in the output. The interface for this tool contains several options: * **MAF file to convert**. Choose multiple alignments from history to be converted to BED format. * **Choose species**. Choose additional species from the alignment to be included in the output * **Exclude blocks which have a species missing**. if an alignment block does not contain any one of the species found in the alignment set and this option is set to **exclude blocks with missing species**, then coordinates of such a block **will not** be included in the output (see **Example 2** below). * **Remove Gap characters from sequences**. Gaps can be removed from sequences before they are output. ----- **Example 1**: **Include only reference genome** (hg18 in this case) and **include blocks with missing species**: For the following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG the tool will create **a single** history item containing the following (**note** the name field is numbered iteratively: hg18_0_0, hg18_1_0 etc. where the first number is the block number and the second number is the iteration through the block (if a species appears twice in a block, that interval will be repeated) and sequences for each species are included in the order specified in the header: the field is left empty when no sequence is available for that species):: #chrom start end strand score name canFam2 hg18 mm8 panTro2 rheMac2 chr20 56827368 56827443 + 68686.0 hg18_0_0 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- chr20 56827443 56827480 + 10289.0 hg18_1_0 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG ----- **Example 2**: **Include hg18 and mm8** and **exclude blocks with missing species**: For the following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG the tool will create **two** history items (one for hg18 and one for mm8) containing the following (**note** that both history items contain only one line describing the first alignment block. The second MAF block is not included in the output because it does not contain mm8): History item **1** (for hg18):: #chrom start end strand score name canFam2 hg18 mm8 panTro2 rheMac2 chr20 56827368 56827443 + 68686.0 hg18_0_0 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- History item **2** (for mm8):: #chrom start end strand score name canFam2 hg18 mm8 panTro2 rheMac2 chr2 173910832 173910893 + 68686.0 mm8_0_0 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- ------- .. class:: infomark **About formats** **MAF format** multiple alignment format file. This format stores multiple alignments at the DNA level between entire genomes. - The .maf format is line-oriented. Each multiple alignment ends with a blank line. - Each sequence in an alignment is on a single line. - Lines starting with # are considered to be comments. - Each multiple alignment is in a separate paragraph that begins with an \"a\" line and contains an \"s\" line for each sequence in the multiple alignment. - Some MAF files may contain two optional line types: - An \"i\" line containing information about what is in the aligned species DNA before and after the immediately preceding \"s\" line; - An \"e\" line containing information about the size of the gap between the alignments that span the current block.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "interval"
    ]
  },
  {
    "tool_id": "MAF_To_Fasta1",
    "name": "MAF to FASTA",
    "description": "Converts a MAF formatted file to FASTA format",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.1",
    "help": "**Types of MAF to FASTA conversion** * **Multiple Blocks** converts a single MAF block to a single FASTA block. For example, if you have 6 MAF blocks, they will be converted to 6 FASTA blocks. * **One Sequence per Species** converts MAF blocks to a single aggregated FASTA block. For example, if you have 6 MAF blocks, they will be converted and concatenated into a single FASTA block. ------- **What it does** This tool converts MAF blocks to FASTA format and concatenates them into a single FASTA block or outputs multiple FASTA blocks separated by empty lines. The interface for this tool contains two pages (steps): * **Step 1 of 2**. Choose multiple alignments from history to be converted to FASTA format. * **Step 2 of 2**. Choose the type of output as well as the species from the alignment to be included in the output. Multiple Block output has additional options: * **Choose species** - the tool reads the alignment provided during Step 1 and generates a list of species contained within that alignment. Using checkboxes you can specify taxa to be included in the output (all species are selected by default). * **Choose to include/exclude blocks with missing species** - if an alignment block does not contain any one of the species you selected within **Choose species** menu and this option is set to **exclude blocks with missing species**, then such a block **will not** be included in the output (see **Example 2** below). For example, if you want to extract human, mouse, and rat from a series of alignments and one of the blocks does not contain mouse sequence, then this block will not be converted to FASTA and will not be returned. ----- **Example 1**: In the concatenated approach, the following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG will be converted to (**note** that because mm8 (mouse) and canFam2 (dog) are absent from the second block, they are replaced with gaps after concatenation):: >canFam2 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C------------------------------------- >hg18 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC-ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG >mm8 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC-------------------------------------------- >panTro2 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC-ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG >rheMac2 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA-------ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG ------ **Example 2a**: Multiple Block Approach **Include all species** and **include blocks with missing species**: The following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG will be converted to:: >hg18.chr20(+):56827368-56827443|hg18_0 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- >panTro2.chr20(+):56528685-56528760|panTro2_0 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- >rheMac2.chr10(-):89144112-89144181|rheMac2_0 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- >mm8.chr2(+):173910832-173910893|mm8_0 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- >canFam2.chr24(+):46551822-46551889|canFam2_0 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C >hg18.chr20(+):56827443-56827480|hg18_1 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG >panTro2.chr20(+):56528760-56528797|panTro2_1 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG >rheMac2.chr10(-):89144181-89144218|rheMac2_1 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG ----- **Example 2b**: Multiple Block Approach **Include hg18 and mm8** and **exclude blocks with missing species**: The following alignment:: ##maf version=1 a score=68686.000000 s hg18.chr20 56827368 75 + 62435964 GACAGGGTGCATCTGGGAGGG---CCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s panTro2.chr20 56528685 75 + 62293572 GACAGGGTGCATCTGAGAGGG---CCTGCCAGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC- s rheMac2.chr10 89144112 69 - 94855758 GACAGGGTGCATCTGAGAGGG---CCTGCTGGGCCTTTG-TTCAAAACTAGATATGCCCCAACTCCAATTCTA------- s mm8.chr2 173910832 61 + 181976762 AGAAGGATCCACCT------------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------- s canFam2.chr24 46551822 67 + 50763139 CG------GCGTCTGTAAGGGGCCACCGCCCGGCCTGTG-CTCAAAGCTACAAATGACTCAACTCCCAACCGA------C a score=10289.000000 s hg18.chr20 56827443 37 + 62435964 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s panTro2.chr20 56528760 37 + 62293572 ATGTGCAGAAAATGTGATACAGAAACCTGCAGAGCAG s rheMac2.chr10 89144181 37 - 94855758 ATGTGCGGAAAATGTGATACAGAAACCTGCAGAGCAG will be converted to (**note** that the second MAF block, which does not have mm8, is not included in the output):: >hg18.chr20(+):56827368-56827443|hg18_0 GACAGGGTGCATCTGGGAGGGCCTGCCGGGCCTTTA-TTCAACACTAGATACGCCCCATCTCCAATTCTAATGGAC >mm8.chr2(+):173910832-173910893|mm8_0 AGAAGGATCCACCT---------TGCTGGGCCTCTGCTCCAGCAAGACCCACCTCCCAACTCAAATGCCC------ ------ .. class:: infomark **About formats** **MAF format** multiple alignment format file. This format stores multiple alignments at the DNA level between entire genomes. - The .maf format is line-oriented. Each multiple alignment ends with a blank line. - Each sequence in an alignment is on a single line. - Lines starting with # are considered to be comments. - Each multiple alignment is in a separate paragraph that begins with an \"a\" line and contains an \"s\" line for each sequence in the multiple alignment. - Some MAF files may contain two optional line types: - An \"i\" line containing information about what is in the aligned species DNA before and after the immediately preceding \"s\" line; - An \"e\" line containing information about the size of the gap between the alignments that span the current block.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "Sff_extractor",
    "name": "SFF converter",
    "description": "",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool extracts data from the 454 Sequencer SFF format and creates three files containing the: Sequences (FASTA), Qualities (QUAL) and Clippings (XML)",
    "input_formats": [
      "sff"
    ],
    "output_formats": [
      "fastqsanger",
      "xml",
      "fasta",
      "qual"
    ]
  },
  {
    "tool_id": "bed_to_bigBed",
    "name": "BED-to-bigBed",
    "description": "converter",
    "categories": [
      "Convert Formats"
    ],
    "version": "1.0.1",
    "help": "This tool converts a **sorted** BED file into a bigBed file. Currently, the bedFields option to specify the number of non-standard fields is not supported as an AutoSQL file must be provided, which is a format currently not supported by Galaxy.",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "bigbed"
    ]
  },
  {
    "tool_id": "liftOver1",
    "name": "Convert genome coordinates",
    "description": "between assemblies and genomes",
    "categories": [
      "Lift-Over"
    ],
    "version": "1.0.6",
    "help": ".. class:: warningmark Make sure that the genome build of the input dataset is specified (click the pencil icon in the history item to set it if necessary). .. class:: warningmark This tool can work with interval, GFF, and GTF datasets. It requires the interval datasets to have chromosome in column 1, start co-ordinate in column 2 and end co-ordinate in column 3. BED comments and track and browser lines will be ignored, but if other non-interval lines are present the tool will return empty output datasets. ----- .. class:: infomark **What it does** This tool is based on the LiftOver utility and Chain track from `the UC Santa Cruz Genome Browser` . It converts coordinates and annotations between assemblies and genomes. It produces 2 files, one containing all the mapped coordinates and the other containing the unmapped coordinates, if any. .. : http://genome.ucsc.edu/ ----- **Example** Converting the following hg16 intervals to hg18 intervals:: chrX 85170 112199 AK002185 0 + chrX 110458 112199 AK097346 0 + chrX 112203 121212 AK074528 0 - will produce the following hg18 intervals:: chrX 132991 160020 AK002185 0 + chrX 158279 160020 AK097346 0 + chrX 160024 169033 AK074528 0 -",
    "input_formats": [
      "interval",
      "gff",
      "gtf"
    ],
    "output_formats": []
  },
  {
    "tool_id": "wiggle2simple1",
    "name": "Wiggle-to-Interval",
    "description": "converter",
    "categories": [
      "Operate on Genomic Intervals"
    ],
    "version": "1.0.1",
    "help": "**Syntax** This tool converts wiggle data into interval type. - **Wiggle format**: The .wig format is line-oriented. Wiggle data is preceded by a UCSC track definition line. Following the track definition line is the track data, which can be entered in three different formats described below. - **BED format** with no declaration line and four columns of data:: chromA chromStartA chromEndA dataValueA chromB chromStartB chromEndB dataValueB - **variableStep** two column data; started by a declaration line and followed with chromosome positions and data values:: variableStep chrom=chrN [span=windowSize] chromStartA dataValueA chromStartB dataValueB - **fixedStep** single column data; started by a declaration line and followed with data values:: fixedStep chrom=chrN start=position step=stepInterval [span=windowSize] dataValue1 dataValue2 ----- **Example** - input wiggle format file:: #track type=wiggle_0 name=\"Bed Format\" description=\"BED format\" chr19 59302000 59302300 -1.0 chr19 59302300 59302600 -0.75 chr19 59302600 59302900 -0.50 chr19 59302900 59303200 -0.25 chr19 59303200 59303500 0.0 #track type=wiggle_0 name=\"variableStep\" description=\"variableStep format\" variableStep chrom=chr19 span=150 59304701 10.0 59304901 12.5 59305401 15.0 59305601 17.5 #track type=wiggle_0 name=\"fixedStep\" description=\"fixed step\" visibility=full fixedStep chrom=chr19 start=59307401 step=300 span=200 1000 900 800 700 600 - convert the above file to interval file:: chr19 59302000 59302300 + -1.0 chr19 59302300 59302600 + -0.75 chr19 59302600 59302900 + -0.5 chr19 59302900 59303200 + -0.25 chr19 59303200 59303500 + 0.0 chr19 59304701 59304851 + 10.0 chr19 59304901 59305051 + 12.5 chr19 59305401 59305551 + 15.0 chr19 59305601 59305751 + 17.5 chr19 59307701 59307901 + 1000.0 chr19 59308001 59308201 + 900.0 chr19 59308301 59308501 + 800.0 chr19 59308601 59308801 + 700.0 chr19 59308901 59309101 + 600.0",
    "input_formats": [
      "wig"
    ],
    "output_formats": [
      "interval"
    ]
  },
  {
    "tool_id": "aggregate_scores_in_intervals2",
    "name": "Aggregate datapoints",
    "description": "Appends the average, min, max of datapoints per interval",
    "categories": [
      "Operate on Genomic Intervals"
    ],
    "version": "1.1.4",
    "help": ".. class:: warningmark This tool currently only has cached data for genome builds hg16, hg17 and hg18. However, you may use your own data point (wiggle) data, such as those available from UCSC. If you are trying to use your own data point file and it is not appearing as an option, make sure that the builds for your history items are the same. .. class:: warningmark This tool assumes that the input dataset is in interval format and contains at least a chrom column, a start column and an end column. These 3 columns can be dispersed throughout any number of other data columns. ----- .. class:: infomark **TIP:** Computing summary information may throw exceptions if the data type (e.g., string, integer) in every line of the columns is not appropriate for the computation (e.g., attempting numerical calculations on strings). If an exception is thrown when computing summary information for a line, that line is skipped as invalid for the computation. The number of invalid skipped lines is documented in the resulting history item as a \"Data issue\". ----- **Syntax** This tool appends columns of summary information for each interval matched against a selected dataset. For each interval, the average, minimum and maximum for the data falling within the interval is computed. - Several quantitative scores are provided for the ENCODE regions. - Various Scores - Regulatory Potential - Neutral rate (Ancestral Repeats) - GC fraction - Conservation Scores - PhastCons - binCons - GERP ----- **Example** If your original data has the following format: +------+-----+-----+---+------+ |other1|chrom|start|end|other2| +------+-----+-----+---+------+ and you choose to aggregate phastCons scores, your output will look like this: +------+-----+-----+---+------+---+---+---+ |other1|chrom|start|end|other2|avg|min|max| +------+-----+-----+---+------+---+---+---+ where: * **avg** - average phastCons score for each region * **min** - minimum phastCons score for each region * **max** - maximum phastCons score for each region",
    "input_formats": [
      "interval",
      "wig"
    ],
    "output_formats": [
      "interval"
    ]
  },
  {
    "tool_id": "gene2exon1",
    "name": "Gene BED To Exon/Intron/Codon BED",
    "description": "expander",
    "categories": [
      "Operate on Genomic Intervals"
    ],
    "version": "1.0.0",
    "help": ".. class:: warningmark This tool works only on a BED file that contains at least 12 fields (see **Example** and **About formats** below). The output will be empty if applied to a BED file with 3 or 6 fields. ------ **What it does** BED format can be used to represent a single gene in just one line, which contains the information about exons, coding sequence location (CDS), and positions of untranslated regions (UTRs). This tool *unpacks* this information by converting a single line describing a gene into a collection of lines representing individual exons, introns, UTRs, etc. ------- **Example** Extracting **Coding Exons + UTR Exons** from the following two BED lines:: chr7 127475281 127491632 NM_000230 0 + 127486022 127488767 0 3 29,172,3225, 0,10713,13126 chr7 127486011 127488900 D49487 0 + 127486022 127488767 0 2 155,490, 0,2399 will return:: chr7 127475281 127475310 NM_000230 0 + chr7 127485994 127486166 NM_000230 0 + chr7 127488407 127491632 NM_000230 0 + chr7 127486011 127486166 D49487 0 + chr7 127488410 127488900 D49487 0 + ------ .. class:: infomark **About formats** **BED format** Browser Extensible Data format was designed at UCSC for displaying data tracks in the Genome Browser. It has three required fields and additional optional ones. In the specific case of this tool the following fields must be present:: 1. chrom - The name of the chromosome (e.g. chr1, chrY_random). 2. chromStart - The starting position in the chromosome. (The first base in a chromosome is numbered 0.) 3. chromEnd - The ending position in the chromosome, plus 1 (i.e., a half-open interval). 4. name - The name of the BED line. 5. score - A score between 0 and 1000. 6. strand - Defines the strand - either '+' or '-'. 7. thickStart - The starting position where the feature is drawn thickly at the Genome Browser. 8. thickEnd - The ending position where the feature is drawn thickly at the Genome Browser. 9. reserved - This should always be set to zero. 10. blockCount - The number of blocks (exons) in the BED line. 11. blockSizes - A comma-separated list of the block sizes. The number of items in this list should correspond to blockCount. 12. blockStarts - A comma-separated list of block starts. All of the blockStart positions should be calculated relative to chromStart. The number of items in this list should correspond to blockCount.",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "Interval2Maf_pairwise1",
    "name": "Extract Pairwise MAF blocks",
    "description": "given a set of genomic intervals",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool takes genomic coordinates, superimposes them on pairwise alignments (in MAF format) stored on the Galaxy site, and excises alignment blocks corresponding to each set of coordinates. Alignment blocks that extend past START and/or END positions of an interval are trimmed. Note that a single genomic interval may correspond to two or more alignment blocks. ----- **Example** Here a single interval is superimposed on three MAF blocks. Blocks 1 and 3 are trimmed because they extend beyond boundaries of the interval: .. image:: ${static_path}/images/maf_icons/interval2maf.png",
    "input_formats": [
      "interval"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "Interval_Maf_Merged_Fasta2",
    "name": "Stitch MAF blocks",
    "description": "given a set of genomic intervals",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** A single genomic region can be covered by multiple alignment blocks. In many cases it is desirable to stitch these alignment blocks together. This tool accepts a list of genomic intervals. For every interval it performs the following: * finds all MAF blocks that overlap the interval; * sorts MAF blocks by alignment score; * stitches blocks together and resolves overlaps based on alignment score; * outputs alignments in FASTA format. ------ **Example** Here three MAF blocks overlapping a single interval are stitched together. Space between blocks 2 and 3 is filled with gaps: .. image:: ${static_path}/images/maf_icons/stitchMaf.png",
    "input_formats": [
      "interval",
      "maf"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "GeneBed_Maf_Fasta2",
    "name": "Stitch Gene blocks",
    "description": "given a set of coding exon intervals",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** The coding sequence of genes are usually composed of several coding exons. Each of these coding exons is an individual genomic region, which when concatenated with each other constitutes the coding sequence. A single genomic region can be covered by multiple alignment blocks. In many cases it is desirable to stitch these alignment blocks together. This tool accepts a list of gene-based intervals, in the Gene BED format. For every interval it performs the following: * finds all MAF blocks that overlap the coding regions; * sorts MAF blocks by alignment score; * stitches blocks together and resolves overlaps based on alignment score; * outputs alignments in FASTA format.",
    "input_formats": [
      "bed",
      "maf"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "maf_stats1",
    "name": "MAF Coverage Stats",
    "description": "Alignment coverage information",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool takes a MAF file and an interval file and relates coverage information by interval for each species. If a column does not exist in the reference genome, it is not included in the output. Consider the interval: \"chrX 1000 1100 myInterval\" Let's suppose we want to do stats on three way alignments for H, M, and R. The result look like this: chrX 1000 1100 myInterval H XXX YYY chrX 1000 1100 myInterval M XXX YYY chrX 1000 1100 myInterval R XXX YYY where XXX and YYY are: XXX = number of nucleotides YYY = number of gaps ---- Alternatively, you can request only summary information for a set of intervals: #species nucleotides coverage hg18 30639 0.2372 rheMac2 7524 0.0582 panTro2 30390 0.2353 where **coverage** is the number of nucleotides divided by the total length of the provided intervals.",
    "input_formats": [
      "interval",
      "maf"
    ],
    "output_formats": [
      "interval"
    ]
  },
  {
    "tool_id": "MAF_Thread_For_Species1",
    "name": "Join MAF blocks",
    "description": "by Species",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.0",
    "help": "**What it does** This tool allows the user to merge MAF blocks which are adjoining in each specified species from a MAF file. Columns which contain only gaps are removed. Species which are not desired are removed from the output. **Example** Specifying the desired species as hg17 and panTro1 with this MAF file:: ##maf version=1 a score=60426.000000 s hg17.chr7 127471195 331 + 158628139 gtttgccatcttttgctgctctagggaatccagcagctgtcaccatgtaaacaagcccaggctagaccaGTTACCCTCATCATCTTAGCTGATAGCCAGCCAGCCACCACAGGCAtgagtcaggccatattgctggacccacagaattatgagctaaataaatagtcttgggttaagccactaagttttaggcatagtgtgttatgtaTCTCACAAACATATAAGACTGTGTGTTTGTTGACTGGAGGAAGAGATGCTATAAAGACCACCTTTTAAAACTTCCC-------------------------------AAATACT-GCCACTGATGTCCTG-----ATGGAGGTA-------TGAA-------------------AACATCCACTAA s panTro1.chr6 129885076 331 + 161576975 gtttgccatcttttgctgctcttgggaatccagcagctgtcaccatgtaaacaagcccaggctagaccaGTTACCCTCATCATCTTAGCTGATAGCCAGCCAGCCACCACAGGCAtgagtcaggccatattgctggacccacagaattatgagctaaataaatagtcttgggttaagccactaagttttaggcatagtgtgttatgtaTCTCACAAACATATAAGACTGTGTGTTTGTTGACTGGAGGAAGAGATGCTATAAAGACCACCTTTTGAAACTTCCC-------------------------------AAATACT-GCCACTGATGTCCTG-----ATGGAGGTA-------TGAA-------------------AACATCCACTAA s mm5.chr6 28904571 357 + 149721531 CTCCACTCTCGTTTGCTGTT----------------CTGTCACCATGGAAACAAA-CGAGGGTGGTCCAGTTACTATCTTGACTGCAGCTGGCAGTCAGTT-GCCACT-----CAGGAATAAGGCTATGCCATT-GATCCACTGAACCGTGATCTGGAAACCTGGCTGTTGTTT-------CAAGCCTTGGGGCCAGTTTGCGGTGTTACTCATGA--CTCTAAGATCGTGTGCTTG----CTGCAGGAAGAGACAGCAAGGGGGTTACATTTAAAAAGCCCCCAGTTTAGCTATAGGCAGGCCAACAGGTGTAAAAATACTCACTAGTAATGGGCTGAACTCATGGAGGTAGCATTAGTGAGACACTGTAACTGTTTTTTTAAAAATCACTAA s rn3.chr4 56178191 282 + 187371129 CTTCACTCTCATTTGCTGTT----------------CTGTCACTATGGAGACAAACACAGGCTAGCCCAGTTACTATCTTGATCACAGCAGCT-GTCAGCTAGCTGCCACTCACAGGAATAAGGCCATACCATT-GATCCACTGAACCTTGATCTAGGAATTTGGC----------------------TGGGGCCAGTTTGCGGTGTCACTCATGA--CTCTAAGATTGTGTGTTTG----CTCCAGGAAGAGACGGCAAGAGGATTACCTTTAAAAGGTTC---------------------------------GGAGTCTAGCTGTAGACAGCCCA-----ATG--GGTA-------TAAC-------------------AATACTCACTAA a score=8157.000000 s hg17.chr7 127471526 58 + 158628139 AATTTGTGGTTTATTCATTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG s panTro1.chr6 129885407 58 + 161576975 AATTTGTGGTTTATTCGTTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG s mm5.chr6 28904928 54 + 149721531 AA----CGTTTCATTGATTGCTCATCATTTAAAAAAAGAAATTCCTCAGTGGAAGAGG results in:: ##maf version=1 a score=0.0 s hg17.chr7 127471195 389 + 158628139 gtttgccatcttttgctgctctagggaatccagcagctgtcaccatgtaaacaagcccaggctagaccaGTTACCCTCATCATCTTAGCTGATAGCCAGCCAGCCACCACAGGCAtgagtcaggccatattgctggacccacagaattatgagctaaataaatagtcttgggttaagccactaagttttaggcatagtgtgttatgtaTCTCACAAACATATAAGACTGTGTGTTTGTTGACTGGAGGAAGAGATGCTATAAAGACCACCTTTTAAAACTTCCCAAATACTGCCACTGATGTCCTGATGGAGGTATGAAAACATCCACTAAAATTTGTGGTTTATTCATTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG s panTro1.chr6 129885076 389 + 161576975 gtttgccatcttttgctgctcttgggaatccagcagctgtcaccatgtaaacaagcccaggctagaccaGTTACCCTCATCATCTTAGCTGATAGCCAGCCAGCCACCACAGGCAtgagtcaggccatattgctggacccacagaattatgagctaaataaatagtcttgggttaagccactaagttttaggcatagtgtgttatgtaTCTCACAAACATATAAGACTGTGTGTTTGTTGACTGGAGGAAGAGATGCTATAAAGACCACCTTTTGAAACTTCCCAAATACTGCCACTGATGTCCTGATGGAGGTATGAAAACATCCACTAAAATTTGTGGTTTATTCGTTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "MAF_Limit_To_Species1",
    "name": "Filter MAF blocks",
    "description": "by Species",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.0",
    "help": "**What It Does** This tool allows the user to remove any undesired species from a MAF file. Columns which contain only gaps are removed. The options for this tool are: * **Exclude blocks which have missing species** - suppose you want to restrict an 8-way alignment to human, mouse, and rat. The tool will first remove all other species. Next, if this option is set to **YES** the tool WILL NOT return MAF blocks, which do not include human, mouse, or rat. This means that all alignment blocks returned by the tool will have exactly three sequences in this example. * **Exclude blocks with have only one species** - if this option is set to **YES** all single sequence alignment blocks WILL NOT be returned.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "maf_limit_size1",
    "name": "Filter MAF blocks",
    "description": "by Size",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool takes a MAF file and a size range and extracts the MAF blocks which fall within the specified range.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "maf_by_block_number1",
    "name": "Extract MAF by block number",
    "description": "given a set of block numbers and a MAF file",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool takes a list of block numbers, one per line, and extracts the corresponding MAF blocks from the provided file. Block numbers start at 0.",
    "input_formats": [
      "tabular",
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "MAF_Reverse_Complement_1",
    "name": "Reverse Complement",
    "description": "a MAF file",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool takes a MAF file and creates a new MAF file, where each block has been reversed complemented. **Example** This MAF Block:: a score=8157.000000 s hg17.chr7 127471526 58 + 158628139 AATTTGTGGTTTATTCATTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG s panTro1.chr6 129885407 58 + 161576975 AATTTGTGGTTTATTCGTTTTTCATTATTTTGTTTAAGGAGGTCTATAGTGGAAGAGG s mm5.chr6 28904928 54 + 149721531 AA----CGTTTCATTGATTGCTCATCATTTAAAAAAAGAAATTCCTCAGTGGAAGAGG becomes:: a score=8157.000000 s hg17.chr7 31156555 58 - 158628139 CCTCTTCCACTATAGACCTCCTTAAACAAAATAATGAAAAATGAATAAACCACAAATT s panTro1.chr6 31691510 58 - 161576975 CCTCTTCCACTATAGACCTCCTTAAACAAAATAATGAAAAACGAATAAACCACAAATT s mm5.chr6 120816549 54 - 149721531 CCTCTTCCACTGAGGAATTTCTTTTTTTAAATGATGAGCAATCAATGAAACG----TT",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "MAF_filter",
    "name": "Filter MAF",
    "description": "by specified attributes",
    "categories": [
      "Fetch Sequences/Alignments"
    ],
    "version": "1.0.1",
    "help": "This tool allows you to build complex filters to be applied to each alignment block of a MAF file. You can define restraints on species based upon chromosome and strand. You can specify comma separated lists of chromosomes where appropriate. .. class:: infomark For example, this tool is useful to restrict a set of alignments to only those blocks which contain alignments between chromosomes that are considered homologous. ----- .. class:: warningmark If a species is not found in a particular block, all filters on that species are ignored. ----- This tool allows the user to remove any undesired species from a MAF file. If no species are specified then all species will be kept. If species are specified, columns which contain only gaps are removed. The options for this are: * **Exclude blocks which have missing species** - suppose you want to restrict an 8-way alignment to human, mouse, and rat. The tool will first remove all other species. Next, if this option is set to **YES** the tool WILL NOT return MAF blocks, which do not include human, mouse, or rat. This means that all alignment blocks returned by the tool will have exactly three sequences in this example. * **Exclude blocks which have only one species** - if this option is set to **YES** all single sequence alignment blocks WILL NOT be returned. ----- You can also provide a size range and limit your output to the MAF blocks which fall within the specified range.",
    "input_formats": [
      "maf"
    ],
    "output_formats": [
      "maf"
    ]
  },
  {
    "tool_id": "hgv_linkToGProfile",
    "name": "g:Profiler",
    "description": "tools for functional profiling of gene lists",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input dataset is tabular_ with a column of identifiers. The output dataset is html_ with a link to g:Profiler. (`Dataset missing?`_) .. _tabular: ${static_path}/formatHelp.html#tab .. _html: ${static_path}/formatHelp.html#html .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** This tool creates a link to the g:GOSt tool (Gene Group Functional Profiling), which is part of the g:Profiler site at the University of Tartu in Estonia. g:GOSt retrieves the most significant Gene Ontology (GO) terms, KEGG and REACTOME pathways, and TRANSFAC motifs for a user-specified group of genes, proteins, or microarray probes. g:GOSt also allows analysis of ranked or ordered lists of genes, visual browsing of GO graph structure, interactive visualization of retrieved results, and many other features. Multiple testing corrections are applied to extract only statistically important results. The g:GOSt form is pre-filled with gene, protein, or microarray probe IDs from the selected column of a tabular Galaxy dataset. Or you can chose to use the genomic coordinates (must be lastest build used by Ensembl). The coordinates don't have to be genes they can be for SNPs, and g:GOst will map to the gene ID. To follow the created link, click on the eye icon when the Galaxy tool has finished running. Once at the g:Profiler site, scroll down to see the g:GOSt results. You can also adjust the options in the g:GOSt form to your liking, or use the row of links between the form and the results to run other g:Profiler tools using the same list of IDs. ----- **Reference** Reimand J, Kull M, Peterson H, Hansen J, Vilo J. (2007) g:Profiler -- a web-based toolset for functional profiling of gene lists from large-scale experiments. Nucleic Acids Res. 35(Web Server issue):W193-200. Epub 2007 May 3.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "hgv_david",
    "name": "DAVID",
    "description": "functional annotation for a list of genes",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.1",
    "help": ".. class:: infomark The list is limited to 400 IDs. ----- **Dataset formats** The input dataset is in tabular_ format. The output dataset is html_ with a link to the DAVID website as described below. (`Dataset missing?`_) .. _tabular: ${static_path}/formatHelp.html#tab .. _html: ${static_path}/formatHelp.html#html .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** This tool creates a link to the Database for Annotation, Visualization, and Integrated Discovery (DAVID) website at NIH, sending a list of IDs from the selected column of a tabular Galaxy dataset. To follow the created link, click on the eye icon once the Galaxy tool has finished running. DAVID provides a comprehensive set of functional annotation tools to help investigators discover biological meaning behind large lists of genes. ----- **References** Huang DW, Sherman BT, Lempicki RA. (2009) Systematic and integrative analysis of large gene lists using DAVID bioinformatics resources. Nat Protoc. 4(1):44-57. Dennis G, Sherman BT, Hosack DA, Yang J, Gao W, Lane HC, Lempicki RA. (2003) DAVID: database for annotation, visualization, and integrated discovery. Genome Biol. 4(5):P3. Epub 2003 Apr 3.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "hgv_ldtools",
    "name": "LD",
    "description": "linkage disequilibrium and tag SNPs",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input and output datasets are tabular_. (`Dataset missing?`_) .. _tabular: ${static_path}/formatHelp.html#tab .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** This tool can be used to analyze the patterns of linkage disequilibrium (LD) between polymorphic sites in a locus. SNPs are grouped based on the threshold level of LD as measured by r\\ :sup:`2` (regardless of genomic position), and a representative \"tag SNP\" is reported for each group. The other SNPs in the group are in LD with the tag SNP, but not necessarily with each other. The underlying algorithm is the same as the one used in ldSelect (Carlson et al. 2004). However, this tool is implemented to be much faster and more efficient than ldSelect. The input is a tabular file with genotype information for each individual at each SNP site, in exactly four columns: site ID, sample ID, and the two allele nucleotides. ----- **Example** - input file:: rs2334386 NA20364 G T rs2334386 NA20363 G G rs2334386 NA20360 G G rs2334386 NA20359 G G rs2334386 NA20358 G G rs2334386 NA20356 G G rs2334386 NA20357 G G rs2334386 NA20350 G G rs2334386 NA20349 G G rs2334386 NA20348 G G rs2334386 NA20347 G G rs2334386 NA20346 G G rs2334386 NA20345 G G rs2334386 NA20344 G G rs2334386 NA20342 G G etc. - output file:: rs2238748 rs2793064,rs6518516,rs6518517,rs2283641,rs5993533,rs715590,rs2072123,rs2105421,rs2800954,rs1557847,rs807750,rs807753,rs5993488,rs8138035,rs2800980,rs2525079,rs5992353,rs712966,rs2525036,rs807743,rs1034727,rs807744,rs2074003 rs2871023 rs1210715,rs1210711,rs5748189,rs1210709,rs3788298,rs7284649,rs9306217,rs9604954,rs1210703,rs5748179,rs5746727,rs5748190,rs5993603,rs2238766,rs885981,rs2238763,rs5748165,rs9605996,rs9606001,rs5992398 rs7292006 rs13447232,rs5993665,rs2073733,rs1057457,rs756658,rs5992395,rs2073760,rs739369,rs9606017,rs739370,rs4493360,rs2073736 rs2518840 rs1061325,rs2283646,rs362148,rs1340958,rs361956,rs361991,rs2073754,rs2040771,rs2073740,rs2282684 rs2073775 rs10160,rs2800981,rs807751,rs5993492,rs2189490,rs5747997,rs2238743 rs5747263 rs12159924,rs2300688,rs4239846,rs3747025,rs3747024,rs3747023,rs2300691 rs433576 rs9605439,rs1109052,rs400509,rs401099,rs396012,rs410456,rs385105 rs2106145 rs5748131,rs2013516,rs1210684,rs1210685,rs2238767,rs2277837 rs2587082 rs2257083,rs2109659,rs2587081,rs5747306,rs2535704,rs2535694 rs807667 rs2800974,rs756651,rs762523,rs2800973,rs1018764 rs2518866 rs1206542,rs807467,rs807464,rs807462,rs712950 rs1110661 rs1110660,rs7286607,rs1110659,rs5992917,rs1110662 rs759076 rs5748760,rs5748755,rs5748752,rs4819925,rs933461 rs5746487 rs5992895,rs2034113,rs2075455,rs1867353 rs5748212 rs5746736,rs4141527,rs5748147,rs5748202 etc. ----- **Reference** Carlson CS, Eberle MA, Rieder MJ, Yi Q, Kruglyak L, Nickerson DA. (2004) Selecting a maximally informative set of single-nucleotide polymorphisms for association analyses using linkage disequilibrium. Am J Hum Genet. 74(1):106-20. Epub 2003 Dec 15.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "hgv_pass",
    "name": "PASS",
    "description": "significant transcription factor binding sites from ChIP data",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input is in GFF_ format, and the output is tabular_. (`Dataset missing?`_) .. _GFF: ${static_path}/formatHelp.html#gff .. _tabular: ${static_path}/formatHelp.html#tab .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** PASS (Poisson Approximation for Statistical Significance) detects significant transcription factor binding sites in the genome from ChIP data. This is probably the only peak-calling method that accurately controls the false-positive rate and FDR in ChIP data, which is important given the huge discrepancy in results obtained from different peak-calling algorithms. At the same time, this method achieves a similar or better power than previous methods. ----- **Hints** - ChIP-Seq data: If the data is from ChIP-Seq, you need to convert the ChIP-Seq values into z-scores before using this program. It is also recommended that you group read counts within a neighborhood together, e.g. in tiled windows of 30bp. In this way, the ChIP-Seq data will resemble ChIP-chip data in format. - Choosing window size options: The window size is related to the probe tiling density. For example, if the probes are tiled at every 100bp, then setting the smallest window = 2 and largest window = 6 is appropriate, because the DNA fragment size is around 300-500bp. ----- **Example** - input file:: chr7 Nimblegen ID 40307603 40307652 1.668944 . . . chr7 Nimblegen ID 40307703 40307752 0.8041307 . . . chr7 Nimblegen ID 40307808 40307865 -1.089931 . . . chr7 Nimblegen ID 40307920 40307969 1.055044 . . . chr7 Nimblegen ID 40308005 40308068 2.447853 . . . chr7 Nimblegen ID 40308125 40308174 0.1638694 . . . chr7 Nimblegen ID 40308223 40308275 -0.04796628 . . . chr7 Nimblegen ID 40308318 40308367 0.9335709 . . . chr7 Nimblegen ID 40308526 40308584 0.5143972 . . . chr7 Nimblegen ID 40308611 40308660 -1.089931 . . . etc. In GFF, a value of dot '.' is used to mean \"not applicable\". - output file:: ID Chr Start End WinSz PeakValue # of FPs FDR 1 chr7 40310931 40311266 4 1.663446 0.248817 0.248817 ----- **References** Zhang Y. (2008) Poisson approximation for significance in genome-wide ChIP-chip tiling arrays. Bioinformatics. 24(24):2825-31. Epub 2008 Oct 25. Chen KB, Zhang Y. (2010) A varying threshold method for ChIP peak calling using multiple sources of information. Submitted.",
    "input_formats": [
      "gff"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "hgv_gpass",
    "name": "GPASS",
    "description": "significant single-SNP associations in case-control studies",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input dataset must be in lped_ format, and the output is tabular_. (`Dataset missing?`_) .. _lped: ${static_path}/formatHelp.html#lped .. _tabular: ${static_path}/formatHelp.html#tab .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** GPASS (Genome-wide Poisson Approximation for Statistical Significance) detects significant single-SNP associations in case-control studies at a user-specified FDR. Unlike previous methods, this tool can accurately approximate the genome-wide significance and FDR of SNP associations, while adjusting for millions of multiple comparisons, within seconds or minutes. The program has two main functionalities: 1. Detect significant single-SNP associations at a user-specified false discovery rate (FDR). *Note*: a \"typical\" definition of FDR could be FDR = E(# of false positive SNPs / # of significant SNPs) This definition however is very inappropriate for association mapping, since SNPs are highly correlated. Our FDR is defined differently to account for SNP correlations, and thus will obtain a proper FDR in terms of \"proportion of false positive loci\". 2. Approximate the significance of a list of candidate SNPs, adjusting for multiple comparisons. If you have isolated a few SNPs of interest and want to know their significance in a GWAS, you can supply the GWAS data and let the program specifically test those SNPs. *Also note*: the number of SNPs in a study cannot be both too small and at the same time too clustered in a local region. A few hundreds of SNPs, or tens of SNPs spread in different regions, will be fine. The sample size cannot be too small either; around 100 or more individuals (case + control combined) will be fine. Otherwise use permutation. ----- **Example** - input map file:: 1 rs0 0 738547 1 rs1 0 5597094 1 rs2 0 9424115 etc. - input ped file:: 1 1 0 0 1 1 G G A A A A A A A A A G A A G G G G A A G G G G G G A A A A A G A A G G A G A G A A G G A A G G A A G G A G A A G G A A G G A A A G A G G G A G G G G G A A A G A A G G G G G G G G A G A A A A A A A A 1 1 0 0 1 1 G G A G G G A A A A A G A A G G G G G G A A G G A G A G G G G G A G G G A G A A G G A G G G A A G G G G A G A G G G A G A A A A G G G G A G A G G G A G A A A A A G G G A G G G A G G G G G A A G G A G etc. - output dataset, showing significant SNPs and their p-values and FDR:: #ID chr position Statistics adj-Pvalue FDR rs35 chr1 136606952 4.890849 0.991562 0.682138 rs36 chr1 137748344 4.931934 0.991562 0.795827 rs44 chr2 14423047 7.712832 0.665086 0.218776 etc. ----- **Reference** Zhang Y, Liu JS. (2010) Fast and accurate significance approximation for genome-wide association studies. Submitted.",
    "input_formats": [
      "lped"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "hgv_beam",
    "name": "BEAM",
    "description": "significant single- and multi-locus SNP associations in case-control studies",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": ".. class:: infomark This tool can take a long time to run, depending on the number of SNPs, the sample size, and the number of MCMC steps specified. If you have hundreds of thousands of SNPs, it may take over a day. The main tasks that slow down this tool are searching for interactions and dynamically partitioning the SNPs into blocks. Optimization is certainly possible, but hasn't been done yet. **If your only interest is to detect SNPs with primary effects (i.e., single-SNP associations), please use the GPASS tool instead.** ----- **Dataset formats** The input dataset must be in lped_ format. The output datasets are both tabular_. (`Dataset missing?`_) .. _lped: ${static_path}/formatHelp.html#lped .. _tabular: ${static_path}/formatHelp.html#tabular .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** BEAM (Bayesian Epistasis Association Mapping) uses a Markov Chain Monte Carlo (MCMC) method to infer SNP block structures and detect both single-marker and interaction effects from case-control SNP data. This tool also partitions SNPs into blocks based on linkage disequilibrium (LD). The method utilized is Bayesian, so the outputs are posterior probabilities of association, along with block partitions. An advantage of this method is that it provides uncertainty measures for the associations and block partitions, and it scales well from small to large sample sizes. It is powerful in detecting gene-gene interactions, although slow for large datasets. ----- **Example** - input map file:: 1 rs0 0 738547 1 rs1 0 5597094 1 rs2 0 9424115 etc. - input ped file:: 1 1 0 0 1 1 G G A A A A A A A A A G A A G G G G A A G G G G G G A A A A A G A A G G A G A G A A G G A A G G A A G G A G A A G G A A G G A A A G A G G G A G G G G G A A A G A A G G G G G G G G A G A A A A A A A A 1 1 0 0 1 1 G G A G G G A A A A A G A A G G G G G G A A G G A G A G G G G G A G G G A G A A G G A G G G A A G G G G A G A G G G A G A A A A G G G G A G A G G G A G A A A A A G G G A G G G A G G G G G A A G G A G etc. - first output file, significance.txt:: ID chr position results rs0 chr1 738547 10 20 score= 45.101397 , df= 8 , p= 0.000431 , N=1225 - second output file, posterior.txt:: id: chr position marginal + interaction = total posterior 0: 1 738547 0.0000 + 0.0000 = 0.0000 1: 1 5597094 0.0000 + 0.0000 = 0.0000 2: 1 9424115 0.0000 + 0.0000 = 0.0000 3: 1 13879818 0.0000 + 0.0000 = 0.0000 4: 1 13934751 0.0000 + 0.0000 = 0.0000 5: 1 16803491 0.0000 + 0.0000 = 0.0000 6: 1 17236854 0.0000 + 0.0000 = 0.0000 7: 1 18445387 0.0000 + 0.0000 = 0.0000 8: 1 21222571 0.0000 + 0.0000 = 0.0000 etc. id: chr position block_boundary | allele counts in cases and controls 0: 1 738547 1.000 | 156 93 251 | 169 83 248 1: 1 5597094 1.000 | 323 19 158 | 328 16 156 2: 1 9424115 1.000 | 366 6 128 | 369 11 120 3: 1 13879818 1.000 | 252 31 217 | 278 32 190 4: 1 13934751 1.000 | 246 64 190 | 224 58 218 5: 1 16803491 1.000 | 91 160 249 | 91 174 235 6: 1 17236854 1.000 | 252 43 205 | 249 44 207 7: 1 18445387 1.000 | 205 66 229 | 217 56 227 8: 1 21222571 1.000 | 353 9 138 | 352 8 140 etc. The \"id\" field is an internally used index. ----- **References** Zhang Y, Liu JS. (2007) Bayesian inference of epistatic interactions in case-control studies. Nat Genet. 39(9):1167-73. Epub 2007 Aug 26. Zhang Y, Zhang J, Liu JS. (2010) Block-based bayesian epistasis association mapping with application to WTCCC type 1 diabetes data. Submitted.",
    "input_formats": [
      "lped"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "hgv_lps",
    "name": "LPS",
    "description": "LASSO-Patternsearch algorithm",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input and output datasets are tabular_. The columns are described below. There is a second output dataset (a log) that is in text_ format. (`Dataset missing?`_) .. _tabular: ${static_path}/formatHelp.html#tab .. _text: ${static_path}/formatHelp.html#text .. _Dataset missing?: ${static_path}/formatHelp.html ----- **What it does** The LASSO-Patternsearch algorithm fits your dataset to an L1-regularized logistic regression model. A benefit of using L1-regularization is that it typically yields a weight vector with relatively few non-zero coefficients. For example, say you have a dataset containing M rows (subjects) and N columns (attributes) where one of these N attributes is binary, indicating whether or not the subject has some property of interest P. In simple terms, LPS calculates a weight for each of the other attributes in your dataset. This weight indicates how \"relevant\" that attribute is for predicting whether or not a given subject has property P. The L1-regularization causes most of these weights to be equal to zero, which means LPS will find a \"small\" subset of the remaining N-1 attributes in your dataset that can be used to predict P. In other words, LPS can be used for feature selection. The input dataset is tabular, and must contain a label column which indicates whether or not a given row has property P. In the current version of this tool, P must be encoded using +1 and -1. The Lambda_fac parameter ranges from 0 to 1, and controls how sparse the weight vector will be. At the low end, when Lambda_fac = 0, there will be no regularization. At the high end, when Lambda_fac = 1, there will be \"too much\" regularization, and all of the weights will equal zero. The LPS tool creates two output datasets. The first, called the results file, is a tabular dataset containing one column of weights for each value of the regularization parameter lambda that was tried. The weight columns are in order from left to right by decreasing values of lambda. The first N-1 rows in each column are the weights for the N-1 attributes in your input dataset. The final row is a constant, the intercept. Let **x** be a row from your input dataset and let **b** be a column from the results file. To compute the probability that row **x** has a label value of +1: Probability(row **x** has label value = +1) = 1 / [1 + exp{**x** \\* **b**\\[1..N-1\\] + **b**\\[N\\]}] where **x** \\* **b**\\[1..N-1\\] represents matrix multiplication. The second output dataset, called the log file, is a text file which contains additional data about the fitted L1-regularized logistic regression model. These data include the number of features, the computed value of lambda_max, the actual values of lambda used, the optimal values of the log-likelihood and regularized log-likelihood functions, the number of non-zeros, and the number of iterations. Website: http://pages.cs.wisc.edu/~swright/LPS/ ----- **Example** - input file:: +1 1 0 0 0 0 1 0 1 1 ... +1 1 1 1 0 0 1 0 1 1 ... +1 1 0 1 0 1 0 1 0 1 ... etc. - output results file:: 0 0 0 0 0.025541 etc. - output log file:: Data set has 100 vectors with 50 features. calculateLambdaMax: n=50, m=100, m+=50, m-=50 computed value of lambda_max: 5.0000e-01 lambda=2.96e-02 solution: optimal log-likelihood function value: 6.46e-01 optimal *regularized* log-likelihood function value: 6.79e-01 number of nonzeros at the optimum: 5 number of iterations required: 43 etc.",
    "input_formats": [
      "tabular",
      "integer"
    ],
    "output_formats": [
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "master2pgSnp",
    "name": "MasterVar to pgSnp",
    "description": "Convert from MasterVar to pgSnp format",
    "categories": [
      "Phenotype Association"
    ],
    "version": "1.0.0",
    "help": "**Dataset formats** The input dataset is in the MasterVar_ format provided by the Complete Genomics analysis process (Galaxy considers this to be tabular_, but it must have the columns specified for MasterVar). The output dataset is in pgSnp_ format. (`Dataset missing?`_) .. _Dataset missing?: ./static/formatHelp.html .. _pgSnp: ./static/formatHelp.html#pgSnp .. _MasterVar: ./static/formatHelp.html#mastervar .. _tabular: ./static/formatHelp.html#tab ----- **What it does** This converts a Complete Genomics MasterVar file to pgSnp format, so it can be viewed in browsers or used with the phenotype association and interval operations tools. Positions homozygous for the reference are skipped. ----- **Examples** - input MasterVar file:: 934 2 chr1 41980 41981 hom snp A G G 76 97 dbsnp.86:rs806721 425 1 1 1 2 -170 ERVL-E-int:ERVL:47.4 2 1.17 N 935 2 chr1 41981 42198 hom ref = = = -170 1.17 N 1102 2 chr1 53205 53206 het-ref snp G C G 93 127 dbsnp.100:rs2854676 477 7 30 0 37 -127 2 1.17 N etc. - output:: chr1 41980 41981 G 1 1 76 chr1 51672 51673 C 1 1 53 chr1 52237 52238 G 1 7 63 chr1 53205 53206 C/G 2 7,30 93,127 etc.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "interval"
    ]
  },
  {
    "tool_id": "Summary_Statistics1",
    "name": "Summary Statistics",
    "description": "for any numerical column",
    "categories": [
      "Statistics"
    ],
    "version": "1.1.2",
    "help": ".. class:: warningmark This tool expects input datasets consisting of tab-delimited columns (blank or comment lines beginning with a # character are automatically skipped). .. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert delimiters to TAB* .. class:: infomark **TIP:** Computing summary statistics may throw exceptions if the data value in every line of the columns being summarized is not numerical. If a line is missing a value or contains a non-numerical value in the column being summarized, that line is skipped and the value is not included in the statistical computation. The number of invalid skipped lines is documented in the resulting history item. .. class:: infomark **USING R FUNCTIONS:** Most functions (like *abs*) take only a single expression. *log* can take one or two parameters, like *log(expression,base)* Currently, these R functions are supported: *abs, sign, sqrt, floor, ceiling, trunc, round, signif, exp, log, cos, sin, tan, acos, asin, atan, cosh, sinh, tanh, acosh, asinh, atanh, lgamma, gamma, gammaCody, digamma, trigamma, cumsum, cumprod, cummax, cummin* ----- **Syntax** This tool computes basic summary statistics on a given column, or on a valid expression containing one or more columns. - Columns are referenced with **c** and a **number**. For example, **c1** refers to the first column of a tab-delimited file. - For example: - **log(c5)** calculates the summary statistics for the natural log of column 5 - **(c5 + c6 + c7) / 3** calculates the summary statistics on the average of columns 5-7 - **log(c5,10)** summary statistics of the base 10 log of column 5 - **sqrt(c5+c9)** summary statistics of the square root of column 5 + column 9 ----- **Examples** - Input Dataset:: c1 c2 c3 c4 c5 c6 586 chrX 161416 170887 41108_at 16990 73 chrX 505078 532318 35073_at 1700 595 chrX 1361578 1388460 33665_s_at 1960 74 chrX 1420620 1461919 1185_at 8600 - Summary Statistics on column c6 of the above input dataset:: #sum mean stdev 0% 25% 50% 75% 100% 29250.000 7312.500 7198.636 1700.000 1895.000 5280.000 10697.500 16990.000",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "Count1",
    "name": "Count",
    "description": "occurrences of each record",
    "categories": [
      "Statistics"
    ],
    "version": "1.0.3",
    "help": ".. class:: infomark **TIP:** If your data is not TAB delimited, use *Text Manipulation->Convert* ----- **Syntax** This tool counts occurrences of unique values in selected column(s). - If multiple columns are selected, counting is performed on each unique group of all values in the selected columns. - The first column of the resulting dataset will be the count of unique values in the selected column(s) and will be followed by each value. ----- **Example** - Input file:: chr1 10 100 gene1 chr1 105 200 gene2 chr1 205 300 gene3 chr2 10 100 gene4 chr2 1000 1900 gene5 chr3 15 1656 gene6 chr4 10 1765 gene7 chr4 10 1765 gene8 - Counting unique values in column c1 will result in:: 3 chr1 2 chr2 1 chr3 2 chr4 - Counting unique values in the grouping of columns c2 and c3 will result in:: 2 10 100 2 10 1765 1 1000 1900 1 105 200 1 15 1656 1 205 300",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "vcf_to_maf_customtrack1",
    "name": "VCF to MAF Custom Track",
    "description": "for display at UCSC",
    "categories": [
      "Graph/Display Data"
    ],
    "version": "1.0.1",
    "help": "**What it does** This tool converts a Variant Call Format (VCF) file into a Multiple Alignment Format (MAF) custom track file suitable for display at genome browsers. This file should be used for display purposes only (e.g as a UCSC Custom Track). Performing an analysis using the output created by this tool as input is not recommended; the source VCF file should be used when performing an analysis. *Unknown nucleotides* are represented as '*' as required to allow the display to draw properly; these include e.g. reference bases which appear before a deletion and are not available without querying the original reference sequence. **Example** Starting with a VCF:: ##fileformat=VCFv3.3 ##fileDate=20090805 ##source=myImputationProgramV3.1 ##reference=1000GenomesPilot-NCBI36 ##phasing=partial ##INFO=NS,1,Integer,\"Number of Samples With Data\" ##INFO=DP,1,Integer,\"Total Depth\" ##INFO=AF,-1,Float,\"Allele Frequency\" ##INFO=AA,1,String,\"Ancestral Allele\" ##INFO=DB,0,Flag,\"dbSNP membership, build 129\" ##INFO=H2,0,Flag,\"HapMap2 membership\" ##FILTER=q10,\"Quality below 10\" ##FILTER=s50,\"Less than 50% of samples have data\" ##FORMAT=GT,1,String,\"Genotype\" ##FORMAT=GQ,1,Integer,\"Genotype Quality\" ##FORMAT=DP,1,Integer,\"Read Depth\" ##FORMAT=HQ,2,Integer,\"Haplotype Quality\" #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA00001 NA00002 NA00003 20 14370 rs6054257 G A 29 0 NS=3;DP=14;AF=0.5;DB;H2 GT:GQ:DP:HQ 0|0:48:1:51,51 1|0:48:8:51,51 1/1:43:5:-1,-1 20 17330 . T A 3 q10 NS=3;DP=11;AF=0.017 GT:GQ:DP:HQ 0|0:49:3:58,50 0|1:3:5:65,3 0/0:41:3:-1,-1 20 1110696 rs6040355 A G,T 67 0 NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ 1|2:21:6:23,27 2|1:2:0:18,2 2/2:35:4:-1,-1 20 1230237 . T . 47 0 NS=3;DP=13;AA=T GT:GQ:DP:HQ 0|0:54:7:56,60 0|0:48:4:51,51 0/0:61:2:-1,-1 20 1234567 microsat1 G D4,IGA 50 0 NS=3;DP=9;AA=G GT:GQ:DP 0/1:35:4 0/2:17:2 1/1:40:3 Under the following conditions: **VCF Source type:** *Per Population (file)*, **Name for this population:** *CHB+JPT* Results in the following MAF custom track:: track name=\"Galaxy Custom Track\" visibility=pack ##maf version=1 a score=0 s hg18.chr20 14369 1 + 14370 G s CHB+JPT_1.1 0 1 + 1 A a score=0 s hg18.chr20 17329 1 + 17330 T s CHB+JPT_1.2 0 1 + 1 A a score=0 s hg18.chr20 1110695 1 + 1110696 A s CHB+JPT_1.3 0 1 + 1 G s CHB+JPT_2.3 0 1 + 1 T a score=0 s hg18.chr20 1230236 1 + 1230237 T s CHB+JPT_1.4 0 1 + 1 . a score=0 s hg18.chr20 1234565 5 + 1234572 *G--*** s CHB+JPT_1.5 0 1 + 1 *------ s CHB+JPT_2.5 0 7 + 7 *GGA***",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "mafcustomtrack"
    ]
  },
  {
    "tool_id": "interactive_tool_jupyter_notebook",
    "name": "Interactive JupyterLab Notebook",
    "description": "",
    "categories": [
      "Interactive Tools"
    ],
    "version": "1.0.1",
    "help": "Welcome to the **JupyTool**! Here you can create, run, and share custom Galaxy tools based upon Jupyter Notebooks. The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more. Galaxy offers you to use Jupyter Notebooks directly in Galaxy accessing and interacting with Galaxy datasets as you like. A very common use-case is to do the heavy lifting and data reduction steps in Galaxy and the plotting and more `interactive` part on smaller datasets in Jupyter. You can start with a new Jupyter notebook from scratch or load an already existing one, e.g. from your colleague and execute it on your dataset. You can specify any number of user-defined inputs using the repeat input, providing `name` value, selecting the type of input, and then providing values. You can make the JupyTool reusable in a workflow, by allowing the user to specify input values for the defined input blocks. Inputs can be accessed by `name` from the automatically provided `GALAXY_INPUTS` dictionary. Outputs can be written automatically to the user's history by writing to the `outputs` directory for one individual file or to the `outputs/collection` directory for multiple files. Using collection tools, you can parse out the individual elements from the collection, as needed. For backwards compatibility, you can import data into the notebook via a predefined `get()` function and write results back to Galaxy with a `put()` function.",
    "input_formats": [
      "ipynb",
      "data"
    ],
    "output_formats": [
      "ipynb",
      "data"
    ]
  },
  {
    "tool_id": "interactive_tool_panoply",
    "name": "Panoply",
    "description": "interative plotting tool for geo-referenced data",
    "categories": [
      "Interactive Tools"
    ],
    "version": "4.5.1",
    "help": "`Panoply `_ plots geo-referenced and other arrays from netCDF, HDF, GRIB, and other datasets.",
    "input_formats": [
      "netcdf",
      "h5"
    ],
    "output_formats": []
  },
  {
    "tool_id": "interactive_tool_phinch",
    "name": "Phinch Visualisation",
    "description": "",
    "categories": [
      "Interactive Tools"
    ],
    "version": "0.1",
    "help": "Interactive tool for visualising Biom data.",
    "input_formats": [
      "biom1"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "interactive_tool_pavian",
    "name": "Pavian",
    "description": "Interactive analysis of metagenomics data",
    "categories": [
      "Interactive Tools"
    ],
    "version": "1.0",
    "help": "`Pavian `_ is a interactive browser application for analyzing and visualization metagenomics classification results from classifiers such as Kraken, KrakenUniq, Kraken 2, Centrifuge and MetaPhlAn. Pavian also provides an alignment viewer for validation of matches to a particular genome. pavian natively supports the Kraken and MetaPhlAn-style report formats. In extension, you can use Centrifuge results by running centrifuge-report on Centrifuge output files, and Kaiju results by running kraken-report on Kaiju output files.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "interactive_tool_qiskit_jupyter_notebook",
    "name": "Qiskit Jupyter notebook",
    "description": "interactive tool",
    "categories": [
      "Interactive Tools"
    ],
    "version": "0.2",
    "help": "Welcome to the **Qiskit JupyTool**! This tool incorporates the entire Qiskit stack, including tutorials and supplemental resources. This tool is an extension of the standard **JupyTool**, so a full functionality of Jupyter lab is also included. You can create, run, and share custom Galaxy tools based upon Jupyter Notebooks. Qiskit is a Python based, open-source software stack for quantum computing on IBM quantum systems. When run, the Jupyter lab instance includes directories for many resources and relevant tutorials, including the introductory materials for building quantum circuits, to using quantum algorithms like Variational Quantum Eigensolvers (VQE), Quantum Approximate Optimization Algorithm (QAOA), as well as Grover's algorithm. The associated docker image contains most relevant Qiskit modules including: qiskit-aer, qiskit-dynamics, qiskit-experiments, qiskit-finance, qiskit-ibm-experiment, qiskit-ibm-provider, qiskit-ibm-runtime, qiskit-ibmq-provider, qiskit-machine-learning, qiskit-nature, qiskit-optimization, qiskit_research, qiskit-terra, qiskit-xyz2pdb. So, this tool provides the necessary resources for beginners and experienced users of Qiskit alike. Users can readily run their scripts with quantum simulators on the backend (qasm, aer, etc.), or run on actual quantum hardware. For the latter, users need to have an account with IBM quantum lab and pass their signature API token by pasting it in their user preferences on this Galaxy instance (User -> preferences -> manage information). Instructions for specifying the quantum backend can be found at https://qiskit.org/ecosystem/ibm-runtime/how_to/backends.html. The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more. Galaxy offers you the use of Jupyter Notebooks directly in Galaxy accessing and interacting with Galaxy datasets as you like. A very common use-case is to do the heavy lifting and data reduction steps in Galaxy and the plotting and more `interactive` part on smaller datasets in Jupyter. You can start with a new Jupyter notebook from scratch or load an already existing one, e.g. from your colleague and execute it on your dataset. You can specify any number of user-defined inputs using the repeat input, providing `name` value, selecting the type of input, and then providing values. You can make the Qiskit JupyTool reusable in a workflow, by allowing the user to specify input values for the defined input blocks. Inputs can be accessed by `name` from the automatically provided `GALAXY_INPUTS` dictionary. Outputs can be written automatically to the user's history by writing to the `outputs` directory for one individual file or to the `outputs/collection` directory for multiple files. Using collection tools, you can parse out the individual elements from the collection, as needed. For backwards compatibility, you can import data into the notebook via a predefined `get()` function and write results back to Galaxy with a `put()` function. .. image:: https://upload.wikimedia.org/wikipedia/commons/5/51/Qiskit-Logo.svg",
    "input_formats": [
      "ipynb",
      "data"
    ],
    "output_formats": [
      "ipynb",
      "data"
    ]
  },
  {
    "tool_id": "interactive_tool_blobtoolkit",
    "name": "Interactive BlobToolKit",
    "description": "genome assembly QC viewer",
    "categories": [
      "Interactive Tools"
    ],
    "version": "4.1.0+galaxy0",
    "help": "BlobToolKit is a software suite to aid researchers in identifying and isolating non-target data in draft and publicly available genome assemblies. It can be used to process assembly, read and analysis files for fully reproducible interactive exploration in the browser-based Viewer. BlobToolKit can be used during assembly to filter non-target DNA, helping researchers produce assemblies with high biological credibility.",
    "input_formats": [
      "tgz",
      "tar"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "interactive_tool_phyloseq",
    "name": "Phyloseq",
    "description": "Explore microbiome profiles",
    "categories": [
      "Interactive Tools"
    ],
    "version": "1.0.0",
    "help": "**Overview** The analysis of microbial communities brings many challenges: the integration of many different types of data with methods from ecology, genetics, phylogenetics, network analysis, visualization and testing. The data itself may originate from widely different sources, such as the microbiomes of humans, soils, surface and ocean waters, wastewater treatment plants, industrial facilities, and so on; and as a result, these varied sample types may have very different forms and scales of related data that is extremely dependent upon the experiment and its question(s). The phyloseq package is a tool to import, store, analyze, and graphically display complex phylogenetic sequencing data that has already been clustered into Operational Taxonomic Units (OTUs), especially when there is associated sample data, phylogenetic tree, and/or taxonomic assignment of the OTUs. Full documentation: https://joey711.github.io/phyloseq/ **Shiny App** This IT uses https://github.com/joey711/shiny-phyloseq as the basis app but added some features that allow loading phyloseq objects dynamically from the Galaxy Input. The shiny app allows to interactively visualize and filer amplicon data: * Filter * Alpha Diversity * Network plots * d3Network plots * Ordination plots * Heatmaps * Tree plots * Scatter pots * Bar charts Unfortunately, the following features of the app are currently defunct: provenance.",
    "input_formats": [
      "phyloseq"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.13",
    "name": "Samtools depth",
    "description": "compute the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "**What it does** Computes the depth at each position or region using the ``samtools depth`` command. The output is a tabular file, with one line for each base of each reference with any coverage (bases with no coverage may not appear). The first column is the reference name, the second column is the reference position, and then there is one column for each SAM/BAM file giving the coverage depth at that position.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.13",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.13",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.13",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.13",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.13+galaxy1",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13+galaxy1",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. ## Filtering by Tag ** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.13+galaxy1",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13+galaxy1",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.13+galaxy2",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13+galaxy2",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. ## Filtering by Tag ** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.13",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.13",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_sort/samtools_sort/2.0.4",
    "name": "Samtools sort",
    "description": "order of storing aligned sequences",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Sort alignments by leftmost coordinates, or by read name when -n is used. An appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary. **Ordering Rules** The following rules are used for ordering records. If option -t is in use, records are first sorted by the value of the given alignment tag, and then by position or name (if using -n). For example, -t RG will make read group the primary sort key. The rules for ordering by tag are: - Records that do not have the tag are sorted before ones that do. - If the types of the tags are different, they will be sorted so that single character tags (type A) come before array tags (type B), then string tags (types H and Z), then numeric tags (types f and i). - Numeric tags (types f and i) are compared by value. Note that comparisons of floating-point values are subject to issues of rounding and precision. - String tags (types H and Z) are compared based on the binary contents of the tag using the C strcmp(3) function. - Character tags (type A) are compared by binary character value. - No attempt is made to compare tags of other types  notably type B array values will not be compared. When the -n option is present, records are sorted by name. Names are compared so as to give a natural ordering  i.e. sections consisting of digits are compared numerically while all other sections are compared based on their binary representation. This means a1 will come before b1 and a9 will come before a10. Records with the same name will be ordered according to the values of the READ1 and READ2 flags (see flags). When the -n option is not present, reads are sorted by reference (according to the order of the @SQ header records), then by position in the reference, and then by the REVERSE flag. This has now been removed. The previous out.prefix argument (and -f option, if any) should be changed to an appropriate combination of -T PREFIX and -o FILE. The previous -o option should be removed, as output defaults to standard output. When the -M (minash collation) option is present, then samtools sort groups unmapped reads with similar sequence together. This can sometimes significantly reduce the file size.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_mpileup/samtools_mpileup/2.1.6",
    "name": "Samtools mpileup",
    "description": "multi-way pileup of variants",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.6",
    "help": "**What it does** Generate pileup for one or multiple BAM files. Alignment records are grouped by sample (SM) identifiers in @RG header lines. If sample identifiers are absent, each input file is regarded as one sample. Generation of VCF and BCF output, is deprecated and not available in the Galaxy tool. Please use bcftools mpileup for this instead. In the pileup format (without -u or -g), each line represents a genomic position, consisting of chromosome name, 1-based coordinate, reference base, the number of reads covering the site, read bases, base qualities and alignment mapping qualities. Information on match, mismatch, indel, strand, mapping quality and start and end of a read are all encoded at the read base column. At this column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, a '>' or ' BAQ is turned on when a reference file is supplied using the -f option. To disable it, use the -B option. It is possible to store pre-calculated BAQ values in a SAM BQ:Z tag. Samtools mpileup will use the precalculated values if it finds them. The -E option can be used to make it ignore the contents of the BQ:Z tag and force it to recalculate the BAQ scores by making a new alignment.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz",
      "bed",
      "txt"
    ],
    "output_formats": [
      "pileup"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_flagstat/samtools_flagstat/2.0.4",
    "name": "Samtools flagstat",
    "description": "tabulate descriptive stats for BAM datset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Uses ``samtools flagstat`` command to print descriptive information for a BAM dataset. Here is an example of such information:: 200 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 25 + 0 mapped (12.50%:nan%) 200 + 0 paired in sequencing 100 + 0 read1 100 + 0 read2 0 + 0 properly paired (0.00%:nan%) 0 + 0 with itself and mate mapped 25 + 0 singletons (12.50%:nan%) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) The results of samtools flagstat can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bam_to_sam/bam_to_sam/2.0.2",
    "name": "BAM-to-SAM",
    "description": "convert BAM to SAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.2",
    "help": "**What it does** Converts BAM dataset to SAM using the ``samtools view`` command.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "sam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_idxstats/samtools_idxstats/2.0.4",
    "name": "Samtools idxstats",
    "description": "reports stats of the BAM index file",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Runs the ``samtools idxstats`` command. It retrieves and prints stats in the index file. Input is a sorted and indexed BAM file, the output is tabular with four columns (one row per reference sequence plus a final line for unmapped reads):: Column Description ------ ----------------------------- 1 Reference sequence identifier 2 Reference sequence length 3 Number of mapped reads 4 Number of placed but unmapped reads (typically unmapped partners of mapped reads) ------ **Example** output from a *de novo* assembly:: contig_1 170035 98397 0 contig_2 403835 199564 0 contig_3 553102 288189 0 ... ... ... ... contig_603 653 50 0 contig_604 214 6 0 \\* 0 0 50320 In this example there were 604 contigs, each with one line in the output table, plus the final row (labelled with an asterisk) representing 50320 unmapped reads. In this BAM file, the final column was otherwise zero. The results of samtools ixdstats can be visualized with MultiQC. ------ Peter J.A. Cock (2013), `Galaxy wrapper `_ for the samtools idxstats command",
    "input_formats": [
      "bam",
      "cram"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/sam_to_bam/sam_to_bam/2.1.2",
    "name": "SAM-to-BAM",
    "description": "convert SAM to BAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.2",
    "help": "**What it does** Converts SAM dataset into its binary, BAM, representation using the ``samtools view`` and ``sort`` commands.",
    "input_formats": [
      "sam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_calmd/samtools_calmd/2.0.3",
    "name": "Samtools calmd",
    "description": "recalculate MD/NM tags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.3",
    "help": "**What it does** Generates the MD tag using the ``samtools calmd`` command. If the MD tag (see SAM format reference below for explanation of SAM/BAM tags) is already present, this command will give a warning if the MD tag generated is different from the existing tag. Optionally, also generates the BQ tag to encode base alignment qualities, caps the mapping quality of poorly mapping reads, and modifies read sequences replacing bases matching the reference with ``=``. Outputs a BAM file. ----- **SAM/BAM tags written by this tool** From the SAM format tag specification:: MD (string) String for mismatching positions. Regex : [0-9]+(([A-Z]|\\^[A-Z]+)[0-9]+)*7 NM (integer) Edit distance to the reference, including ambiguous bases but excluding clipping BQ (string) String of offsets to base alignment quality (BAQ), of the same length as the read sequence. At the i-th read base, BAQ i = Q i  (BQ i  64) where Q i is the i-th base quality. See references for more information about SAM format tags.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_bedcov/samtools_bedcov/2.0.3",
    "name": "Samtools bedcov",
    "description": "calculate read depth for a set of genomic intervals",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.3",
    "help": "**What it does** Calculates read depth for regions listed in a BED dataset using ``samtools bedcov`` command:: samtools bedcov [INPUT BED] [INPUT BAM1] ... [INPUT BAMn] > [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_split/samtools_split/1.15.1+galaxy0",
    "name": "Samtools split",
    "description": "BAM dataset on readgroups",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Splits BAM files on readgroups. This tool is based on ``samtools split`` command. It will generate multiple output datasets for each redagroup from the input dataset.",
    "input_formats": [
      "bam",
      "sam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.4",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/2.0.2",
    "name": "Slice",
    "description": "BAM by genomic regions",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.2",
    "help": "**What it does** Allows to restrict (slice) input BAM dataset to a list of intervals defined in a BED file, individual chromosomes, or manually set list of coordinates. BED datasets can be obtained from **Get Data -> UCSC Main**. This tool is based on ``samtools view`` command. @no-chrom-options@",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_reheader/samtools_reheader/2.0.2",
    "name": "Samtools reheader",
    "description": "copy SAM/BAM header between datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.2",
    "help": "**What it does** Generates a new BAM dataset with the contents of *target* dataset, but the header of *source* dataset using the ``samtools reheader`` command.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_split/bamtools_split/2.5.1+galaxy0",
    "name": "Split",
    "description": "BAM datasets on variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.1+galaxy0",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- .. class:: warningmark **DANGER: Multiple Outputs** As described below, splitting a BAM dataset(s) on reference name or a tag value can produce very large numbers of outputs. Read below and know what you are doing. ----- **How it works** The following options can be specified via \"**Split BAM dataset(s) by**\" dropdown:: Mapping status (-mapped) split mapped/unmapped and generate two output files named (MAPPED) and (UNMAPPED) containing mapped and unmapped reads, respectively. Pairing status (-paired) split single-end/paired-end alignments and generate two output files named (SINGLE_END) and (PAIRED_END) containing paired and unpaired reads, respectively. Reference name (-reference) split alignments by reference name. In cases of unfinished genomes with very large number of reference sequences (scaffolds) it can generate thousands (if not millions) of output datasets. Specific tag (-tag) split alignments based on all values of TAG encountered. Choosing this option from the menu will allow you to enter the tag name. As was the case with the reference splitting above, this option can produce very large number of outputs if a tag has a large number of unique values. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/2.5.1+galaxy0",
    "name": "Convert, Merge, Randomize",
    "description": "BAM datasets and perform other transformations",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.1+galaxy0",
    "help": "**What is does** BAMTools is a collection of utilities for manipulation on BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). This Galaxy implementation of BAMTools utilities includes seven utilities - Convert, Count, Coverage, Header, Merge, Random, and Revert - decsribed in detail below. ----- **Convert** Converts BAM dataset(s) into BED, FASTA, FASTQ, JSON, Pileup, SAM, or YAML formats. Note that the conversion to the pileup format requires providing a reference sequence either cashed at this Galaxy instance, or provided by you as a FASTA dataset from History. ----- **Count** Counts a number of alignments in a BAM dataset(s). ----- **Coverage** Prints per-base coverage for a BAM dataset. ----- **Header** Prints header from a BAM dataset(s). ------ **Merge** Merges multiple BAM datasets into a single one. Obviously, you need to select multiple BAMs as input, which is done by pressing the \"**Add new BAM dataset(s) to filter**\" button. ------ **Random** Grabs a specified number of random lines from BAM dataset(s). ------ **Revert** Removes duplicate marks and restores original (non-recalibrated) base qualities. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam",
      "fasta"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/2.5.1+galaxy0",
    "name": "Filter",
    "description": "BAM datasets on a variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.1+galaxy0",
    "help": "**What is does** BAMTools filter is a very powerful utility to perform complex filtering of BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** The tool use logic relies on the three concepts: (1) input BAM, (2) groups, and (3) filters. *Input BAM(s)* The input BAM is self-explanatory. This is the dataset you will be filtering. The tool can accept just one or multiple BAM files. To filter on multiple BAMs just add them by clicking **Add new BAM dataset(s) to filter** *Conditions and Filters* Conditions for filtering BAM files can be arranged in **Groups and Filters**. While it can be confusing at first this is what gives ultimate power to this tools. So try to look at the examples we are supplying below. ----- **Example 1. Using a single filter** When filtering on a single condition there is no need to worry about filters and conditions. Just choose a filter from the **Select BAM property to filter on:** dropdown and enter a value (or click a checkbox for binary filters). For example, for retaining reads with mapping quality of at least 20 one would set the tool interface as shown below: .. image:: single-filter.png ----- **Example 2. Using multiple filters** Now suppose one needs to extract reads that (1) have mapping quality of at least 20, (2) contain at least 1 mismatch, and (3) are mapping onto forward strand only. To do so we will use three filters as shown below (multiple filters are added to the interface by clicking on the **Add new Filter** button): .. image:: multiple-filters.png In this case (you can see that the three filters are grouped within a single Condition - **Condition 1**) the filter too use logical **AND** to perform filtering. In other words only reads that (1) have mapping quality of at least 20 **AND** (2) contain at least 1 mismatch **AND** are mapping onto forward strand will be returned in this example. ----- **Example 3. Complex filtering with multiple conditions** Suppose now you would like to select **either** reads that (**1**) have (*1.1*) no mismatches and (*1.2*) are on the forward strand **OR** (**2**) reads that have (*2.1*) at least one mismatch and (*2.2*) are on the reverse strand. In this scenario we have to set up two conditions: (**1**) and (**2**) each with two filters: *1.1* and *1.2* as well as *2.1* and *2.2*. The following screenshot expalins how this can be done: .. image:: complex-filters.png ----- **Example 4. Even more complex filtering with Rules** In the above example we have used two conditions (Condition 1 and Condition 2). Using multiple conditions allows to combine them and a variety of ways to enable even more powerful filtering. For example, suppose get all reads that (**1**) do NOT map to mitochondria and either (**2**) have mapping quality over 20, or (**3**) are in properly mapped pairs. The logical rule to enable such filtering will look like this:: !(1) & (2 | 3) Here, numbers 1, 2, and 3 represent conditions. The following screenshot illustrates how to do this in Galaxy: .. image:: rule.png There are three conditions here, each with a single filter. A text entry area that can be opened by clicking on the **Would you like to set rules?** checkbox enables you to enter a rule. Here numbers correspond to numbers of conditions as they are shown in the interface. E.g., 1 corresponds to condition 1, 2 to condition 2 and so on... In human language this means:: NOT condition 1 AND (condition 2 OR condition 3) ----- **JSON script file** This tool produces two outputs. One of the them is a BAM file containing filtered reads. The other is a JSONified script. It can help you to see how your instructions are sent to BAMTools. For instance, the example 4 looks like this in the JSON form:: { \"filters\": [ { \"id\": \"1\", \"tag\":\"NM:=0\", \"isReverseStrand\":\"false\" }, { \"id\": \"2\", \"tag\":\"NM:>0\", \"isReverseStrand\":\"true\" } ] } ----- **More information** .. class:: infomark Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.15.1+galaxy0",
    "name": "Samtools depth",
    "description": "compute the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Computes the depth at each position or region using the ``samtools depth`` command. The output is a tabular file, with one line for each base of each reference with any coverage (bases with no coverage may not appear). The first column is the reference name, the second column is the reference position, and then there is one column for each SAM/BAM file giving the coverage depth at that position.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.15.1+galaxy0",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.15.1+galaxy0",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.15.1+galaxy0",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.15.1+galaxy0",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_phase/samtools_phase/2.0.2",
    "name": "Samtools phase",
    "description": "call and phase heterozygous SNPs",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.2",
    "help": "**What it does** Call and phase heterozygous SNPs.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.15.1+galaxy0",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. ## Filtering by Tag ** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.15.1+galaxy0",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy0",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/lldelisle/revertr2orientationinbam/revertR2orientationInBam/0.0.2",
    "name": "revertR2orientationInBam",
    "description": "Revert the mapped orientation of R2 mates in a bam.",
    "categories": [
      "SAM/BAM"
    ],
    "version": "0.0.2",
    "help": "This tool is very useful when you have paired-end stranded RNA-seq. Using this tool prior to a bedtools genome coverage allow to have strand specific coverage using both mates. It uses samtools to convert input to sam format and then awk to modify the flag \"reverse strand\" for the second mate of pairs.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.3",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.3",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_split/bamtools_split/2.5.2+galaxy0",
    "name": "Split",
    "description": "BAM datasets on variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy0",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- .. class:: warningmark **DANGER: Multiple Outputs** As described below, splitting a BAM dataset(s) on reference name or a tag value can produce very large numbers of outputs. Read below and know what you are doing. ----- **How it works** The following options can be specified via \"**Split BAM dataset(s) by**\" dropdown:: Mapping status (-mapped) split mapped/unmapped and generate two output files named (MAPPED) and (UNMAPPED) containing mapped and unmapped reads, respectively. Pairing status (-paired) split single-end/paired-end alignments and generate two output files named (SINGLE_END) and (PAIRED_END) containing paired and unpaired reads, respectively. Reference name (-reference) split alignments by reference name. In cases of unfinished genomes with very large number of reference sequences (scaffolds) it can generate thousands (if not millions) of output datasets. Specific tag (-tag) split alignments based on all values of TAG encountered. Choosing this option from the menu will allow you to enter the tag name. As was the case with the reference splitting above, this option can produce very large number of outputs if a tag has a large number of unique values. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/2.5.2+galaxy1",
    "name": "Operate on and transform BAM",
    "description": "datasets in various ways",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools is a collection of utilities for manipulation on BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). This Galaxy implementation of BAMTools utilities includes seven utilities - Convert, Count, Coverage, Header, Merge, Random, and Revert - decsribed in detail below. ----- **Convert** Converts BAM dataset(s) into BED, FASTA, FASTQ, JSON, Pileup, SAM, or YAML formats. Note that the conversion to the pileup format requires providing a reference sequence either cached on this Galaxy instance, or provided by you as a FASTA dataset from History. ----- **Count** Counts the number of alignments in a BAM dataset(s). ----- **Coverage** Prints per-base coverage for a BAM dataset. ----- **Header** Prints the header of a BAM dataset. ------ **Merge** Merges multiple BAM datasets into a single one. ------ **Random** Grabs a specified number of random lines from BAM dataset(s). ------ **Revert** Removes duplicate marks and restores original (non-recalibrated) base qualities. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam",
      "fasta"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/2.5.2+galaxy1",
    "name": "Filter BAM",
    "description": "datasets on a variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools filter is a very powerful utility to perform complex filtering of BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** The tool use logic relies on the three concepts: (1) input BAM, (2) groups, and (3) filters. *Input BAM(s)* The input BAM is self-explanatory. This is the dataset you will be filtering. The tool can accept just one or multiple BAM files. To filter on multiple BAMs just add them by clicking **Add new BAM dataset(s) to filter** *Conditions and Filters* Conditions for filtering BAM files can be arranged in **Groups and Filters**. While it can be confusing at first this is what gives ultimate power to this tools. So try to look at the examples we are supplying below. ----- **Example 1. Using a single filter** When filtering on a single condition there is no need to worry about filters and conditions. Just choose a filter from the **Select BAM property to filter on:** dropdown and enter a value (or click a checkbox for binary filters). For example, for retaining reads with mapping quality of at least 20 one would set the tool interface as shown below: .. image:: single-filter.png ----- **Example 2. Using multiple filters** Now suppose one needs to extract reads that (1) have mapping quality of at least 20, (2) contain at least 1 mismatch, and (3) are mapping onto forward strand only. To do so we will use three filters as shown below (multiple filters are added to the interface by clicking on the **Add new Filter** button): .. image:: multiple-filters.png In this case (you can see that the three filters are grouped within a single Condition - **Condition 1**) the filter too use logical **AND** to perform filtering. In other words only reads that (1) have mapping quality of at least 20 **AND** (2) contain at least 1 mismatch **AND** are mapping onto forward strand will be returned in this example. ----- **Example 3. Complex filtering with multiple conditions** Suppose now you would like to select **either** reads that (**1**) have (*1.1*) no mismatches and (*1.2*) are on the forward strand **OR** (**2**) reads that have (*2.1*) at least one mismatch and (*2.2*) are on the reverse strand. In this scenario we have to set up two conditions: (**1**) and (**2**) each with two filters: *1.1* and *1.2* as well as *2.1* and *2.2*. The following screenshot expalins how this can be done: .. image:: complex-filters.png ----- **Example 4. Even more complex filtering with Rules** In the above example we have used two conditions (Condition 1 and Condition 2). Using multiple conditions allows to combine them and a variety of ways to enable even more powerful filtering. For example, suppose get all reads that (**1**) do NOT map to mitochondria and either (**2**) have mapping quality over 20, or (**3**) are in properly mapped pairs. The logical rule to enable such filtering will look like this:: !(1) & (2 | 3) Here, numbers 1, 2, and 3 represent conditions. The following screenshot illustrates how to do this in Galaxy: .. image:: rule.png There are three conditions here, each with a single filter. A text entry area that can be opened by clicking on the **Would you like to set rules?** checkbox enables you to enter a rule. Here numbers correspond to numbers of conditions as they are shown in the interface. E.g., 1 corresponds to condition 1, 2 to condition 2 and so on... In human language this means:: NOT condition 1 AND (condition 2 OR condition 3) ----- **JSON script file** This tool produces two outputs. One of the them is a BAM file containing filtered reads. The other is a JSONified script. It can help you to see how your instructions are sent to BAMTools. For instance, the example 4 looks like this in the JSON form:: { \"filters\": [ { \"id\": \"1\", \"tag\":\"NM:=0\", \"isReverseStrand\":\"false\" }, { \"id\": \"2\", \"tag\":\"NM:>0\", \"isReverseStrand\":\"true\" } ] } ----- **More information** .. class:: infomark Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.15.1+galaxy1",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy1",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_mapped/bamtools_split_mapped/2.5.2+galaxy1",
    "name": "Split BAM by reads mapping status",
    "description": "into a mapped and an unmapped dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Splits the input BAM file into 2 output files containing mapped and unmapped reads, respectively. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_paired/bamtools_split_paired/2.5.2+galaxy1",
    "name": "Split BAM into paired- and single-end",
    "description": "reads datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Splits the input BAM file into 2 output files named containing single_end and paired_end reads, respectively. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_ref/bamtools_split_ref/2.5.2+galaxy1",
    "name": "Split BAM by reference",
    "description": "into a dataset list collection",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on the BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Split alignments by reference name into a dataset list collection. The collection will be in the same order as the input BAM references and will consist of as many elements as there are references selected or listed in the input BAM header. .. class:: warningmark In cases of unfinished genomes with very large number of reference sequences (scaffolds) this could generate a collection with thousands (if not millions) of elements. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_tag/bamtools_split_tag/2.5.2+galaxy1",
    "name": "Split BAM by read tag value",
    "description": "into a dataset list collection",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy1",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on the BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Split alignments by tag name into a dataset list collection. .. class:: warningmark This can generate a collection with a huge number of elements depending on the number of distinct values of the TAG. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_sort/samtools_sort/2.0.5",
    "name": "Samtools sort",
    "description": "order of storing aligned sequences",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Sort alignments by leftmost coordinates, or by read name when -n is used. An appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary. **Ordering Rules** The following rules are used for ordering records. If option -t is in use, records are first sorted by the value of the given alignment tag, and then by position or name (if using -n). For example, -t RG will make read group the primary sort key. The rules for ordering by tag are: - Records that do not have the tag are sorted before ones that do. - If the types of the tags are different, they will be sorted so that single character tags (type A) come before array tags (type B), then string tags (types H and Z), then numeric tags (types f and i). - Numeric tags (types f and i) are compared by value. Note that comparisons of floating-point values are subject to issues of rounding and precision. - String tags (types H and Z) are compared based on the binary contents of the tag using the C strcmp(3) function. - Character tags (type A) are compared by binary character value. - No attempt is made to compare tags of other types  notably type B array values will not be compared. When the -n option is present, records are sorted by name. Names are compared so as to give a natural ordering  i.e. sections consisting of digits are compared numerically while all other sections are compared based on their binary representation. This means a1 will come before b1 and a9 will come before a10. Records with the same name will be ordered according to the values of the READ1 and READ2 flags (see flags). When the -n option is not present, reads are sorted by reference (according to the order of the @SQ header records), then by position in the reference, and then by the REVERSE flag. This has now been removed. The previous out.prefix argument (and -f option, if any) should be changed to an appropriate combination of -T PREFIX and -o FILE. The previous -o option should be removed, as output defaults to standard output. When the -M (minash collation) option is present, then samtools sort groups unmapped reads with similar sequence together. This can sometimes significantly reduce the file size.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_mpileup/samtools_mpileup/2.1.7",
    "name": "Samtools mpileup",
    "description": "multi-way pileup of variants",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.7",
    "help": "**What it does** Generate pileup for one or multiple BAM files. Alignment records are grouped by sample (SM) identifiers in @RG header lines. If sample identifiers are absent, each input file is regarded as one sample. Generation of VCF and BCF output, is deprecated and not available in the Galaxy tool. Please use bcftools mpileup for this instead. In the pileup format (without -u or -g), each line represents a genomic position, consisting of chromosome name, 1-based coordinate, reference base, the number of reads covering the site, read bases, base qualities and alignment mapping qualities. Information on match, mismatch, indel, strand, mapping quality and start and end of a read are all encoded at the read base column. At this column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, a '>' or ' BAQ is turned on when a reference file is supplied using the -f option. To disable it, use the -B option. It is possible to store pre-calculated BAQ values in a SAM BQ:Z tag. Samtools mpileup will use the precalculated values if it finds them. The -E option can be used to make it ignore the contents of the BQ:Z tag and force it to recalculate the BAQ scores by making a new alignment.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz",
      "bed",
      "txt"
    ],
    "output_formats": [
      "pileup"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_flagstat/samtools_flagstat/2.0.5",
    "name": "Samtools flagstat",
    "description": "tabulate descriptive stats for BAM datset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Uses ``samtools flagstat`` command to print descriptive information for a BAM dataset. Here is an example of such information:: 200 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 25 + 0 mapped (12.50%:nan%) 200 + 0 paired in sequencing 100 + 0 read1 100 + 0 read2 0 + 0 properly paired (0.00%:nan%) 0 + 0 with itself and mate mapped 25 + 0 singletons (12.50%:nan%) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) The results of samtools flagstat can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bam_to_sam/bam_to_sam/2.0.4",
    "name": "BAM-to-SAM",
    "description": "convert BAM to SAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Converts BAM dataset to SAM using the ``samtools view`` command.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "sam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_idxstats/samtools_idxstats/2.0.5",
    "name": "Samtools idxstats",
    "description": "reports stats of the BAM index file",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Runs the ``samtools idxstats`` command. It retrieves and prints stats in the index file. Input is a sorted and indexed BAM file, the output is tabular with four columns (one row per reference sequence plus a final line for unmapped reads):: Column Description ------ ----------------------------- 1 Reference sequence identifier 2 Reference sequence length 3 Number of mapped reads 4 Number of placed but unmapped reads (typically unmapped partners of mapped reads) ------ **Example** output from a *de novo* assembly:: contig_1 170035 98397 0 contig_2 403835 199564 0 contig_3 553102 288189 0 ... ... ... ... contig_603 653 50 0 contig_604 214 6 0 \\* 0 0 50320 In this example there were 604 contigs, each with one line in the output table, plus the final row (labelled with an asterisk) representing 50320 unmapped reads. In this BAM file, the final column was otherwise zero. The results of samtools ixdstats can be visualized with MultiQC. ------ Peter J.A. Cock (2013), `Galaxy wrapper `_ for the samtools idxstats command",
    "input_formats": [
      "bam",
      "cram"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_calmd/samtools_calmd/2.0.4",
    "name": "Samtools calmd",
    "description": "recalculate MD/NM tags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Generates the MD tag using the ``samtools calmd`` command. If the MD tag (see SAM format reference below for explanation of SAM/BAM tags) is already present, this command will give a warning if the MD tag generated is different from the existing tag. Optionally, also generates the BQ tag to encode base alignment qualities, caps the mapping quality of poorly mapping reads, and modifies read sequences replacing bases matching the reference with ``=``. Outputs a BAM file. ----- **SAM/BAM tags written by this tool** From the SAM format tag specification:: MD (string) String for mismatching positions. Regex : [0-9]+(([A-Z]|\\^[A-Z]+)[0-9]+)*7 NM (integer) Edit distance to the reference, including ambiguous bases but excluding clipping BQ (string) String of offsets to base alignment quality (BAQ), of the same length as the read sequence. At the i-th read base, BAQ i = Q i  (BQ i  64) where Q i is the i-th base quality. See references for more information about SAM format tags.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_bedcov/samtools_bedcov/2.0.4",
    "name": "Samtools bedcov",
    "description": "calculate read depth for a set of genomic intervals",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Calculates read depth for regions listed in a BED dataset using ``samtools bedcov`` command:: samtools bedcov [INPUT BED] [INPUT BAM1] ... [INPUT BAMn] > [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_split/samtools_split/1.15.1+galaxy2",
    "name": "Samtools split",
    "description": "BAM dataset on readgroups",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Splits BAM files on readgroups. This tool is based on ``samtools split`` command. It will generate multiple output datasets for each redagroup from the input dataset.",
    "input_formats": [
      "bam",
      "sam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.5",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/2.0.3",
    "name": "Slice",
    "description": "BAM by genomic regions",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.3",
    "help": "**What it does** Allows to restrict (slice) input BAM dataset to a list of intervals defined in a BED file, individual chromosomes, or manually set list of coordinates. BED datasets can be obtained from **Get Data -> UCSC Main**. This tool is based on ``samtools view`` command. @no-chrom-options@",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_reheader/samtools_reheader/2.0.3",
    "name": "Samtools reheader",
    "description": "copy SAM/BAM header between datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.3",
    "help": "**What it does** Generates a new BAM dataset with the contents of *target* dataset, but the header of *source* dataset using the ``samtools reheader`` command.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.15.1+galaxy2",
    "name": "Samtools depth",
    "description": "compute the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Computes the depth at each position or region using the ``samtools depth`` command. The output is a tabular file, with one line for each base of each reference with any coverage (bases with no coverage may not appear). The first column is the reference name, the second column is the reference position, and then there is one column for each SAM/BAM file giving the coverage depth at that position.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.15.1+galaxy2",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.15.1+galaxy2",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.15.1+galaxy2",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.15.1+galaxy2",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.15.1+galaxy2",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. ## Filtering by Tag ** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.15.1+galaxy2",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/2.5.2+galaxy2",
    "name": "Operate on and transform BAM",
    "description": "datasets in various ways",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools is a collection of utilities for manipulation on BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). This Galaxy implementation of BAMTools utilities includes seven utilities - Convert, Count, Coverage, Header, Merge, Random, and Revert - decsribed in detail below. ----- **Convert** Converts BAM dataset(s) into BED, FASTA, FASTQ, JSON, Pileup, SAM, or YAML formats. Note that the conversion to the pileup format requires providing a reference sequence either cached on this Galaxy instance, or provided by you as a FASTA dataset from History. ----- **Count** Counts the number of alignments in a BAM dataset(s). ----- **Coverage** Prints per-base coverage for a BAM dataset. ----- **Header** Prints the header of a BAM dataset. ------ **Merge** Merges multiple BAM datasets into a single one. ------ **Random** Grabs a specified number of random lines from BAM dataset(s). ------ **Revert** Removes duplicate marks and restores original (non-recalibrated) base qualities. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam",
      "fasta"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/2.5.2+galaxy2",
    "name": "Filter BAM",
    "description": "datasets on a variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools filter is a very powerful utility to perform complex filtering of BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** The tool use logic relies on the three concepts: (1) input BAM, (2) groups, and (3) filters. *Input BAM(s)* The input BAM is self-explanatory. This is the dataset you will be filtering. The tool can accept just one or multiple BAM files. To filter on multiple BAMs just add them by clicking **Add new BAM dataset(s) to filter** *Conditions and Filters* Conditions for filtering BAM files can be arranged in **Groups and Filters**. While it can be confusing at first this is what gives ultimate power to this tools. So try to look at the examples we are supplying below. ----- **Example 1. Using a single filter** When filtering on a single condition there is no need to worry about filters and conditions. Just choose a filter from the **Select BAM property to filter on:** dropdown and enter a value (or click a checkbox for binary filters). For example, for retaining reads with mapping quality of at least 20 one would set the tool interface as shown below: .. image:: single-filter.png ----- **Example 2. Using multiple filters** Now suppose one needs to extract reads that (1) have mapping quality of at least 20, (2) contain at least 1 mismatch, and (3) are mapping onto forward strand only. To do so we will use three filters as shown below (multiple filters are added to the interface by clicking on the **Add new Filter** button): .. image:: multiple-filters.png In this case (you can see that the three filters are grouped within a single Condition - **Condition 1**) the filter too use logical **AND** to perform filtering. In other words only reads that (1) have mapping quality of at least 20 **AND** (2) contain at least 1 mismatch **AND** are mapping onto forward strand will be returned in this example. ----- **Example 3. Complex filtering with multiple conditions** Suppose now you would like to select **either** reads that (**1**) have (*1.1*) no mismatches and (*1.2*) are on the forward strand **OR** (**2**) reads that have (*2.1*) at least one mismatch and (*2.2*) are on the reverse strand. In this scenario we have to set up two conditions: (**1**) and (**2**) each with two filters: *1.1* and *1.2* as well as *2.1* and *2.2*. The following screenshot expalins how this can be done: .. image:: complex-filters.png ----- **Example 4. Even more complex filtering with Rules** In the above example we have used two conditions (Condition 1 and Condition 2). Using multiple conditions allows to combine them and a variety of ways to enable even more powerful filtering. For example, suppose get all reads that (**1**) do NOT map to mitochondria and either (**2**) have mapping quality over 20, or (**3**) are in properly mapped pairs. The logical rule to enable such filtering will look like this:: !(1) & (2 | 3) Here, numbers 1, 2, and 3 represent conditions. The following screenshot illustrates how to do this in Galaxy: .. image:: rule.png There are three conditions here, each with a single filter. A text entry area that can be opened by clicking on the **Would you like to set rules?** checkbox enables you to enter a rule. Here numbers correspond to numbers of conditions as they are shown in the interface. E.g., 1 corresponds to condition 1, 2 to condition 2 and so on... In human language this means:: NOT condition 1 AND (condition 2 OR condition 3) ----- **JSON script file** This tool produces two outputs. One of the them is a BAM file containing filtered reads. The other is a JSONified script. It can help you to see how your instructions are sent to BAMTools. For instance, the example 4 looks like this in the JSON form:: { \"filters\": [ { \"id\": \"1\", \"tag\":\"NM:=0\", \"isReverseStrand\":\"false\" }, { \"id\": \"2\", \"tag\":\"NM:>0\", \"isReverseStrand\":\"true\" } ] } ----- **More information** .. class:: infomark Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_mapped/bamtools_split_mapped/2.5.2+galaxy2",
    "name": "Split BAM by reads mapping status",
    "description": "into a mapped and an unmapped dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Splits the input BAM file into 2 output files containing mapped and unmapped reads, respectively. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_paired/bamtools_split_paired/2.5.2+galaxy2",
    "name": "Split BAM into paired- and single-end",
    "description": "reads datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Splits the input BAM file into 2 output files named containing single_end and paired_end reads, respectively. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_ref/bamtools_split_ref/2.5.2+galaxy2",
    "name": "Split BAM by reference",
    "description": "into a dataset list collection",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on the BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Split alignments by reference name into a dataset list collection. The collection will be in the same order as the input BAM references and will consist of as many elements as there are references selected or listed in the input BAM header. .. class:: warningmark In cases of unfinished genomes with very large number of reference sequences (scaffolds) this could generate a collection with thousands (if not millions) of elements. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bamtools_split_tag/bamtools_split_tag/2.5.2+galaxy2",
    "name": "Split BAM by read tag value",
    "description": "into a dataset list collection",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy2",
    "help": "**What is does** BAMTools split is a utility for splitting BAM files. It is based on the BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** Split alignments by tag name into a dataset list collection. .. class:: warningmark This can generate a collection with a huge number of elements depending on the number of distinct values of the TAG. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/mosdepth/mosdepth/0.3.8+galaxy0",
    "name": "mosdepth",
    "description": "- fast and flexible depth coverage calculation",
    "categories": [
      "SAM/BAM"
    ],
    "version": "0.3.8+galaxy0",
    "help": "mosdepth_ is a tool for fast and flexible calculation of read depths from BAM or CRAM files. It can compute: * mean (or median) depth in fixed-sized windows * mean (or median) depth in regions specified by a BED file * per base depths * a histogram of read depths * the mean or median coverage histogram for windows / regions * a distribution of proportion of based covered over a particular threshold * a BED format report on regions that are defined by coverage thresholds By default, only a summary and depth histogram is computed, but the other options mentioned above can be enabled using different options in the \"Compute depth by region\" selector and some of the Advanced options. .. _mosdepth: https://github.com/brentp/mosdepth",
    "input_formats": [
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "tabular",
      "bedgraph",
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/qualimap_multi_bamqc/qualimap_multi_bamqc/2.3+galaxy0",
    "name": "QualiMap Multi-Sample BamQC",
    "description": "",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.3+galaxy0",
    "help": "**What it does** This tool lets you combine the summary statistics, obtained through multiple runs of the *Qualimap BamQC* tool, of several aligned reads datasets into a single report. This makes it easy to visualize the degree of similarities between the different inputs and to spot differences between them. Input Several *Raw Data* collections obtained from previous runs of *Qualimap BamQC*. Options ------- *Report samples* -> ``Individually`` / ``In groups`` You may decide to group the input data for reporting, in which case you will need to provide a name for each group that will be used in the plot legends. Output The single HTML report generated by this tool contains the following: *Input data and parameters* This section lists the names of the BamQC Raw Data collections that served as input along with the names of the groups (if any) each input got assigned to. *Summary* The summary table contains comparison of selected critical alignment metrics for all samples. The metrics include mean and standard deviation of coverage, mean GC content, mean insert size and mean mapping qualities. If the sample groups are provided, they are also shown for each sample. *PCA plot* The alignment features presented in the Summary section undergo Principal Component Analysis. Afterwards the biplot presenting first and second principal component is constructed. It allows to detect if any samples group together and if there are any outliers among the analyzed samples. *Other plots* Here you will find plots of: - Coverage Across Reference, - Coverage Histogram, - Genome Fraction Coverage, - Duplication Rate Histogram, - Mapped Reads GC Content, - Mapped Reads GC Content Distribution, - Mapped Reads Clipping Profile, - Mapping Quality Across Reference, - Mapping Quality Histogram and, if applicable, - Insert Size Across Reference, - Insert Size Histogram Essentially, these are overlays of the plots of the individual inputs (or of the groups they have been assigned to) and that are explained in the help of the *Qualimap BamQC* tool.",
    "input_formats": [
      "txt"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/qualimap_bamqc/qualimap_bamqc/2.3+galaxy0",
    "name": "QualiMap BamQC",
    "description": "",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.3+galaxy0",
    "help": "**What it does** **Qualimap BAM QC** lets you evaluate the quality of aligned reads data in BAM format. The tool summarizes basic statistics of the alignment (number of reads, coverage, GC-content, etc.) and produces a number of useful graphs for their interpretation. The analysis can be performed with any kind of sequencing data, such as whole-genome sequencing, exome sequencing, RNA-seq or ChIP-seq data. In addition, it is possible to provide an annotation file so the results are computed for the reads mapping inside (and optionally outside) of the corresponding genomic regions, which can be especially useful for evaluating target-enrichment sequencing studies. Input *Mapped reads input dataset* The dataset holding the mapped reads to carry out the analysis with. *Dataset specifying regions* If you decide to calculate mapping statistics for selected regions of the reference genome (instead of for the whole genome), you need to specify the regions through this additional dataset in gtf, gff or bed format. .. class:: infomark A typical problem when working with regions (and genome annotation data, in general) is potential inconsistency between the chromosome names used in the mapped reads input versus those used to define the regions. In the case of the human genome, for example, UCSC data has chromosomes starting with a 'chr' prefix, which is lacking from Ensemble data. This simple form of the problem is handled by Qualimap: if chromosome names in the regions input have a 'chr' prefix, Qualimap will add that prefix to the mapped reads chromosome names as needed. For more complex cases you will have to adjust your inputs manually. Parameters ---------- *Reference genome regions to calculate mapping statistics for* Choose whether you would like to have mapping statistics reported across - the entire reference genome (as specified in the header of the mapped reads input) - specific regions of the reference In the second case, you need to select a *Dataset specifying regions* (see above). Using the *Invert regions* switch you can then indicate whether you want to select or exclude the regions in this dataset. *Generate per-base coverage output* *Skip duplicate reads* The tool lets you skip alignments of duplicate reads from the analysis. Depending on whether you select none, either one, or both of the available options, you can decide to: - not correct for duplicate reads at all (*e.g.* because you have removed them at an earlier step with some dedicated tool) - identify and flag duplicate reads with a dedicated tool (like ``Picard MarkDuplicates`` or ``samtools markdup``), then have Qualimap ignore the duplicate-flagged reads (recommended, most flexible option since other tools can be told to ignore the same reads) - have Qualimap identify potential duplicates by itself and ignore them - combine external and Qualimap-internal duplicate detection for extra stringency Independent of your selection, the HTML report will always list (in the `Globals` section of the `Summary`) the number of duplicated reads estimated by Qualimap. If you choose to skip duplicates, you will also be informed about the number of skipped reads in that same section and, if you instruct Qualimap to look for the duplicate flag on reads, the number of reads flagged as duplicates will also be reported here. **Section: Settings affecting specific plots** Parameters in this section only affect some (or even only one) of the plots contained in the HTML report (and the corresponding part of the *Raw Data* output collection). For most of these options, the parameter help above should be descriptive enough. Just a few more words on two of them: *Number of bins to use in across-reference plots* This value is used for computing the various graphs that plot information across the reference. Basically, the reference genome gets split into the given number of bins, and reads falling in the same bin are aggregated in the statistics of that bin. Thus, the higher the number of bins, the higher the resolution of the plots, but more bins also require longer time for their statistics to be computed. Less bins, on the other hand, mean more reads will have to be aggregated per bin and this comes with higher memory requirements. Hence, if the tool fails with an ``Out Of Memory`` error, you may want to rerun it with a higher bin number. *Plot expected GC-content distribution of the following reference genome* The choice of reference genomes with pre-calculated GC distributions is built into Qualimap. Future releases of Qualimap may include more choices, but the current version is limited to those offered here. Outputs HTML Report ----------- **Summary Section** *Globals* This section contains information about the total number of reads, number of mapped reads, paired-end mapping performance, read length distribution, number of clipped reads and duplication rate (estimated from the start positions of read alignments). *ACGT Content* Nucleotide content and GC percentage in the mapped reads. *Coverage* Mean and standard deviation of the coverage depth. *Mapping quality* Mean mapping quality of the mapped reads. *Insert size* Mean, standard deviation and percentiles of the insert size distribution if applicable. The features are computed based on the TLEN field of the SAM file. *Mismatches and indels* The section reports general alignment error rate (computed as a ratio of total collected edit distance to the number of mapped bases), total number of mismatches and total number of indels (computed from the CIGAR values). Additionally fraction of the homopolymer indels among total indels is provided. Note, the error rate and mismatches metrics are based on optional fields of a SAM record (NM for edit distance, MD for mismatches). The features are not reported if these fields are missing in the SAM file. *Chromosome stats* Number of mapped bases, mean and standard deviation of the coverage depth for each chromosome as defined by the header of the SAM file. For region-based analysis the information is given inside of regions, including some additional information like, for example, number of correct strand reads. **Plots** *Coverage Across Reference* This plot consists of two figures. The upper figure provides the coverage distribution (red line) and coverage deviation across the reference sequence. The lower figure shows GC content across reference (black line) together with its average value (red dotted line). *Coverage Histogram* Histogram of the number of genomic locations having a given coverage rate. The bins of the x-axis are conveniently scaled by aggregating some coverage values in order to produce a representative histogram also in presence of the usual NGS peaks of coverage. *Coverage Histogram (0-50X)* Similar to the previous plot, but in this graph genome locations with a coverage greater than 50X are grouped into the last bin. By doing so a higher resolution of the most common values for the coverage rate is obtained. *Genome Fraction Coverage* Provides a visual way of knowing how much reference has been sequenced to at least a given coverage rate. This graph should be interpreted as in this example: If one aims for a coverage rate of at least 25X (x-axis), how much of the reference (y-axis) will be considered? *Duplication Rate Histogram* This plot shows the distribution of duplicated reads. Due to several factors (*e.g.* amount of starting material, sample preparation, *etc.*) it is possible that the same fragments are sequenced several times. For some experiments where enrichment is used (*e.g.* ChIP-seq ) this is expected to some degree. For most experiments, however, a high duplication level of the reads indicates some unwanted bias. *Mapped Reads Nucleotide Content* This plot shows the nucleotide content per position of the mapped reads. *Mapped Reads GC Content Distribution* This graph shows the distribution of GC-content per mapped read. If compared with a precomputed genome distribution, this plot allows to check if there is a shift in the GC content. *Mapped Reads Clipping Profile* Represents the percentage of clipped bases across the reads. Technically, the clipping is detected via SAM format CIGAR codes H (hard clipping) and S (soft clipping). In addition, the total number of clipped reads can be found in the report `Summary` section. This plot is not shown if no clipped reads are found. *Homopolymer Indels* This bar plot shows the number of indels that are located within A, C, G and T homopolymers, respectively, as well as the number of indels that are not within any homopolymer. Large numbers of homopolymer indels may indicate a problem in the sequencing process. Technically, Qualimap identifies indels from the CIGAR code of the aligned reads. Indel statistics can also be found in a dedicated section of the report `Summary`. This graph is not shown if the sample doesnt contain any indels. *Mapping Quality Across Reference* This plot provides the mapping quality distribution across the reference. To construct the plot, the mean mapping quality is computed for each bin. *Mapping Quality Histogram* Histogram of the number of genomic locations having a given mapping quality. To construct the histogram the mean mapping quality is computed at each genome position with non-zero coverage and collected. According to the SAM/BAM format specifications, the range for the mapping quality score is [0-255]. *Insert Size Across Reference* This plot provides the insert size distribution across the reference. Technically, the insert size of each pair of aligned reads is collected from the SAM alignment field `TLEN`. Only positive values are taken into account. To construct the plot, the mean insert size is computed for each bin. *Insert Size Histogram* Histogram of insert size distribution. Raw Data -------- This is a *Collection* of 10 individual datasets. The *genome_results* dataset provides a plain-text summary of key statistics, most of which can also be found in the *Summary* section of the *HTML Report*. The remaining 12 datasets hold the tabular raw data underlying the plots of the corresponding names in the *HTML Report*. Per-base coverage ----------------- Optional. This is a tabular dataset listing the coverage of every base in the reference genome unless that coverage is zero. Since its content is uncompressed text, this dataset can easily become huge, and it is recommended that you generate this dataset only for very small genomes or very limited regions of larger genomes.",
    "input_formats": [
      "bam",
      "gff",
      "gtf",
      "bed"
    ],
    "output_formats": [
      "html",
      "tsv",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.15.1+galaxy3",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy3",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. **Filtering by Tag** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS. **Filtering by Expression** Filter expressions are used as an on-the-fly checking of incoming SAM, BAM or CRAM records, discarding records that do not match the specified expression. The language used is primarily C style, but with a few differences in the precedence rules for bit operators and the inclusion of regular expression matching. The operator precedence, from strongest binding to weakest, is :: Grouping (, ) E.g. \"(1+2)*3\" Values: literals, vars Numbers, strings and variables Unary ops: +, -, !, ~ E.g. -10 +10, !10 (not), ~5 (bit not) Math ops: \\*, /, % Multiply, division and (integer) modulo Math ops: +, - Addition / subtraction Bit-wise: & Integer AND Bit-wise ^ Integer XOR Bit-wise | Integer OR Conditionals: >, >=, 1) + (3 = 30 && (tlen >= 100000 || tlen =10 can be used to look for alignments with many mismatches and [RG]=~\"grp[ABC]-\" will match the read-group string. If no comparison is used with an auxiliary tag it is taken simply to be a test for the existence of that tag. So [NM] will return any record containing an NM tag, even if that tag is zero (NM:i:0). In htslib 20\" works and will not report these records. NAN also fails all equality, comparisons, and returns zero when given as an argument to the exists function. It can be negated with !x in which case it becomes true. Functions that operate on both strings and numerics: :: exists(x) True if the value exists (or is explicitly true). default(x,d) Value x if it exists or d if not. Functions that apply only to numeric values: :: qrt(x) Square root of x og(x) Natural logarithm of x ow(x, y) Power function, x to the power of y xp(x) Base-e exponential, equivalent to pow(e,x)",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_split/samtools_split/1.20+galaxy2",
    "name": "Samtools split",
    "description": "BAM dataset on readgroups",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "**What it does** Splits BAM files on readgroups. This tool is based on ``samtools split`` command. It will generate multiple output datasets for each readgroup from the input dataset.",
    "input_formats": [
      "bam",
      "sam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.20+galaxy2",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.20+galaxy2",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.20+galaxy2",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.20+galaxy2",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.20+galaxy3",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy3",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. **Filtering by Tag** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS. **Filtering by Expression** Filter expressions are used as an on-the-fly checking of incoming SAM, BAM or CRAM records, discarding records that do not match the specified expression. The language used is primarily C style, but with a few differences in the precedence rules for bit operators and the inclusion of regular expression matching. The operator precedence, from strongest binding to weakest, is :: Grouping (, ) E.g. \"(1+2)*3\" Values: literals, vars Numbers, strings and variables Unary ops: +, -, !, ~ E.g. -10 +10, !10 (not), ~5 (bit not) Math ops: \\*, /, % Multiply, division and (integer) modulo Math ops: +, - Addition / subtraction Bit-wise: & Integer AND Bit-wise ^ Integer XOR Bit-wise | Integer OR Conditionals: >, >=, 1) + (3 = 30 && (tlen >= 100000 || tlen =10 can be used to look for alignments with many mismatches and [RG]=~\"grp[ABC]-\" will match the read-group string. If no comparison is used with an auxiliary tag it is taken simply to be a test for the existence of that tag. So [NM] will return any record containing an NM tag, even if that tag is zero (NM:i:0). In htslib 20\" works and will not report these records. NAN also fails all equality, comparisons, and returns zero when given as an argument to the exists function. It can be negated with !x in which case it becomes true. Functions that operate on both strings and numerics: :: exists(x) True if the value exists (or is explicitly true). default(x,d) Value x if it exists or d if not. Functions that apply only to numeric values: :: qrt(x) Square root of x og(x) Natural logarithm of x ow(x, y) Power function, x to the power of y xp(x) Base-e exponential, equivalent to pow(e,x)",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.20+galaxy2",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy2",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_coverage/samtools_coverage/1.15.1+galaxy2",
    "name": "Samtools coverage",
    "description": "computes the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.15.1+galaxy2",
    "help": "**What it does** This tool runs the ``samtools coverage`` command. Computes the depth at each position or region and draws an ASCII-art histogram or tabulated text. If you select to pool the bam files, then it calculates coverage for the combined files. The tabulated form uses the following headings: - rname Reference name / chromosome - startpos Start position - endpos End position (or sequence length) - numreads Number reads aligned to the region (after filtering) - covbases Number of covered bases with depth >= 1 - coverage Proportion of covered bases [0..1] - meandepth Mean depth of coverage - meanbaseq Mean baseQ in covered region - meanmapq Mean mapQ of selected reads",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_sort/samtools_sort/2.0.6",
    "name": "Samtools sort",
    "description": "order of storing aligned sequences",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Sort alignments by leftmost coordinates, or by read name when -n is used. An appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary. **Ordering Rules** The following rules are used for ordering records. If option -t is in use, records are first sorted by the value of the given alignment tag, and then by position or name (if using -n). For example, -t RG will make read group the primary sort key. The rules for ordering by tag are: - Records that do not have the tag are sorted before ones that do. - If the types of the tags are different, they will be sorted so that single character tags (type A) come before array tags (type B), then string tags (types H and Z), then numeric tags (types f and i). - Numeric tags (types f and i) are compared by value. Note that comparisons of floating-point values are subject to issues of rounding and precision. - String tags (types H and Z) are compared based on the binary contents of the tag using the C strcmp(3) function. - Character tags (type A) are compared by binary character value. - No attempt is made to compare tags of other types  notably type B array values will not be compared. When the -n option is present, records are sorted by name. Names are compared so as to give a natural ordering  i.e. sections consisting of digits are compared numerically while all other sections are compared based on their binary representation. This means a1 will come before b1 and a9 will come before a10. Records with the same name will be ordered according to the values of the READ1 and READ2 flags (see flags). When the -n option is not present, reads are sorted by reference (according to the order of the @SQ header records), then by position in the reference, and then by the REVERSE flag. This has now been removed. The previous out.prefix argument (and -f option, if any) should be changed to an appropriate combination of -T PREFIX and -o FILE. The previous -o option should be removed, as output defaults to standard output. When the -M (minash collation) option is present, then samtools sort groups unmapped reads with similar sequence together. This can sometimes significantly reduce the file size.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_mpileup/samtools_mpileup/2.1.8",
    "name": "Samtools mpileup",
    "description": "multi-way pileup of variants",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.8",
    "help": "**What it does** Generate pileup for one or multiple BAM files. Alignment records are grouped by sample (SM) identifiers in @RG header lines. If sample identifiers are absent, each input file is regarded as one sample. Generation of VCF and BCF output, is deprecated and not available in the Galaxy tool. Please use bcftools mpileup for this instead. In the pileup format (without -u or -g), each line represents a genomic position, consisting of chromosome name, 1-based coordinate, reference base, the number of reads covering the site, read bases, base qualities and alignment mapping qualities. Information on match, mismatch, indel, strand, mapping quality and start and end of a read are all encoded at the read base column. At this column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, a '>' or '<' for a reference skip, 'ACGTN' for a mismatch on the forward strand and 'acgtn' for a mismatch on the reverse strand. A pattern '\\\\+[0-9]+[ACGTNacgtn]+' indicates there is an insertion between this reference position and the next reference position. The length of the insertion is given by the integer in the pattern, followed by the inserted sequence. Similarly, a pattern '-[0-9]+[ACGTNacgtn]+' represents a deletion from the reference. The deleted bases will be presented as '*' in the following lines. Also at the read base column, a symbol '^' marks the start of a read. The ASCII of the character following '^' minus 33 gives the mapping quality. A symbol '$' marks the end of a read segment. Note that there are two orthogonal ways to specify locations in the input file; via -r region and -l file. The former uses (and requires) an index to do random access while the latter streams through the file contents filtering out the specified regions, requiring no index. The two may be used in conjunction. For example a BED file containing locations of genes in chromosome 20 could be specified using -r 20 -l chr20.bed, meaning that the index is used to find chromosome 20 and then it is filtered for the regions listed in the bed file. **BAQ (Base Alignment Quality)** BAQ is the Phred-scaled probability of a read base being misaligned. It greatly helps to reduce false SNPs caused by misalignments. BAQ is calculated using the probabilistic realignment method described in the paper Improving SNP discovery by base alignment quality, Heng Li, Bioinformatics, Volume 27, Issue 8 BAQ is turned on when a reference file is supplied using the -f option. To disable it, use the -B option. It is possible to store pre-calculated BAQ values in a SAM BQ:Z tag. Samtools mpileup will use the precalculated values if it finds them. The -E option can be used to make it ignore the contents of the BQ:Z tag and force it to recalculate the BAQ scores by making a new alignment.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz",
      "bed",
      "txt"
    ],
    "output_formats": [
      "pileup"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_flagstat/samtools_flagstat/2.0.6",
    "name": "Samtools flagstat",
    "description": "tabulate descriptive stats for BAM datset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Uses ``samtools flagstat`` command to print descriptive information for a BAM dataset. Here is an example of such information:: 200 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 25 + 0 mapped (12.50%:nan%) 200 + 0 paired in sequencing 100 + 0 read1 100 + 0 read2 0 + 0 properly paired (0.00%:nan%) 0 + 0 with itself and mate mapped 25 + 0 singletons (12.50%:nan%) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) The results of samtools flagstat can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bam_to_sam/bam_to_sam/2.0.5",
    "name": "BAM-to-SAM",
    "description": "convert BAM to SAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Converts BAM dataset to SAM using the ``samtools view`` command.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "sam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_idxstats/samtools_idxstats/2.0.6",
    "name": "Samtools idxstats",
    "description": "reports stats of the BAM index file",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Runs the ``samtools idxstats`` command. It retrieves and prints stats in the index file. Input is a sorted and indexed BAM file, the output is tabular with four columns (one row per reference sequence plus a final line for unmapped reads):: Column Description ------ ----------------------------- 1 Reference sequence identifier 2 Reference sequence length 3 Number of mapped reads 4 Number of placed but unmapped reads (typically unmapped partners of mapped reads) ------ **Example** output from a *de novo* assembly:: contig_1 170035 98397 0 contig_2 403835 199564 0 contig_3 553102 288189 0 ... ... ... ... contig_603 653 50 0 contig_604 214 6 0 \\* 0 0 50320 In this example there were 604 contigs, each with one line in the output table, plus the final row (labelled with an asterisk) representing 50320 unmapped reads. In this BAM file, the final column was otherwise zero. The results of samtools ixdstats can be visualized with MultiQC. ------ Peter J.A. Cock (2013), `Galaxy wrapper `_ for the samtools idxstats command",
    "input_formats": [
      "bam",
      "cram"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/sam_to_bam/sam_to_bam/2.1.3",
    "name": "SAM-to-BAM",
    "description": "convert SAM to BAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.3",
    "help": "**What it does** Converts SAM dataset into its binary, BAM, representation using the ``samtools view`` and ``sort`` commands.",
    "input_formats": [
      "sam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_calmd/samtools_calmd/2.0.5",
    "name": "Samtools calmd",
    "description": "recalculate MD/NM tags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Generates the MD tag using the ``samtools calmd`` command. If the MD tag (see SAM format reference below for explanation of SAM/BAM tags) is already present, this command will give a warning if the MD tag generated is different from the existing tag. Optionally, also generates the BQ tag to encode base alignment qualities, caps the mapping quality of poorly mapping reads, and modifies read sequences replacing bases matching the reference with ``=``. Outputs a BAM file. ----- **SAM/BAM tags written by this tool** From the SAM format tag specification:: MD (string) String for mismatching positions. Regex : [0-9]+(([A-Z]|\\^[A-Z]+)[0-9]+)*7 NM (integer) Edit distance to the reference, including ambiguous bases but excluding clipping BQ (string) String of offsets to base alignment quality (BAQ), of the same length as the read sequence. At the i-th read base, BAQ i = Q i  (BQ i  64) where Q i is the i-th base quality. See references for more information about SAM format tags.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_bedcov/samtools_bedcov/2.0.5",
    "name": "Samtools bedcov",
    "description": "calculate read depth for a set of genomic intervals",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Calculates read depth for regions listed in a BED dataset using ``samtools bedcov`` command:: samtools bedcov [INPUT BED] [INPUT BAM1] ... [INPUT BAMn] > [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.6",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/2.0.4",
    "name": "Slice",
    "description": "BAM by genomic regions",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Allows to restrict (slice) input BAM dataset to a list of intervals defined in a BED file, individual chromosomes, or manually set list of coordinates. BED datasets can be obtained from **Get Data -> UCSC Main**. This tool is based on ``samtools view`` command. @no-chrom-options@",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_reheader/samtools_reheader/2.0.4",
    "name": "Samtools reheader",
    "description": "copy SAM/BAM header between datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.4",
    "help": "**What it does** Generates a new BAM dataset with the contents of *target* dataset, but the header of *source* dataset using the ``samtools reheader`` command.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/2.5.2+galaxy3",
    "name": "Operate on and transform BAM",
    "description": "datasets in various ways",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy3",
    "help": "**What is does** BAMTools is a collection of utilities for manipulation on BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). This Galaxy implementation of BAMTools utilities includes seven utilities - Convert, Count, Coverage, Header, Merge, Random, and Revert - decsribed in detail below. ----- **Convert** Converts BAM dataset(s) into BED, FASTA, FASTQ, JSON, Pileup, SAM, or YAML formats. Note that the conversion to the pileup format requires providing a reference sequence either cached on this Galaxy instance, or provided by you as a FASTA dataset from History. ----- **Count** Counts the number of alignments in a BAM dataset(s). ----- **Coverage** Prints per-base coverage for a BAM dataset. ----- **Header** Prints the header of a BAM dataset. ------ **Merge** Merges multiple BAM datasets into a single one. ------ **Random** Grabs a specified number of random lines from BAM dataset(s). ------ **Revert** Removes duplicate marks and restores original (non-recalibrated) base qualities. ----- .. class:: infomark **More information** Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam",
      "fasta"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/2.5.2+galaxy3",
    "name": "Filter BAM",
    "description": "datasets on a variety of attributes",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.5.2+galaxy3",
    "help": "**What is does** BAMTools filter is a very powerful utility to perform complex filtering of BAM files. It is based on BAMtools suite of tools by Derek Barnett (https://github.com/pezmaster31/bamtools). ----- **How it works** The tool use logic relies on the three concepts: (1) input BAM, (2) groups, and (3) filters. *Input BAM(s)* The input BAM is self-explanatory. This is the dataset you will be filtering. The tool can accept just one or multiple BAM files. To filter on multiple BAMs just add them by clicking **Add new BAM dataset(s) to filter** *Conditions and Filters* Conditions for filtering BAM files can be arranged in **Groups and Filters**. While it can be confusing at first this is what gives ultimate power to this tools. So try to look at the examples we are supplying below. ----- **Example 1. Using a single filter** When filtering on a single condition there is no need to worry about filters and conditions. Just choose a filter from the **Select BAM property to filter on:** dropdown and enter a value (or click a checkbox for binary filters). For example, for retaining reads with mapping quality of at least 20 one would set the tool interface as shown below: .. image:: single-filter.png ----- **Example 2. Using multiple filters** Now suppose one needs to extract reads that (1) have mapping quality of at least 20, (2) contain at least 1 mismatch, and (3) are mapping onto forward strand only. To do so we will use three filters as shown below (multiple filters are added to the interface by clicking on the **Add new Filter** button): .. image:: multiple-filters.png In this case (you can see that the three filters are grouped within a single Condition - **Condition 1**) the filter too use logical **AND** to perform filtering. In other words only reads that (1) have mapping quality of at least 20 **AND** (2) contain at least 1 mismatch **AND** are mapping onto forward strand will be returned in this example. ----- **Example 3. Complex filtering with multiple conditions** Suppose now you would like to select **either** reads that (**1**) have (*1.1*) no mismatches and (*1.2*) are on the forward strand **OR** (**2**) reads that have (*2.1*) at least one mismatch and (*2.2*) are on the reverse strand. In this scenario we have to set up two conditions: (**1**) and (**2**) each with two filters: *1.1* and *1.2* as well as *2.1* and *2.2*. The following screenshot expalins how this can be done: .. image:: complex-filters.png ----- **Example 4. Even more complex filtering with Rules** In the above example we have used two conditions (Condition 1 and Condition 2). Using multiple conditions allows to combine them and a variety of ways to enable even more powerful filtering. For example, suppose get all reads that (**1**) do NOT map to mitochondria and either (**2**) have mapping quality over 20, or (**3**) are in properly mapped pairs. The logical rule to enable such filtering will look like this:: !(1) & (2 | 3) Here, numbers 1, 2, and 3 represent conditions. The following screenshot illustrates how to do this in Galaxy: .. image:: rule.png There are three conditions here, each with a single filter. A text entry area that can be opened by clicking on the **Would you like to set rules?** checkbox enables you to enter a rule. Here numbers correspond to numbers of conditions as they are shown in the interface. E.g., 1 corresponds to condition 1, 2 to condition 2 and so on... In human language this means:: NOT condition 1 AND (condition 2 OR condition 3) ----- **JSON script file** This tool produces two outputs. One of the them is a BAM file containing filtered reads. The other is a JSONified script. It can help you to see how your instructions are sent to BAMTools. For instance, the example 4 looks like this in the JSON form:: { \"filters\": [ { \"id\": \"1\", \"tag\":\"NM:=0\", \"isReverseStrand\":\"false\" }, { \"id\": \"2\", \"tag\":\"NM:>0\", \"isReverseStrand\":\"true\" } ] } ----- **More information** .. class:: infomark Additional information about BAMtools can be found at https://github.com/pezmaster31/bamtools/wiki",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.21+galaxy0",
    "name": "Samtools depth",
    "description": "compute the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "**What it does** Computes the depth at each position or region using the ``samtools depth`` command. The output is a tabular file, with one line for each base of each reference with any coverage (bases with no coverage may not appear). The first column is the reference name, the second column is the reference position, and then there is one column for each SAM/BAM file giving the coverage depth at that position.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.21+galaxy0",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.21+galaxy0",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.21+galaxy0",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.21+galaxy0",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.21+galaxy0",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. **Filtering by Tag** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS. **Filtering by Expression** Filter expressions are used as an on-the-fly checking of incoming SAM, BAM or CRAM records, discarding records that do not match the specified expression. The language used is primarily C style, but with a few differences in the precedence rules for bit operators and the inclusion of regular expression matching. The operator precedence, from strongest binding to weakest, is :: Grouping (, ) E.g. \"(1+2)*3\" Values: literals, vars Numbers, strings and variables Unary ops: +, -, !, ~ E.g. -10 +10, !10 (not), ~5 (bit not) Math ops: \\*, /, % Multiply, division and (integer) modulo Math ops: +, - Addition / subtraction Bit-wise: & Integer AND Bit-wise ^ Integer XOR Bit-wise | Integer OR Conditionals: >, >=, 1) + (3 = 30 && (tlen >= 100000 || tlen =10 can be used to look for alignments with many mismatches and [RG]=~\"grp[ABC]-\" will match the read-group string. If no comparison is used with an auxiliary tag it is taken simply to be a test for the existence of that tag. So [NM] will return any record containing an NM tag, even if that tag is zero (NM:i:0). In htslib 20\" works and will not report these records. NAN also fails all equality, comparisons, and returns zero when given as an argument to the exists function. It can be negated with !x in which case it becomes true. Functions that operate on both strings and numerics: :: exists(x) True if the value exists (or is explicitly true). default(x,d) Value x if it exists or d if not. Functions that apply only to numeric values: :: qrt(x) Square root of x og(x) Natural logarithm of x ow(x, y) Power function, x to the power of y xp(x) Base-e exponential, equivalent to pow(e,x)",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.21+galaxy0",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy0",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_coverage/samtools_coverage/1.21+galaxy3",
    "name": "Samtools coverage",
    "description": "Produces a histogram or table of coverage per chromosome",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.21+galaxy3",
    "help": "**What it does** This tool runs the ``samtools coverage`` command. Computes the depth at each position or region and draws an ASCII-art histogram or tabulated text. If you select to pool the bam files, then it calculates coverage for the combined files. The tabulated form uses the following headings: - rname Reference name / chromosome - startpos Start position - endpos End position (or sequence length) - numreads Number reads aligned to the region (after filtering) - covbases Number of covered bases with depth >= 1 - coverage Proportion of covered bases [0..1] - meandepth Mean depth of coverage - meanbaseq Mean baseQ in covered region - meanmapq Mean mapQ of selected reads",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_coverage/samtools_coverage/1.20+galaxy3",
    "name": "Samtools coverage",
    "description": "Produces a histogram or table of coverage per chromosome",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.20+galaxy3",
    "help": "**What it does** This tool runs the ``samtools coverage`` command. Computes the depth at each position or region and draws an ASCII-art histogram or tabulated text. If you select to pool the bam files, then it calculates coverage for the combined files. The tabulated form uses the following headings: - rname Reference name / chromosome - startpos Start position - endpos End position (or sequence length) - numreads Number reads aligned to the region (after filtering) - covbases Number of covered bases with depth >= 1 - coverage Proportion of covered bases [0..1] - meandepth Mean depth of coverage - meanbaseq Mean baseQ in covered region - meanmapq Mean mapQ of selected reads",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_sort/samtools_sort/2.0.7",
    "name": "Samtools sort",
    "description": "order of storing aligned sequences",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Sort alignments by leftmost coordinates, or by read name when -n is used. An appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary. **Ordering Rules** The following rules are used for ordering records. If option -t is in use, records are first sorted by the value of the given alignment tag, and then by position or name (if using -n). For example, -t RG will make read group the primary sort key. The rules for ordering by tag are: - Records that do not have the tag are sorted before ones that do. - If the types of the tags are different, they will be sorted so that single character tags (type A) come before array tags (type B), then string tags (types H and Z), then numeric tags (types f and i). - Numeric tags (types f and i) are compared by value. Note that comparisons of floating-point values are subject to issues of rounding and precision. - String tags (types H and Z) are compared based on the binary contents of the tag using the C strcmp(3) function. - Character tags (type A) are compared by binary character value. - No attempt is made to compare tags of other types  notably type B array values will not be compared. When the -n option is present, records are sorted by name. Names are compared so as to give a natural ordering  i.e. sections consisting of digits are compared numerically while all other sections are compared based on their binary representation. This means a1 will come before b1 and a9 will come before a10. Records with the same name will be ordered according to the values of the READ1 and READ2 flags (see flags). When the -n option is not present, reads are sorted by reference (according to the order of the @SQ header records), then by position in the reference, and then by the REVERSE flag. This has now been removed. The previous out.prefix argument (and -f option, if any) should be changed to an appropriate combination of -T PREFIX and -o FILE. The previous -o option should be removed, as output defaults to standard output. When the -M (minash collation) option is present, then samtools sort groups unmapped reads with similar sequence together. This can sometimes significantly reduce the file size.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_mpileup/samtools_mpileup/2.1.9",
    "name": "Samtools mpileup",
    "description": "multi-way pileup of variants",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.9",
    "help": "**What it does** Generate pileup for one or multiple BAM files. Alignment records are grouped by sample (SM) identifiers in @RG header lines. If sample identifiers are absent, each input file is regarded as one sample. Generation of VCF and BCF output, is deprecated and not available in the Galaxy tool. Please use bcftools mpileup for this instead. In the pileup format (without -u or -g), each line represents a genomic position, consisting of chromosome name, 1-based coordinate, reference base, the number of reads covering the site, read bases, base qualities and alignment mapping qualities. Information on match, mismatch, indel, strand, mapping quality and start and end of a read are all encoded at the read base column. At this column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, a '>' or '<' for a reference skip, 'ACGTN' for a mismatch on the forward strand and 'acgtn' for a mismatch on the reverse strand. A pattern '\\\\+[0-9]+[ACGTNacgtn]+' indicates there is an insertion between this reference position and the next reference position. The length of the insertion is given by the integer in the pattern, followed by the inserted sequence. Similarly, a pattern '-[0-9]+[ACGTNacgtn]+' represents a deletion from the reference. The deleted bases will be presented as '*' in the following lines. Also at the read base column, a symbol '^' marks the start of a read. The ASCII of the character following '^' minus 33 gives the mapping quality. A symbol '$' marks the end of a read segment. Note that there are two orthogonal ways to specify locations in the input file; via -r region and -l file. The former uses (and requires) an index to do random access while the latter streams through the file contents filtering out the specified regions, requiring no index. The two may be used in conjunction. For example a BED file containing locations of genes in chromosome 20 could be specified using -r 20 -l chr20.bed, meaning that the index is used to find chromosome 20 and then it is filtered for the regions listed in the bed file. **BAQ (Base Alignment Quality)** BAQ is the Phred-scaled probability of a read base being misaligned. It greatly helps to reduce false SNPs caused by misalignments. BAQ is calculated using the probabilistic realignment method described in the paper Improving SNP discovery by base alignment quality, Heng Li, Bioinformatics, Volume 27, Issue 8 BAQ is turned on when a reference file is supplied using the -f option. To disable it, use the -B option. It is possible to store pre-calculated BAQ values in a SAM BQ:Z tag. Samtools mpileup will use the precalculated values if it finds them. The -E option can be used to make it ignore the contents of the BQ:Z tag and force it to recalculate the BAQ scores by making a new alignment.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz",
      "bed",
      "txt"
    ],
    "output_formats": [
      "pileup"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_flagstat/samtools_flagstat/2.0.7",
    "name": "Samtools flagstat",
    "description": "tabulate descriptive stats for BAM datset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Uses ``samtools flagstat`` command to print descriptive information for a BAM dataset. Here is an example of such information:: 200 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 25 + 0 mapped (12.50%:nan%) 200 + 0 paired in sequencing 100 + 0 read1 100 + 0 read2 0 + 0 properly paired (0.00%:nan%) 0 + 0 with itself and mate mapped 25 + 0 singletons (12.50%:nan%) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) The results of samtools flagstat can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bam_to_sam/bam_to_sam/2.0.6",
    "name": "BAM-to-SAM",
    "description": "convert BAM to SAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Converts BAM dataset to SAM using the ``samtools view`` command.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "sam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_idxstats/samtools_idxstats/2.0.7",
    "name": "Samtools idxstats",
    "description": "reports stats of the BAM index file",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Runs the ``samtools idxstats`` command. It retrieves and prints stats in the index file. Input is a sorted and indexed BAM file, the output is tabular with four columns (one row per reference sequence plus a final line for unmapped reads):: Column Description ------ ----------------------------- 1 Reference sequence identifier 2 Reference sequence length 3 Number of mapped reads 4 Number of placed but unmapped reads (typically unmapped partners of mapped reads) ------ **Example** output from a *de novo* assembly:: contig_1 170035 98397 0 contig_2 403835 199564 0 contig_3 553102 288189 0 ... ... ... ... contig_603 653 50 0 contig_604 214 6 0 \\* 0 0 50320 In this example there were 604 contigs, each with one line in the output table, plus the final row (labelled with an asterisk) representing 50320 unmapped reads. In this BAM file, the final column was otherwise zero. The results of samtools ixdstats can be visualized with MultiQC. ------ Peter J.A. Cock (2013), `Galaxy wrapper `_ for the samtools idxstats command",
    "input_formats": [
      "bam",
      "cram"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/sam_to_bam/sam_to_bam/2.1.4",
    "name": "SAM-to-BAM",
    "description": "convert SAM to BAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.4",
    "help": "**What it does** Converts SAM dataset into its binary, BAM, representation using the ``samtools view`` and ``sort`` commands.",
    "input_formats": [
      "sam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_calmd/samtools_calmd/2.0.6",
    "name": "Samtools calmd",
    "description": "recalculate MD/NM tags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Generates the MD tag using the ``samtools calmd`` command. If the MD tag (see SAM format reference below for explanation of SAM/BAM tags) is already present, this command will give a warning if the MD tag generated is different from the existing tag. Optionally, also generates the BQ tag to encode base alignment qualities, caps the mapping quality of poorly mapping reads, and modifies read sequences replacing bases matching the reference with ``=``. Outputs a BAM file. ----- **SAM/BAM tags written by this tool** From the SAM format tag specification:: MD (string) String for mismatching positions. Regex : [0-9]+(([A-Z]|\\^[A-Z]+)[0-9]+)*7 NM (integer) Edit distance to the reference, including ambiguous bases but excluding clipping BQ (string) String of offsets to base alignment quality (BAQ), of the same length as the read sequence. At the i-th read base, BAQ i = Q i  (BQ i  64) where Q i is the i-th base quality. See references for more information about SAM format tags.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_bedcov/samtools_bedcov/2.0.6",
    "name": "Samtools bedcov",
    "description": "calculate read depth for a set of genomic intervals",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Calculates read depth for regions listed in a BED dataset using ``samtools bedcov`` command:: samtools bedcov [INPUT BED] [INPUT BAM1] ... [INPUT BAMn] > [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.7",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/2.0.5",
    "name": "Slice",
    "description": "BAM by genomic regions",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Allows to restrict (slice) input BAM dataset to a list of intervals defined in a BED file, individual chromosomes, or manually set list of coordinates. BED datasets can be obtained from **Get Data -> UCSC Main**. This tool is based on ``samtools view`` command. @no-chrom-options@",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_reheader/samtools_reheader/2.0.5",
    "name": "Samtools reheader",
    "description": "copy SAM/BAM header between datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.5",
    "help": "**What it does** Generates a new BAM dataset with the contents of *target* dataset, but the header of *source* dataset using the ``samtools reheader`` command.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.22+galaxy0",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy0",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam",
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/mosdepth/mosdepth/0.3.11+galaxy0",
    "name": "mosdepth",
    "description": "- fast and flexible depth coverage calculation",
    "categories": [
      "SAM/BAM"
    ],
    "version": "0.3.11+galaxy0",
    "help": "mosdepth_ is a tool for fast and flexible calculation of read depths from BAM or CRAM files. It can compute: * mean (or median) depth in fixed-sized windows * mean (or median) depth in regions specified by a BED file * per base depths * a histogram of read depths * the mean or median coverage histogram for windows / regions * a distribution of proportion of based covered over a particular threshold * a BED format report on regions that are defined by coverage thresholds By default, only a summary and depth histogram is computed, but the other options mentioned above can be enabled using different options in the \"Compute depth by region\" selector and some of the Advanced options. .. _mosdepth: https://github.com/brentp/mosdepth",
    "input_formats": [
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "tabular",
      "bedgraph",
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_sort/samtools_sort/2.0.8",
    "name": "Samtools sort",
    "description": "order of storing aligned sequences",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.8",
    "help": "**What it does** Sort alignments by leftmost coordinates, or by read name when -n is used. An appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary. **Ordering Rules** The following rules are used for ordering records. If option -t is in use, records are first sorted by the value of the given alignment tag, and then by position or name (if using -n). For example, -t RG will make read group the primary sort key. The rules for ordering by tag are: - Records that do not have the tag are sorted before ones that do. - If the types of the tags are different, they will be sorted so that single character tags (type A) come before array tags (type B), then string tags (types H and Z), then numeric tags (types f and i). - Numeric tags (types f and i) are compared by value. Note that comparisons of floating-point values are subject to issues of rounding and precision. - String tags (types H and Z) are compared based on the binary contents of the tag using the C strcmp(3) function. - Character tags (type A) are compared by binary character value. - No attempt is made to compare tags of other types  notably type B array values will not be compared. When the -n option is present, records are sorted by name. Names are compared so as to give a natural ordering  i.e. sections consisting of digits are compared numerically while all other sections are compared based on their binary representation. This means a1 will come before b1 and a9 will come before a10. Records with the same name will be ordered according to the values of the READ1 and READ2 flags (see flags). When the -n option is not present, reads are sorted by reference (according to the order of the @SQ header records), then by position in the reference, and then by the REVERSE flag. This has now been removed. The previous out.prefix argument (and -f option, if any) should be changed to an appropriate combination of -T PREFIX and -o FILE. The previous -o option should be removed, as output defaults to standard output. When the -M (minash collation) option is present, then samtools sort groups unmapped reads with similar sequence together. This can sometimes significantly reduce the file size.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_mpileup/samtools_mpileup/2.2.0",
    "name": "Samtools mpileup",
    "description": "multi-way pileup of variants",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.2.0",
    "help": "**What it does** Generate pileup for one or multiple BAM files. Alignment records are grouped by sample (SM) identifiers in @RG header lines. If sample identifiers are absent, each input file is regarded as one sample. Generation of VCF and BCF output, is deprecated and not available in the Galaxy tool. Please use bcftools mpileup for this instead. In the pileup format (without -u or -g), each line represents a genomic position, consisting of chromosome name, 1-based coordinate, reference base, the number of reads covering the site, read bases, base qualities and alignment mapping qualities. Information on match, mismatch, indel, strand, mapping quality and start and end of a read are all encoded at the read base column. At this column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, a '>' or '<' for a reference skip, 'ACGTN' for a mismatch on the forward strand and 'acgtn' for a mismatch on the reverse strand. A pattern '\\\\+[0-9]+[ACGTNacgtn]+' indicates there is an insertion between this reference position and the next reference position. The length of the insertion is given by the integer in the pattern, followed by the inserted sequence. Similarly, a pattern '-[0-9]+[ACGTNacgtn]+' represents a deletion from the reference. The deleted bases will be presented as '*' in the following lines. Also at the read base column, a symbol '^' marks the start of a read. The ASCII of the character following '^' minus 33 gives the mapping quality. A symbol '$' marks the end of a read segment. Note that there are two orthogonal ways to specify locations in the input file; via -r region and -l file. The former uses (and requires) an index to do random access while the latter streams through the file contents filtering out the specified regions, requiring no index. The two may be used in conjunction. For example a BED file containing locations of genes in chromosome 20 could be specified using -r 20 -l chr20.bed, meaning that the index is used to find chromosome 20 and then it is filtered for the regions listed in the bed file. **BAQ (Base Alignment Quality)** BAQ is the Phred-scaled probability of a read base being misaligned. It greatly helps to reduce false SNPs caused by misalignments. BAQ is calculated using the probabilistic realignment method described in the paper Improving SNP discovery by base alignment quality, Heng Li, Bioinformatics, Volume 27, Issue 8 BAQ is turned on when a reference file is supplied using the -f option. To disable it, use the -B option. It is possible to store pre-calculated BAQ values in a SAM BQ:Z tag. Samtools mpileup will use the precalculated values if it finds them. The -E option can be used to make it ignore the contents of the BQ:Z tag and force it to recalculate the BAQ scores by making a new alignment.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz",
      "bed",
      "txt"
    ],
    "output_formats": [
      "pileup"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_flagstat/samtools_flagstat/2.0.8",
    "name": "Samtools flagstat",
    "description": "tabulate descriptive stats for BAM datset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.8",
    "help": "**What it does** Uses ``samtools flagstat`` command to print descriptive information for a BAM dataset. Here is an example of such information:: 200 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 25 + 0 mapped (12.50%:nan%) 200 + 0 paired in sequencing 100 + 0 read1 100 + 0 read2 0 + 0 properly paired (0.00%:nan%) 0 + 0 with itself and mate mapped 25 + 0 singletons (12.50%:nan%) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) The results of samtools flagstat can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/bam_to_sam/bam_to_sam/2.0.7",
    "name": "BAM-to-SAM",
    "description": "convert BAM to SAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Converts BAM dataset to SAM using the ``samtools view`` command.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "sam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_idxstats/samtools_idxstats/2.0.8",
    "name": "Samtools idxstats",
    "description": "reports stats of the BAM index file",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.8",
    "help": "**What it does** Runs the ``samtools idxstats`` command. It retrieves and prints stats in the index file. Input is a sorted and indexed BAM file, the output is tabular with four columns (one row per reference sequence plus a final line for unmapped reads):: Column Description ------ ----------------------------- 1 Reference sequence identifier 2 Reference sequence length 3 Number of mapped reads 4 Number of placed but unmapped reads (typically unmapped partners of mapped reads) ------ **Example** output from a *de novo* assembly:: contig_1 170035 98397 0 contig_2 403835 199564 0 contig_3 553102 288189 0 ... ... ... ... contig_603 653 50 0 contig_604 214 6 0 \\* 0 0 50320 In this example there were 604 contigs, each with one line in the output table, plus the final row (labelled with an asterisk) representing 50320 unmapped reads. In this BAM file, the final column was otherwise zero. The results of samtools ixdstats can be visualized with MultiQC. ------ Peter J.A. Cock (2013), `Galaxy wrapper `_ for the samtools idxstats command",
    "input_formats": [
      "bam",
      "cram"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/sam_to_bam/sam_to_bam/2.1.5",
    "name": "SAM-to-BAM",
    "description": "convert SAM to BAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.1.5",
    "help": "**What it does** Converts SAM dataset into its binary, BAM, representation using the ``samtools view`` and ``sort`` commands.",
    "input_formats": [
      "sam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_calmd/samtools_calmd/2.0.7",
    "name": "Samtools calmd",
    "description": "recalculate MD/NM tags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Generates the MD tag using the ``samtools calmd`` command. If the MD tag (see SAM format reference below for explanation of SAM/BAM tags) is already present, this command will give a warning if the MD tag generated is different from the existing tag. Optionally, also generates the BQ tag to encode base alignment qualities, caps the mapping quality of poorly mapping reads, and modifies read sequences replacing bases matching the reference with ``=``. Outputs a BAM file. ----- **SAM/BAM tags written by this tool** From the SAM format tag specification:: MD (string) String for mismatching positions. Regex : [0-9]+(([A-Z]|\\^[A-Z]+)[0-9]+)*7 NM (integer) Edit distance to the reference, including ambiguous bases but excluding clipping BQ (string) String of offsets to base alignment quality (BAQ), of the same length as the read sequence. At the i-th read base, BAQ i = Q i  (BQ i  64) where Q i is the i-th base quality. See references for more information about SAM format tags.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_bedcov/samtools_bedcov/2.0.7",
    "name": "Samtools bedcov",
    "description": "calculate read depth for a set of genomic intervals",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.7",
    "help": "**What it does** Calculates read depth for regions listed in a BED dataset using ``samtools bedcov`` command:: samtools bedcov [INPUT BED] [INPUT BAM1] ... [INPUT BAMn] > [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_split/samtools_split/1.22+galaxy1",
    "name": "Samtools split",
    "description": "BAM dataset on readgroups",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Splits BAM files on readgroups. This tool is based on ``samtools split`` command. It will generate multiple output datasets for each readgroup from the input dataset.",
    "input_formats": [
      "bam",
      "sam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_stats/samtools_stats/2.0.8",
    "name": "Samtools stats",
    "description": "generate statistics for BAM dataset",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.8",
    "help": "**What it does** This tool runs the ``samtools stats`` command. The results of samtools stats can be visualized with MultiQC (for this the default of a single output file needs to be selected).",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "fasta",
      "fasta.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/2.0.6",
    "name": "Slice",
    "description": "BAM by genomic regions",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Allows to restrict (slice) input BAM dataset to a list of intervals defined in a BED file, individual chromosomes, or manually set list of coordinates. BED datasets can be obtained from **Get Data -> UCSC Main**. This tool is based on ``samtools view`` command. @no-chrom-options@",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_reheader/samtools_reheader/2.0.6",
    "name": "Samtools reheader",
    "description": "copy SAM/BAM header between datasets",
    "categories": [
      "SAM/BAM"
    ],
    "version": "2.0.6",
    "help": "**What it does** Generates a new BAM dataset with the contents of *target* dataset, but the header of *source* dataset using the ``samtools reheader`` command.",
    "input_formats": [
      "sam",
      "bam"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_depth/samtools_depth/1.22+galaxy1",
    "name": "Samtools depth",
    "description": "compute the depth at each position or region",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Computes the depth at each position or region using the ``samtools depth`` command. The output is a tabular file, with one line for each base of each reference with any coverage (bases with no coverage may not appear). The first column is the reference name, the second column is the reference position, and then there is one column for each SAM/BAM file giving the coverage depth at that position.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fastx/samtools_fastx/1.22+galaxy1",
    "name": "Samtools fastx",
    "description": "extract FASTA or FASTQ from alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "This tool uses `Samtools `_ to extract sequences from a SAM or BAM file in FASTA or FASTQ format.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_fixmate/samtools_fixmate/1.22+galaxy1",
    "name": "Samtools fixmate",
    "description": "fill mate coordinates, ISIZE and mate related flags",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Fill in mate coordinates, ISIZE and mate related flags from a name-sorted alignment.",
    "input_formats": [
      "sam",
      "bam",
      "cram"
    ],
    "output_formats": [
      "qname_sorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_markdup/samtools_markdup/1.22+galaxy1",
    "name": "Samtools markdup",
    "description": "marks duplicate alignments",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "Mark duplicate alignments from a coordinate sorted file that has been run through fixmate with the -m option. This program relies on the MC and ms tags that fixmate provides. Note: The Galaxy tool sorts the data automatically if the input is SAM or query name sorted. The output is BAM (which is query name sorted again if the input is). The optional basic statistics output of samtools markdup can be visualized with MultiQC.",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "fasta"
    ],
    "output_formats": [
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_merge/samtools_merge/1.22+galaxy1",
    "name": "Samtools merge",
    "description": "merge multiple sorted alignment files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Merge multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. If a file to take @headers from is specified the @SQ headers of input files will be merged into the specified header, otherwise they will be merged into a composite header created from the input headers. If in the process of merging @SQ lines for coordinate sorted input files, a conflict arises as to the order (for example input1.bam has @SQ for a,b,c and input2.bam has b,a,c) then the resulting output file will need to be re-sorted back into coordinate order. Unless the @PG/@RG headers are made unique when merging @RG and @PG records into the output header then any IDs found to be duplicates of existing IDs in the output header will have a suffix appended to them to differentiate them from similar header records from other files and the read records will be updated to reflect this.",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/devteam/samtools_phase/samtools_phase/1.22+galaxy1",
    "name": "Samtools phase",
    "description": "call and phase heterozygous SNPs",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Call and phase heterozygous SNPs.",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "txt",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_view/samtools_view/1.22+galaxy1",
    "name": "Samtools view",
    "description": "- reformat, filter, or subsample SAM, BAM or CRAM",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Samtools view can: 1. convert between alignment formats (SAM, BAM, CRAM) 2. filter and subsample alignments according to user-specified criteria 3. count the reads in the input dataset or those retained after filtering and subsampling 4. obtain just the header of the input in any supported format In addition, the tool has (limited) options to modify read records during conversion and/or filtering by: - stripping them of user-specified tags - collapsing backward CIGAR operations if they are specified in their CIGAR fields With default settings, the tool generates a BAM dataset with the header and reads found in the input dataset (which can be in SAM, BAM, or CRAM format). **Alignment format conversion** By changing the *Output format* it is possible to convert an input dataset to another format. Inputs of type SAM, BAM, and CRAM are accepted and can be converted to each of these formats (alternatively alignment counts can be computed) by selecting the appropriate \"Output type\". .. class:: infomark The tool allows you to specify a reference sequence. This is required for SAM input with missing @SQ headers (which include sequence names, length, md5, etc) and useful (and sometimes necessary) for CRAM input and output. In the following the use of the reference sequence in the CRAM format is detailed. CRAM is (primarily) a reference-based compressed format, i.e. only sequence differences between aligned reads and the reference are stored. As a consequence, the reference that was used during read mapping is needed in order to interpret the alignment records (a checksum stored in the CRAM file is used to verify that only the correct reference sequence can be used). This allows for more space-efficient storage than with BAM format, but such a CRAM file is not usable without its reference. It is also possible, however, to use CRAM without a reference with the disadvantage that the reference sequence gets stored then explicitely (as in SAM and BAM). The Galaxy tool **currently generates only CRAM without reference sequence**. For reference based CRAM input the correct refernce sequence needs to be specified. **Filtering alignments** If you ask for *A filtered/subsampled selection of reads*, the tool will allow you to specify filter conditions and/or to choose a subsampling strategy, and the output will contain one of the following depending on your choice under *What would you like to have reported?*: - All reads retained after filtering and subsampling - Reads dropped during filtering and subsampling If instead you want to *split* the input reads based on your criteria and obtain *two* datasets, one with the retained and one with the dropped reads, check the *Produce extra dataset with dropped/retained reads?* option. **Filtering by regions** You may specify one or more space-separated region specifications after the input filename to restrict output to only those alignments which overlap the specified region(s). Use of region specifications requires a coordinate-sorted and indexed input file (in BAM or CRAM format). Regions can be specified as: RNAME[:STARTPOS[-ENDPOS]] and all position coordinates are 1-based. .. class:: Warning mark When multiple regions are given, some alignments may be output multiple times if they overlap more than one of the specified regions. Examples of region specifications: ``chr1`` Output all alignments mapped to the reference sequence named 'chr1' (i.e. @SQ SN:chr1). ``chr2:1000000`` The region on chr2 beginning at base position 1,000,000 and ending at the end of the chromosome. ``chr3:1000-2000`` The 1001bp region on chr3 beginning at base position 1,000 and ending at base position 2,000 (including both end positions). ``*`` Output the unmapped reads at the end of the file. (This does not include any unmapped reads placed on a reference sequence alongside their mapped mates.) ``.`` Output all alignments. (Mostly unnecessary as not specifying a region at all has the same effect.) **Filtering by quality** This filters based on the MAPQ column of the SAM format which gives an estimate about the correct placement of the alignment. Note that aligners do not follow a consistent definition. **Filtering by Tag** This filter allows to select reads based on tool or user specific tags, e.g., XS:i:-18 the alignment score tag of bowtie. Thus to filter for a specific value of the tag you need the format STR1:STR2, e.g., XS:-18 to filter reads with an aligment score of -18. You can also just write STR1 without the value STR2 hence the filter selects all reads with the tag STR1, e.g., XS. **Filtering by Expression** Filter expressions are used as an on-the-fly checking of incoming SAM, BAM or CRAM records, discarding records that do not match the specified expression. The language used is primarily C style, but with a few differences in the precedence rules for bit operators and the inclusion of regular expression matching. The operator precedence, from strongest binding to weakest, is :: Grouping (, ) E.g. \"(1+2)*3\" Values: literals, vars Numbers, strings and variables Unary ops: +, -, !, ~ E.g. -10 +10, !10 (not), ~5 (bit not) Math ops: \\*, /, % Multiply, division and (integer) modulo Math ops: +, - Addition / subtraction Bit-wise: & Integer AND Bit-wise ^ Integer XOR Bit-wise | Integer OR Conditionals: >, >=, 1) + (3 = 30 && (tlen >= 100000 || tlen =10 can be used to look for alignments with many mismatches and [RG]=~\"grp[ABC]-\" will match the read-group string. If no comparison is used with an auxiliary tag it is taken simply to be a test for the existence of that tag. So [NM] will return any record containing an NM tag, even if that tag is zero (NM:i:0). In htslib 20\" works and will not report these records. NAN also fails all equality, comparisons, and returns zero when given as an argument to the exists function. It can be negated with !x in which case it becomes true. Functions that operate on both strings and numerics: :: exists(x) True if the value exists (or is explicitly true). default(x,d) Value x if it exists or d if not. Functions that apply only to numeric values: :: qrt(x) Square root of x og(x) Natural logarithm of x ow(x, y) Power function, x to the power of y xp(x) Base-e exponential, equivalent to pow(e,x)",
    "input_formats": [
      "sam",
      "unsorted.bam",
      "cram",
      "bed",
      "tabular",
      "txt",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_ampliconclip/samtools_ampliconclip/1.22+galaxy1",
    "name": "Samtools ampliconclip",
    "description": "clip primer bases from bam files",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy1",
    "help": "**What it does** Clips read alignments where they match BED file defined regions (e.g. for amplicon sequencing). samtools ampliconclip -b [INPUT BED] [INPUT BAM1] -o [OUTPUT]",
    "input_formats": [
      "bed",
      "bam"
    ],
    "output_formats": [
      "bam",
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/mosdepth/mosdepth/0.3.12+galaxy0",
    "name": "mosdepth",
    "description": "- fast and flexible depth coverage calculation",
    "categories": [
      "SAM/BAM"
    ],
    "version": "0.3.12+galaxy0",
    "help": "mosdepth_ is a tool for fast and flexible calculation of read depths from BAM or CRAM files. It can compute: * mean (or median) depth in fixed-sized windows * mean (or median) depth in regions specified by a BED file * per base depths * a histogram of read depths * the mean or median coverage histogram for windows / regions * a distribution of proportion of based covered over a particular threshold * a BED format report on regions that are defined by coverage thresholds By default, only a summary and depth histogram is computed, but the other options mentioned above can be enabled using different options in the \"Compute depth by region\" selector and some of the Advanced options. .. _mosdepth: https://github.com/brentp/mosdepth",
    "input_formats": [
      "bam",
      "cram",
      "bed"
    ],
    "output_formats": [
      "tabular",
      "bedgraph",
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/samtools_coverage/samtools_coverage/1.22+galaxy3",
    "name": "Samtools coverage",
    "description": "Produces a histogram or table of coverage per chromosome",
    "categories": [
      "SAM/BAM"
    ],
    "version": "1.22+galaxy3",
    "help": "**What it does** This tool runs the ``samtools coverage`` command. Computes the depth at each position or region and draws an ASCII-art histogram or tabulated text. If you select to pool the bam files, then it calculates coverage for the combined files. The tabulated form uses the following headings: - rname Reference name / chromosome - startpos Start position - endpos End position (or sequence length) - numreads Number reads aligned to the region (after filtering) - covbases Number of covered bases with depth >= 1 - coverage Proportion of covered bases [0..1] - meandepth Mean depth of coverage - meanbaseq Mean baseQ in covered region - meanmapq Mean mapQ of selected reads",
    "input_formats": [
      "bam"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_links/2.30.0",
    "name": "bedtools LinksBed",
    "description": "create a HTML page of links to UCSC locations",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Creates an HTML file with links to an instance of the UCSC Genome Browser for all features / intervals in a file. This is useful for cases when one wants to manually inspect through a large set of annotations or features. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedtobam/2.30.0+galaxy1",
    "name": "bedtools BED to BAM",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedToBam converts features in a feature file to BAM format. This is useful as an efficient means of storing large genome annotations in a compact, indexed format for visualization purposes. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "tabular"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_maskfastabed/2.30.0",
    "name": "bedtools MaskFastaBed",
    "description": "use intervals to mask sequences from a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bedtools maskfasta masks sequences in a FASTA file based on intervals defined in a feature file. The headers in the input FASTA file must exactly match the chromosome column in the feature file. This may be useful fro creating your own masked genome file based on custom annotations or for masking all but your target regions when aligning sequence data from a targeted capture experiment. .. image:: $PATH_TO_IMAGES/maskfasta-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_shufflebed/2.30.0+galaxy1",
    "name": "bedtools ShuffleBed",
    "description": "randomly redistrubute intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools shuffle will randomly permute the genomic locations of a feature file among a genome defined in a genome file. One can also provide an exclusions BED/bedGraph/GFF/VCF/EncodePeak file that lists regions where you do not want the permuted features to be placed. For example, one might want to prevent features from being placed in known genome gaps. shuffle is useful as a null basis against which to test the significance of associations of one feature with another. .. image:: $PATH_TO_IMAGES/shuffle-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_nucbed/2.30.0",
    "name": "bedtools NucBed",
    "description": "profile the nucleotide content of intervals in a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Profiles the nucleotide content of intervals in a fasta file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bamtobed/2.30.0+galaxy2",
    "name": "bedtools BAM to BED",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy2",
    "help": "**What it does** bedtools bamtobed is a conversion utility that converts sequence alignments in BAM format into BED, BED12, and/or BEDPE records. .. class:: infomark The \"Report spliced BAM alignment...\" option breaks BAM alignments with the \"N\" (splice) operator into distinct BED entries. For example, using this option on a CIGAR such as 50M1000N50M would, by default, produce a single BED record that spans 1100bp. However, using this option, it would create two separate BED records that are each 50bp in size and are separated by 1000bp (the size of the N operation). This is important for RNA-seq and structural variation experiments. .. class:: warningmark If using a custom BAM alignment TAG as the BED score, note that this must be a numeric tag (e.g., type \"i\" as in NM:i:0). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "unsorted.bam"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_tagbed/2.30.0",
    "name": "bedtools TagBed",
    "description": "tag BAM alignments based on overlaps with interval files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Annotates a BAM file based on overlaps with multiple BED/bedGraph/GFF/VCF/EncodePeak files on the intervals in an input bam file ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_expandbed/2.30.0",
    "name": "bedtools ExpandBed",
    "description": "replicate lines based on lists of values in columns",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Replicate lines in a file based on columns of comma-separated values. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_genomecoveragebed/2.30.0",
    "name": "bedtools Genome Coverage",
    "description": "compute the coverage over an entire genome",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** This tool calculates the genome-wide coverage of intervals defined in a BAM or BED file and reports them in BedGraph format. .. image:: $PATH_TO_IMAGES/genomecov-glyph.png .. class:: warningmark The input BED or BAM file must be sorted by chromosome name (but doesn't necessarily have to be sorted by start position). ----- **Example 1** Input (BED format)- Overlapping, un-sorted intervals:: chr1 140 176 chr1 100 130 chr1 120 147 Output (BedGraph format)- Sorted, non-overlapping intervals, with coverage value on the 4th column:: chr1 100 120 1 chr1 120 130 2 chr1 130 140 1 chr1 140 147 2 chr1 147 176 1 ----- **Example 2 - with ZERO-Regions selected (assuming hg19)** Input (BED format)- Overlapping, un-sorted intervals:: chr1 140 176 chr1 100 130 chr1 120 147 BedGraph output will contain five columns: * 1. Chromosome name (or 'genome' for whole-genome coverage) * 2. Coverage depth * 3. The number of bases on chromosome (or genome) with depth equal to column 2. * 4. The size of chromosome (or entire genome) in base pairs * 5. The fraction of bases on chromosome (or entire genome) with depth equal to column 2. **Example Output**: chr2L 0 1379895 23011544 0.0599653 chr2L 1 837250 23011544 0.0363839 chr2L 2 904442 23011544 0.0393038 chr2L 3 913723 23011544 0.0397072 chr2L 4 952166 23011544 0.0413778 chr2L 5 967763 23011544 0.0420555 chr2L 6 986331 23011544 0.0428624 chr2L 7 998244 23011544 0.0433801 chr2L 8 995791 23011544 0.0432735 chr2L 9 996398 23011544 0.0432999 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular",
      "bam"
    ],
    "output_formats": [
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_windowbed/2.30.0",
    "name": "bedtools WindowBed",
    "description": "find overlapping intervals within a window around an interval",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Similar to bedtools intersect, window searches for overlapping features in A and B. However, window adds a specified number (1000, by default) of base pairs upstream and downstream of each feature in A. In effect, this allows features in B that are near features in A to be detected. .. image:: $PATH_TO_IMAGES/window-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_jaccard/2.30.0",
    "name": "bedtools JaccardBed",
    "description": "calculate the distribution of relative distances between two files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** By default, bedtools jaccard reports the length of the intersection, the length of the union (minus the intersection), the final Jaccard statistic reflecting the similarity of the two sets, as well as the number of intersections. Whereas the bedtools intersect tool enumerates each an every intersection between two sets of genomic intervals, one often needs a single statistic reflecting the similarity of the two sets based on the intersections between them. The Jaccard statistic is used in set theory to represent the ratio of the intersection of two sets to the union of the two sets. Similarly, Favorov et al [1] reported the use of the Jaccard statistic for genome intervals: specifically, it measures the ratio of the number of intersecting base pairs between two sets to the number of base pairs in the union of the two sets. The bedtools jaccard tool implements this statistic, yet modifies the statistic such that the length of the intersection is subtracted from the length of the union. As a result, the final statistic ranges from 0.0 to 1.0, where 0.0 represents no overlap and 1.0 represent complete overlap. .. image:: $PATH_TO_IMAGES/jaccard-glyph.png .. class:: warningmark The jaccard tool requires that your data is pre-sorted by chromosome and then by start position (e.g., sort -k1,1 -k2,2n in.bed > in.sorted.bed for BED files). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_map/2.30.0.3",
    "name": "bedtools MapBed",
    "description": "apply a function to a column for each overlapping interval",
    "categories": [
      "BED"
    ],
    "version": "2.30.0.3",
    "help": "**What it does** bedtools map allows one to map overlapping features in a B file onto features in an A file and apply statistics and/or summary operations on those features. .. image:: $PATH_TO_IMAGES/map-glyph.png .. class:: infomark bedtools map requires each input file to be sorted by genome coordinate. For BED files, this can be done with sort -k1,1 -k2,2n. Other sorting criteria are allowed if a genome file (-g) is provides that specifies the expected chromosome order. .. class:: infomark The map tool is substantially faster in versions 2.19.0 and later. The plot below demonstrates the increased speed when, for example, counting the number of exome alignments that align to each exon. The bedtools times are compared to the bedops bedmap utility as a point of reference. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_intersectbed/2.30.0+galaxy1",
    "name": "bedtools Intersect intervals",
    "description": "find overlapping intervals in various ways",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** By far, the most common question asked of two sets of genomic features is whether or not any of the features in the two sets overlap with one another. This is known as feature intersection. bedtools intersect allows one to screen for overlaps between two sets of genomic features. Moreover, it allows one to have fine control as to how the intersections are reported. bedtools intersect works with both BED/bedGraph/GFF/VCF/EncodePeak and BAM files as input. .. image:: $PATH_TO_IMAGES/intersect-glyph.png .. class:: infomark Note that each BAM alignment is treated individually. Therefore, if one end of a paired-end alignment overlaps an interval in the BED file, yet the other end does not, the output file will only include the overlapping end. .. class:: infomark Note that a BAM alignment will be sent to the output file **once** even if it overlaps more than one interval in the BED file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bed12tobed6/2.30.0",
    "name": "bedtools BED12 to BED6",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bed12ToBed6 is a convenience tool that converts BED features in BED12 (a.k.a. blocked BED features such as genes) to discrete BED6 features. For example, in the case of a gene with six exons, bed12ToBed6 would create six separate BED6 features (i.e., one for each exon). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_groupbybed/2.30.0",
    "name": "bedtools GroupByBed",
    "description": "group by common cols and summarize other cols",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Replicate lines in a file based on columns of comma-separated values. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_unionbedgraph/2.30.0",
    "name": "bedtools Merge BedGraph files",
    "description": "combines coverage intervals from multiple BEDGRAPH files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** This tool merges multiple BedGraph files, allowing direct and fine-scale coverage comparisons among many samples/files. The BedGraph files need not represent the same intervals; the tool will identify both common and file-specific intervals. In addition, the BedGraph values need not be numeric: one can use any text as the BedGraph value and the tool will compare the values from multiple files. .. class:: warningmark This tool requires that each BedGraph file is reference-sorted (chrom, then start) and contains non-overlapping intervals (within a given file). ------ **Example input**:: # 1.bedgraph chr1 1000 1500 10 chr1 2000 2100 20 # 2.bedgraph chr1 900 1600 60 chr1 1700 2050 50 # 3.bedgraph chr1 1980 2070 80 chr1 2090 2100 20 ------ **Examples using the Zero Coverage checkbox** Output example (*without* checking \"Report regions with zero coverage\"):: chr1 900 1000 0 60 0 chr1 1000 1500 10 60 0 chr1 1500 1600 0 60 0 chr1 1700 1980 0 50 0 chr1 1980 2000 0 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 0 80 chr1 2070 2090 20 0 0 chr1 2090 2100 20 0 20 Output example (*with* checking \"Report regions with zero coverage\"). The lines marked with (*) are not covered in any input file, but are still reported (The asterisk marking does not appear in the file).:: chr1 0 900 0 0 0 (*) chr1 900 1000 0 60 0 chr1 1000 1500 10 60 0 chr1 1500 1600 0 60 0 chr1 1600 1700 0 0 0 (*) chr1 1700 1980 0 50 0 chr1 1980 2000 0 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 0 80 chr1 2070 2090 20 0 0 chr1 2090 2100 20 0 20 chr1 2100 247249719 0 0 0 (*) ------ **Examples adjusting the \"Filler value\" for no-covered intervals** The default value is '0', but you can use any other value. Output example with **filler = N/A**:: chr1 900 1000 N/A 60 N/A chr1 1000 1500 10 60 N/A chr1 1500 1600 N/A 60 N/A chr1 1600 1700 N/A N/A N/A chr1 1700 1980 N/A 50 N/A chr1 1980 2000 N/A 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 N/A 80 chr1 2070 2090 20 N/A N/A chr1 2090 2100 20 N/A 20 ------ **Examples using the \"sample name\" labels**:: chrom start end WT-1 WT-2 KO-1 chr1 900 1000 N/A 60 N/A chr1 1000 1500 10 60 N/A chr1 1500 1600 N/A 60 N/A chr1 1600 1700 N/A N/A N/A chr1 1700 1980 N/A 50 N/A chr1 1980 2000 N/A 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 N/A 80 chr1 2070 2090 20 N/A N/A chr1 2090 2100 20 N/A 20 ------ **Non-numeric values** The input BedGraph files can contain any kind of value in the fourth column, not necessarily a numeric value. Input Example:: File-1 File-2 chr1 200 300 Sample1 chr1 100 240 0.75 chr1 400 450 Sample1 chr1 250 700 0.43 chr1 530 600 Sample2 Output Example:: chr1 100 200 0 0.75 chr1 200 240 Sample1 0.75 chr1 240 250 Sample1 0 chr1 250 300 Sample1 0.43 chr1 300 400 0 0.43 chr1 400 450 Sample1 0.43 chr1 450 530 0 0.43 chr1 530 600 Sample2 0.43 chr1 600 700 0 0.43 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bedgraph",
      "tabular"
    ],
    "output_formats": [
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_clusterbed/2.30.0",
    "name": "bedtools ClusterBed",
    "description": "cluster overlapping/nearby intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Similar to merge, cluster report each set of overlapping or book-ended features in an interval file. In contrast to merge, cluster does not flatten the cluster of intervals into a new meta-interval; instead, it assigns an unique cluster ID to each record in each cluster. This is useful for having fine control over how sets of overlapping intervals in a single interval file are combined. .. image:: $PATH_TO_IMAGES/cluster-glyph.png .. class:: warningmark bedtools cluster requires that you presort your data by chromosome and then by start position (e.g., sort -k1,1 -k2,2n in.bed > in.sorted.bed for BED files). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_makewindowsbed/2.30.0",
    "name": "bedtools MakeWindowsBed",
    "description": "make interval windows across a genome",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Makes adjacent or sliding windows across a genome or BED file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_slopbed/2.30.0+galaxy1",
    "name": "bedtools SlopBed",
    "description": "adjust the size of intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools slop will increase the size of each feature in a feature file by a user-defined number of bases. While something like this could be done with an awk '{OFS=\"\\t\" print $1,$2-&lt;slop>,$3+&lt;slop>}', bedtools slop will restrict the resizing to the size of the chromosome (i.e. no start &lt; 0 and no end > chromosome size). .. image:: $PATH_TO_IMAGES/slop-glyph.png .. class:: warningmark In order to prevent the extension of intervals beyond chromosome boundaries, bedtools slop requires a genome file defining the length of each chromosome or contig. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_randombed/2.30.0+galaxy1",
    "name": "bedtools RandomBed",
    "description": "generate random intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools random will generate a random set of intervals in BED6 format. One can specify both the number (-n) and the size (-l) of the intervals that should be generated. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedtoigv/2.30.0",
    "name": "bedtools BED to IGV",
    "description": "create batch script for taking IGV screenshots",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Creates a batch script to create IGV images at each interval defined in a BED/bedGraph/GFF/VCF/EncodePeak file. **Notes** (1) The resulting script is meant to be run from within IGV. (2) It is assumed that prior to running the script, you've loaded the proper genome and tracks. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_complementbed/2.30.0+galaxy1",
    "name": "bedtools ComplementBed",
    "description": "Extract intervals not represented by an interval file",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools complement returns all intervals in a genome that are not covered by at least one interval in the input BED/bedGraph/GFF/VCF/EncodePeak file. .. image:: $PATH_TO_IMAGES/complement-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_coveragebed/2.30.0",
    "name": "bedtools Compute both the depth and breadth of coverage",
    "description": "of features in file B on the features in file A (bedtools coverage)",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** `bedtools coverage`_ computes both the *depth* and *breadth* of coverage of features in file B on the features in file A. For example, ``bedtools coverage`` can compute the coverage of sequence alignments (file B) across 1 kilobase (arbitrary) windows (file A) tiling a genome of interest. One advantage that ``bedtools coverage`` offers is that it not only *counts* the number of features that overlap an interval in file A, it also computes the fraction of bases in the interval in A that were overlapped by one or more features. Thus, ``bedtools coverage`` also computes the *breadth* of coverage for each interval in A. .. _bedtools coverage: http://bedtools.readthedocs.org/en/latest/content/tools/coverage.html .. class:: infomark The lines in the output will be comprised of each interval in A, followed by: 1. The number of features in B that overlapped (by at least one base pair) the A interval. 2. The number of bases in A that had non-zero coverage from features in B. 3. The length of the entry in A. 4. The fraction of bases in A that had non-zero coverage from features in B. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_fisher/2.30.0+galaxy1",
    "name": "bedtools FisherBed",
    "description": "calculate Fisher statistic between two feature files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** Perform fishers exact test on the number of overlaps/unique intervals between 2 files. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_mergebed/2.30.0",
    "name": "bedtools MergeBED",
    "description": "combine overlapping/nearby intervals into a single interval",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bedtools merge combines overlapping or \"book-ended\" features in an interval file into a single feature which spans all of the combined features. .. image:: $PATH_TO_IMAGES/merge-glyph.png .. class:: warningmark bedtools merge requires that you presort your data by chromosome and then by start position. Default behavior By default, ``bedtools merge`` combines overlapping (by at least 1 bp) and/or bookended intervals into a single, \"flattened\" or \"merged\" interval. :: $ cat A.bed chr1 100 200 chr1 180 250 chr1 250 500 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 500 chr1 501 1000 *-s* Enforcing \"strandedness\" The ``-s`` option will only merge intervals that are overlapping/bookended *and* are on the same strand. :: $ cat A.bed chr1 100 200 a1 1 + chr1 180 250 a2 2 + chr1 250 500 a3 3 - chr1 501 1000 a4 4 + $ bedtools merge -i A.bed -s chr1 100 250 + chr1 501 1000 + chr1 250 500 - *-d* Controlling how close two features must be in order to merge By default, only overlapping or book-ended features are combined into a new feature. However, one can force ``merge`` to combine more distant features with the ``-d`` option. For example, were one to set ``-d`` to 1000, any features that overlap or are within 1000 base pairs of one another will be combined. :: $ cat A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed -d 1000 chr1 100 200 1000 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multicovtbed/2.30.0",
    "name": "bedtools MultiCovBed",
    "description": "counts coverage from multiple BAMs at specific intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bedtools multicov, reports the count of alignments from multiple position-sorted and indexed BAM files that overlap intervals in a BED file. Specifically, for each BED interval provided, it reports a separate count of overlapping alignments from each BAM file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_overlapbed/2.30.0",
    "name": "bedtools OverlapBed",
    "description": "computes the amount of overlap from two intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** overlap computes the amount of overlap (in the case of positive values) or distance (in the case of negative values) between feature coordinates occurring on the same input line and reports the result at the end of the same line. In this way, it is a useful method for computing custom overlap scores from the output of other BEDTools. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_flankbed/2.30.0+galaxy1",
    "name": "bedtools FlankBed",
    "description": "create new intervals from the flanks of existing intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools flank will optionally create flanking intervals whose size is user-specified fraction of the original interval. .. image:: $PATH_TO_IMAGES/flank-glyph.png .. class:: warningmark In order to prevent creating intervals that violate chromosome boundaries, bedTools flank requires a bedTool genome file defining the length of each chromosome or contig. . This should be a two column tabular file with the chromosome name in the first column and the END coordinate of the chromosome in the second column. If you need this data for any genome that is at UCSC (http://genome.ucsc.edu), it can be extracted from the Table Browser with the \"Get Data: UCSC Main\" tool. Set \"group\" to \"All Tables\", \"table\" to \"chromInfo\", and \"output format\" to \"all fields from selected table\". ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_annotatebed/2.30.0",
    "name": "bedtools AnnotateBed",
    "description": "annotate coverage of features from multiple files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bedtools annotate, well, annotates one BED/bedGraph/GFF/VCF/EncodePeak file with the coverage and number of overlaps observed from multiple other BED/bedGraph/GFF/VCF/EncodePeak files. In this way, it allows one to ask to what degree one feature coincides with multiple other feature types with a single command. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedpetobam/2.30.0+galaxy1",
    "name": "bedtools BEDPE to BAM",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** Converts feature records to BAM format. .. class:: warningmark BED files must be at least BED4 to create BAM (needs name field). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "unsorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_reldistbed/2.30.0",
    "name": "bedtools ReldistBed",
    "description": "calculate the distribution of relative distances",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Traditional approaches to summarizing the similarity between two sets of genomic intervals are based upon the number or proportion of intersecting intervals. However, such measures are largely blind to spatial correlations between the two sets where, dpesite consistent spacing or proximity, intersections are rare (for example, enhancers and transcription start sites rarely overlap, yet they are much closer to one another than two sets of random intervals). Favorov et al proposed a relative distance metric that describes distribution of relative distances between each interval in one set nd the two closest intervals in another set (see figure above). If there is no spatial correlation between the two sets, one would expect the relative distances to be uniformaly distributed among the relative distances ranging from 0 to 0.5. If, however, the intervals tend to be much closer than expected by chance, the distribution of observed relative distances would be shifted towards low relative distance values (e.g., the figure below). .. image:: $PATH_TO_IMAGES/reldist-glyph.png .. class:: infomark ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_getfastabed/2.30.0+galaxy1",
    "name": "bedtools getfasta",
    "description": "use intervals to extract sequences from a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** bedtools getfasta will extract the sequence defined by the coordinates in a BED interval and create a new FASTA entry in the output file for each extracted sequence. By default, the FASTA header for each extracted sequence will be formatted as follows: >chrom>:&lt;start>-&lt;end>. .. image:: $PATH_TO_IMAGES/getfasta-glyph.png .. class:: warningmark 1. The headers in the input FASTA file must exactly match the chromosome column in the BED file. 2. You can use the UNIX fold command to set the line width of the FASTA output. For example, fold -w 60 will make each line of the FASTA file have at most 60 nucleotides for easy viewing. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_closestbed/2.30.0",
    "name": "bedtools ClosestBed",
    "description": "find the closest, potentially non-overlapping interval",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Similar to intersectBed, closestBed searches for overlapping features in A and B. In the event that no feature in B overlaps the current feature in A, closestBed will report the closest (that is, least genomic distance from the start or end of A) feature in B. For example, one might want to find which is the closest gene to a significant GWAS polymorphism. Note that closestBed will report an overlapping feature as the closestthat is, it does not restrict to closest non-overlapping feature. .. image:: $PATH_TO_IMAGES/closest-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_subtractbed/2.30.0",
    "name": "bedtools SubtractBed",
    "description": "remove intervals based on overlaps",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** bedtools subtract searches for features in B that overlap A. If an overlapping feature is found in B, the overlapping portion is removed from A and the remaining portion of A is reported. If a feature in B overlaps all of a feature in A, the A feature will not be reported. .. image:: $PATH_TO_IMAGES/subtract-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multiintersectbed/2.30.0",
    "name": "bedtools Multiple Intersect",
    "description": "identifies common intervals among multiple interval files",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** This tool identifies common intervals among multiple, sorted BED files. Intervals can be common among 0 to N of the N input BED files. .. class:: warningmark This tool requires that each BED file is reference-sorted (chrom, then start). .. class:: infomark The output file will contain five fixed columns, plus additional columns for each BED file: * 1. Chromosome name (or 'genome' for whole-genome coverage). * 2. The zero-based start position of the interval. * 3. The one-based end position of the interval. * 4. The number of input files that had at least one feature overlapping this interval. * 5. A list of input files or labels that had at least one feature overlapping this interval. * 6. For each input file, an indication (1 = Yes, 0 = No) of whether or not the file had at least one feature overlapping this interval. ------ **Example input**:: # a.bed chr1 6 12bed chr1 10 20 chr1 22 27 chr1 24 30 # b.bed chr1 12 32 chr1 14 30 # c.bed chr1 8 15 chr1 10 14 chr1 32 34 ------ **Example without a header and without reporting intervals with zero coverage**:: chr1 6 8 1 1 1 0 0 chr1 8 12 2 1,3 1 0 1 chr1 12 15 3 1,2,3 1 1 1 chr1 15 20 2 1,2 1 1 0 chr1 20 22 1 2 0 1 0 chr1 22 30 2 1,2 1 1 0 chr1 30 32 1 2 0 1 0 chr1 32 34 1 3 0 0 1 **Example adding a header line**:: chrom start end num list a.bed b.bed c.bed chr1 6 8 1 1 1 0 0 chr1 8 12 2 1,3 1 0 1 chr1 12 15 3 1,2,3 1 1 1 chr1 15 20 2 1,2 1 1 0 chr1 20 22 1 2 0 1 0 chr1 22 30 2 1,2 1 1 0 chr1 30 32 1 2 0 1 0 chr1 32 34 1 3 0 0 1 **Example adding a header line and custom file labels**:: chrom start end num list joe bob sue chr1 6 8 1 joe 1 0 0 chr1 8 12 2 joe,sue 1 0 1 chr1 12 15 3 joe,bob,sue 1 1 1 chr1 15 20 2 joe,bob 1 1 0 chr1 20 22 1 bob 0 1 0 chr1 22 30 2 joe,bob 1 1 0 chr1 30 32 1 bob 0 1 0 chr1 32 34 1 sue 0 0 1 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_spacingbed/2.30.0",
    "name": "bedtools SpacingBed",
    "description": "reports the distances between features",
    "categories": [
      "BED"
    ],
    "version": "2.30.0",
    "help": "**What it does** Report the spacing between intervals in a file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_sortbed/2.30.0+galaxy1",
    "name": "bedtools SortBED",
    "description": "order the intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** Sorts a feature file by chromosome and other criteria. .. class:: warningmark It should be noted that sortBed is merely a convenience utility, as the UNIX sort utility will sort BED files more quickly while using less memory. For example, UNIX sort will sort a BED file by chromosome then by start position in the following manner: sort -k 1,1 -k2,2 -n a.bed ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_coveragebed/2.30.0+galaxy1",
    "name": "bedtools Compute both the depth and breadth of coverage",
    "description": "of features in file B on the features in file A (bedtools coverage)",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy1",
    "help": "**What it does** `bedtools coverage`_ computes both the *depth* and *breadth* of coverage of features in file B on the features in file A. For example, ``bedtools coverage`` can compute the coverage of sequence alignments (file B) across 1 kilobase (arbitrary) windows (file A) tiling a genome of interest. One advantage that ``bedtools coverage`` offers is that it not only *counts* the number of features that overlap an interval in file A, it also computes the fraction of bases in the interval in A that were overlapped by one or more features. Thus, ``bedtools coverage`` also computes the *breadth* of coverage for each interval in A. .. _bedtools coverage: http://bedtools.readthedocs.org/en/latest/content/tools/coverage.html .. class:: infomark The lines in the output will be comprised of each interval in A, followed by: 1. The number of features in B that overlapped (by at least one base pair) the A interval. 2. The number of bases in A that had non-zero coverage from features in B. 3. The length of the entry in A. 4. The fraction of bases in A that had non-zero coverage from features in B. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_sortbed/2.30.0+galaxy2",
    "name": "bedtools SortBED",
    "description": "order the intervals",
    "categories": [
      "BED"
    ],
    "version": "2.30.0+galaxy2",
    "help": "**What it does** Sorts a feature file by chromosome and other criteria. .. class:: warningmark It should be noted that sortBed is merely a convenience utility, as the UNIX sort utility will sort BED files more quickly while using less memory. For example, UNIX sort will sort a BED file by chromosome then by start position in the following manner: sort -k 1,1 -k2,2 -n a.bed ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedops_sortbed/bedops-sort-bed/2.4.41",
    "name": "bedops sort-bed",
    "description": "",
    "categories": [
      "BED"
    ],
    "version": "2.4.41",
    "help": "What this tool does The sort-bed utility sorts BED files of any size, even larger than system memory. BED files that are in lexicographic-chromosome order allow BEDOPS utilities to work efficiently with data from any species without software modifications. Further, sorted files can be traversed very quickly. Sorted BED order is defined first by lexicographic chromosome order, then ascending integer start coordinate order, and finally by ascending integer end coordinate order. To make the sort order unambiguous, a lexicographical sort is applied on fourth and subsequent columns, where present in the input BED dataset. Input The sort-bed utility requires one or more three-column BED file(s). Support for common headers (such as UCSC BED track headers) is included, although headers will be stripped from the output. Output Sort order is defined by a lexicographical sort on chromosome name, a numerical sort on start coordinates, a numerical sort on stop coordinates where there are start matches, and finally a lexicographical sort on the remainder of the BED element (if additional columns are present). Additional options may be specified to print only unique or duplicate elements.",
    "input_formats": [
      "bed"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_links/2.31.1",
    "name": "bedtools LinksBed",
    "description": "create a HTML page of links to UCSC locations",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Creates an HTML file with links to an instance of the UCSC Genome Browser for all features / intervals in a file. This is useful for cases when one wants to manually inspect through a large set of annotations or features. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedtobam/2.31.1+galaxy0",
    "name": "bedtools BED to BAM",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedToBam converts features in a feature file to BAM format. This is useful as an efficient means of storing large genome annotations in a compact, indexed format for visualization purposes. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "tabular"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_maskfastabed/2.31.1",
    "name": "bedtools MaskFastaBed",
    "description": "use intervals to mask sequences from a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bedtools maskfasta masks sequences in a FASTA file based on intervals defined in a feature file. The headers in the input FASTA file must exactly match the chromosome column in the feature file. This may be useful fro creating your own masked genome file based on custom annotations or for masking all but your target regions when aligning sequence data from a targeted capture experiment. .. image:: $PATH_TO_IMAGES/maskfasta-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_shufflebed/2.31.1+galaxy0",
    "name": "bedtools ShuffleBed",
    "description": "randomly redistrubute intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools shuffle will randomly permute the genomic locations of a feature file among a genome defined in a genome file. One can also provide an exclusions BED/bedGraph/GFF/VCF/EncodePeak file that lists regions where you do not want the permuted features to be placed. For example, one might want to prevent features from being placed in known genome gaps. shuffle is useful as a null basis against which to test the significance of associations of one feature with another. .. image:: $PATH_TO_IMAGES/shuffle-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_nucbed/2.31.1",
    "name": "bedtools NucBed",
    "description": "profile the nucleotide content of intervals in a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Profiles the nucleotide content of intervals in a fasta file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bamtobed/2.31.1+galaxy0",
    "name": "bedtools BAM to BED",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools bamtobed is a conversion utility that converts sequence alignments in BAM format into BED, BED12, and/or BEDPE records. .. class:: infomark The \"Report spliced BAM alignment...\" option breaks BAM alignments with the \"N\" (splice) operator into distinct BED entries. For example, using this option on a CIGAR such as 50M1000N50M would, by default, produce a single BED record that spans 1100bp. However, using this option, it would create two separate BED records that are each 50bp in size and are separated by 1000bp (the size of the N operation). This is important for RNA-seq and structural variation experiments. .. class:: warningmark If using a custom BAM alignment TAG as the BED score, note that this must be a numeric tag (e.g., type \"i\" as in NM:i:0). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "unsorted.bam"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_tagbed/2.31.1",
    "name": "bedtools TagBed",
    "description": "tag BAM alignments based on overlaps with interval files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Annotates a BAM file based on overlaps with multiple BED/bedGraph/GFF/VCF/EncodePeak files on the intervals in an input bam file ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_expandbed/2.31.1",
    "name": "bedtools ExpandBed",
    "description": "replicate lines based on lists of values in columns",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Replicate lines in a file based on columns of comma-separated values. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_genomecoveragebed/2.31.1",
    "name": "bedtools Genome Coverage",
    "description": "compute the coverage over an entire genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** This tool calculates the genome-wide coverage of intervals defined in a BAM or BED file and reports them in BedGraph format. .. image:: $PATH_TO_IMAGES/genomecov-glyph.png .. class:: warningmark The input BED or BAM file must be sorted by chromosome name (but doesn't necessarily have to be sorted by start position). ----- **Example 1** Input (BED format)- Overlapping, un-sorted intervals:: chr1 140 176 chr1 100 130 chr1 120 147 Output (BedGraph format)- Sorted, non-overlapping intervals, with coverage value on the 4th column:: chr1 100 120 1 chr1 120 130 2 chr1 130 140 1 chr1 140 147 2 chr1 147 176 1 ----- **Example 2 - with ZERO-Regions selected (assuming hg19)** Input (BED format)- Overlapping, un-sorted intervals:: chr1 140 176 chr1 100 130 chr1 120 147 BedGraph output will contain five columns: * 1. Chromosome name (or 'genome' for whole-genome coverage) * 2. Coverage depth * 3. The number of bases on chromosome (or genome) with depth equal to column 2. * 4. The size of chromosome (or entire genome) in base pairs * 5. The fraction of bases on chromosome (or entire genome) with depth equal to column 2. **Example Output**: chr2L 0 1379895 23011544 0.0599653 chr2L 1 837250 23011544 0.0363839 chr2L 2 904442 23011544 0.0393038 chr2L 3 913723 23011544 0.0397072 chr2L 4 952166 23011544 0.0413778 chr2L 5 967763 23011544 0.0420555 chr2L 6 986331 23011544 0.0428624 chr2L 7 998244 23011544 0.0433801 chr2L 8 995791 23011544 0.0432735 chr2L 9 996398 23011544 0.0432999 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular",
      "bam"
    ],
    "output_formats": [
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_windowbed/2.31.1",
    "name": "bedtools WindowBed",
    "description": "find overlapping intervals within a window around an interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Similar to bedtools intersect, window searches for overlapping features in A and B. However, window adds a specified number (1000, by default) of base pairs upstream and downstream of each feature in A. In effect, this allows features in B that are near features in A to be detected. .. image:: $PATH_TO_IMAGES/window-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_jaccard/2.31.1",
    "name": "bedtools JaccardBed",
    "description": "calculate the distribution of relative distances between two files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** By default, bedtools jaccard reports the length of the intersection, the length of the union (minus the intersection), the final Jaccard statistic reflecting the similarity of the two sets, as well as the number of intersections. Whereas the bedtools intersect tool enumerates each an every intersection between two sets of genomic intervals, one often needs a single statistic reflecting the similarity of the two sets based on the intersections between them. The Jaccard statistic is used in set theory to represent the ratio of the intersection of two sets to the union of the two sets. Similarly, Favorov et al [1] reported the use of the Jaccard statistic for genome intervals: specifically, it measures the ratio of the number of intersecting base pairs between two sets to the number of base pairs in the union of the two sets. The bedtools jaccard tool implements this statistic, yet modifies the statistic such that the length of the intersection is subtracted from the length of the union. As a result, the final statistic ranges from 0.0 to 1.0, where 0.0 represents no overlap and 1.0 represent complete overlap. .. image:: $PATH_TO_IMAGES/jaccard-glyph.png .. class:: warningmark The jaccard tool requires that your data is pre-sorted by chromosome and then by start position (e.g., sort -k1,1 -k2,2n in.bed > in.sorted.bed for BED files). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_map/2.31.1.3",
    "name": "bedtools MapBed",
    "description": "apply a function to a column for each overlapping interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1.3",
    "help": "**What it does** bedtools map allows one to map overlapping features in a B file onto features in an A file and apply statistics and/or summary operations on those features. .. image:: $PATH_TO_IMAGES/map-glyph.png .. class:: infomark bedtools map requires each input file to be sorted by genome coordinate. For BED files, this can be done with sort -k1,1 -k2,2n. Other sorting criteria are allowed if a genome file (-g) is provides that specifies the expected chromosome order. .. class:: infomark The map tool is substantially faster in versions 2.19.0 and later. The plot below demonstrates the increased speed when, for example, counting the number of exome alignments that align to each exon. The bedtools times are compared to the bedops bedmap utility as a point of reference. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_intersectbed/2.31.1+galaxy0",
    "name": "bedtools Intersect intervals",
    "description": "find overlapping intervals in various ways",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** By far, the most common question asked of two sets of genomic features is whether or not any of the features in the two sets overlap with one another. This is known as feature intersection. bedtools intersect allows one to screen for overlaps between two sets of genomic features. Moreover, it allows one to have fine control as to how the intersections are reported. bedtools intersect works with both BED/bedGraph/GFF/VCF/EncodePeak and BAM files as input. .. image:: $PATH_TO_IMAGES/intersect-glyph.png .. class:: infomark Note that each BAM alignment is treated individually. Therefore, if one end of a paired-end alignment overlaps an interval in the BED file, yet the other end does not, the output file will only include the overlapping end. .. class:: infomark Note that a BAM alignment will be sent to the output file **once** even if it overlaps more than one interval in the BED file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bed12tobed6/2.31.1",
    "name": "bedtools BED12 to BED6",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bed12ToBed6 is a convenience tool that converts BED features in BED12 (a.k.a. blocked BED features such as genes) to discrete BED6 features. For example, in the case of a gene with six exons, bed12ToBed6 would create six separate BED6 features (i.e., one for each exon). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_groupbybed/2.31.1",
    "name": "bedtools GroupByBed",
    "description": "group by common cols and summarize other cols",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Replicate lines in a file based on columns of comma-separated values. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_unionbedgraph/2.31.1",
    "name": "bedtools Merge BedGraph files",
    "description": "combines coverage intervals from multiple BEDGRAPH files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** This tool merges multiple BedGraph files, allowing direct and fine-scale coverage comparisons among many samples/files. The BedGraph files need not represent the same intervals; the tool will identify both common and file-specific intervals. In addition, the BedGraph values need not be numeric: one can use any text as the BedGraph value and the tool will compare the values from multiple files. .. class:: warningmark This tool requires that each BedGraph file is reference-sorted (chrom, then start) and contains non-overlapping intervals (within a given file). ------ **Example input**:: # 1.bedgraph chr1 1000 1500 10 chr1 2000 2100 20 # 2.bedgraph chr1 900 1600 60 chr1 1700 2050 50 # 3.bedgraph chr1 1980 2070 80 chr1 2090 2100 20 ------ **Examples using the Zero Coverage checkbox** Output example (*without* checking \"Report regions with zero coverage\"):: chr1 900 1000 0 60 0 chr1 1000 1500 10 60 0 chr1 1500 1600 0 60 0 chr1 1700 1980 0 50 0 chr1 1980 2000 0 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 0 80 chr1 2070 2090 20 0 0 chr1 2090 2100 20 0 20 Output example (*with* checking \"Report regions with zero coverage\"). The lines marked with (*) are not covered in any input file, but are still reported (The asterisk marking does not appear in the file).:: chr1 0 900 0 0 0 (*) chr1 900 1000 0 60 0 chr1 1000 1500 10 60 0 chr1 1500 1600 0 60 0 chr1 1600 1700 0 0 0 (*) chr1 1700 1980 0 50 0 chr1 1980 2000 0 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 0 80 chr1 2070 2090 20 0 0 chr1 2090 2100 20 0 20 chr1 2100 247249719 0 0 0 (*) ------ **Examples adjusting the \"Filler value\" for no-covered intervals** The default value is '0', but you can use any other value. Output example with **filler = N/A**:: chr1 900 1000 N/A 60 N/A chr1 1000 1500 10 60 N/A chr1 1500 1600 N/A 60 N/A chr1 1600 1700 N/A N/A N/A chr1 1700 1980 N/A 50 N/A chr1 1980 2000 N/A 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 N/A 80 chr1 2070 2090 20 N/A N/A chr1 2090 2100 20 N/A 20 ------ **Examples using the \"sample name\" labels**:: chrom start end WT-1 WT-2 KO-1 chr1 900 1000 N/A 60 N/A chr1 1000 1500 10 60 N/A chr1 1500 1600 N/A 60 N/A chr1 1600 1700 N/A N/A N/A chr1 1700 1980 N/A 50 N/A chr1 1980 2000 N/A 50 80 chr1 2000 2050 20 50 80 chr1 2050 2070 20 N/A 80 chr1 2070 2090 20 N/A N/A chr1 2090 2100 20 N/A 20 ------ **Non-numeric values** The input BedGraph files can contain any kind of value in the fourth column, not necessarily a numeric value. Input Example:: File-1 File-2 chr1 200 300 Sample1 chr1 100 240 0.75 chr1 400 450 Sample1 chr1 250 700 0.43 chr1 530 600 Sample2 Output Example:: chr1 100 200 0 0.75 chr1 200 240 Sample1 0.75 chr1 240 250 Sample1 0 chr1 250 300 Sample1 0.43 chr1 300 400 0 0.43 chr1 400 450 Sample1 0.43 chr1 450 530 0 0.43 chr1 530 600 Sample2 0.43 chr1 600 700 0 0.43 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bedgraph",
      "tabular"
    ],
    "output_formats": [
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_clusterbed/2.31.1",
    "name": "bedtools ClusterBed",
    "description": "cluster overlapping/nearby intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Similar to merge, cluster report each set of overlapping or book-ended features in an interval file. In contrast to merge, cluster does not flatten the cluster of intervals into a new meta-interval; instead, it assigns an unique cluster ID to each record in each cluster. This is useful for having fine control over how sets of overlapping intervals in a single interval file are combined. .. image:: $PATH_TO_IMAGES/cluster-glyph.png .. class:: warningmark bedtools cluster requires that you presort your data by chromosome and then by start position (e.g., sort -k1,1 -k2,2n in.bed > in.sorted.bed for BED files). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_makewindowsbed/2.31.1",
    "name": "bedtools MakeWindowsBed",
    "description": "make interval windows across a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Makes adjacent or sliding windows across a genome or BED file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_slopbed/2.31.1+galaxy0",
    "name": "bedtools SlopBed",
    "description": "adjust the size of intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools slop will increase the size of each feature in a feature file by a user-defined number of bases. While something like this could be done with an awk '{OFS=\"\\t\" print $1,$2-&lt;slop>,$3+&lt;slop>}', bedtools slop will restrict the resizing to the size of the chromosome (i.e. no start &lt; 0 and no end > chromosome size). .. image:: $PATH_TO_IMAGES/slop-glyph.png .. class:: warningmark In order to prevent the extension of intervals beyond chromosome boundaries, bedtools slop requires a genome file defining the length of each chromosome or contig. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_randombed/2.31.1+galaxy0",
    "name": "bedtools RandomBed",
    "description": "generate random intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools random will generate a random set of intervals in BED6 format. One can specify both the number (-n) and the size (-l) of the intervals that should be generated. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedtoigv/2.31.1",
    "name": "bedtools BED to IGV",
    "description": "create batch script for taking IGV screenshots",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Creates a batch script to create IGV images at each interval defined in a BED/bedGraph/GFF/VCF/EncodePeak file. **Notes** (1) The resulting script is meant to be run from within IGV. (2) It is assumed that prior to running the script, you've loaded the proper genome and tracks. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_complementbed/2.31.1+galaxy0",
    "name": "bedtools ComplementBed",
    "description": "Extract intervals not represented by an interval file",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools complement returns all intervals in a genome that are not covered by at least one interval in the input BED/bedGraph/GFF/VCF/EncodePeak file. .. image:: $PATH_TO_IMAGES/complement-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_coveragebed/2.31.1+galaxy0",
    "name": "bedtools Compute both the depth and breadth of coverage",
    "description": "of features in file B on the features in file A (bedtools coverage)",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** `bedtools coverage`_ computes both the *depth* and *breadth* of coverage of features in file B on the features in file A. For example, ``bedtools coverage`` can compute the coverage of sequence alignments (file B) across 1 kilobase (arbitrary) windows (file A) tiling a genome of interest. One advantage that ``bedtools coverage`` offers is that it not only *counts* the number of features that overlap an interval in file A, it also computes the fraction of bases in the interval in A that were overlapped by one or more features. Thus, ``bedtools coverage`` also computes the *breadth* of coverage for each interval in A. .. _bedtools coverage: http://bedtools.readthedocs.org/en/latest/content/tools/coverage.html .. class:: infomark The lines in the output will be comprised of each interval in A, followed by: 1. The number of features in B that overlapped (by at least one base pair) the A interval. 2. The number of bases in A that had non-zero coverage from features in B. 3. The length of the entry in A. 4. The fraction of bases in A that had non-zero coverage from features in B. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_fisher/2.31.1+galaxy0",
    "name": "bedtools FisherBed",
    "description": "calculate Fisher statistic between two feature files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** Perform fishers exact test on the number of overlaps/unique intervals between 2 files. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_mergebed/2.31.1",
    "name": "bedtools MergeBED",
    "description": "combine overlapping/nearby intervals into a single interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bedtools merge combines overlapping or \"book-ended\" features in an interval file into a single feature which spans all of the combined features. .. image:: $PATH_TO_IMAGES/merge-glyph.png .. class:: warningmark bedtools merge requires that you presort your data by chromosome and then by start position. Default behavior By default, ``bedtools merge`` combines overlapping (by at least 1 bp) and/or bookended intervals into a single, \"flattened\" or \"merged\" interval. :: $ cat A.bed chr1 100 200 chr1 180 250 chr1 250 500 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 500 chr1 501 1000 *-s* Enforcing \"strandedness\" The ``-s`` option will only merge intervals that are overlapping/bookended *and* are on the same strand. :: $ cat A.bed chr1 100 200 a1 1 + chr1 180 250 a2 2 + chr1 250 500 a3 3 - chr1 501 1000 a4 4 + $ bedtools merge -i A.bed -s chr1 100 250 + chr1 501 1000 + chr1 250 500 - *-d* Controlling how close two features must be in order to merge By default, only overlapping or book-ended features are combined into a new feature. However, one can force ``merge`` to combine more distant features with the ``-d`` option. For example, were one to set ``-d`` to 1000, any features that overlap or are within 1000 base pairs of one another will be combined. :: $ cat A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed -d 1000 chr1 100 200 1000 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multicovtbed/2.31.1",
    "name": "bedtools MultiCovBed",
    "description": "counts coverage from multiple BAMs at specific intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bedtools multicov, reports the count of alignments from multiple position-sorted and indexed BAM files that overlap intervals in a BED file. Specifically, for each BED interval provided, it reports a separate count of overlapping alignments from each BAM file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "bam"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_overlapbed/2.31.1",
    "name": "bedtools OverlapBed",
    "description": "computes the amount of overlap from two intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** overlap computes the amount of overlap (in the case of positive values) or distance (in the case of negative values) between feature coordinates occurring on the same input line and reports the result at the end of the same line. In this way, it is a useful method for computing custom overlap scores from the output of other BEDTools. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_flankbed/2.31.1+galaxy0",
    "name": "bedtools FlankBed",
    "description": "create new intervals from the flanks of existing intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools flank will optionally create flanking intervals whose size is user-specified fraction of the original interval. .. image:: $PATH_TO_IMAGES/flank-glyph.png .. class:: warningmark In order to prevent creating intervals that violate chromosome boundaries, bedTools flank requires a bedTool genome file defining the length of each chromosome or contig. . This should be a two column tabular file with the chromosome name in the first column and the END coordinate of the chromosome in the second column. If you need this data for any genome that is at UCSC (http://genome.ucsc.edu), it can be extracted from the Table Browser with the \"Get Data: UCSC Main\" tool. Set \"group\" to \"All Tables\", \"table\" to \"chromInfo\", and \"output format\" to \"all fields from selected table\". ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_annotatebed/2.31.1",
    "name": "bedtools AnnotateBed",
    "description": "annotate coverage of features from multiple files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bedtools annotate, well, annotates one BED/bedGraph/GFF/VCF/EncodePeak file with the coverage and number of overlaps observed from multiple other BED/bedGraph/GFF/VCF/EncodePeak files. In this way, it allows one to ask to what degree one feature coincides with multiple other feature types with a single command. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedpetobam/2.31.1+galaxy0",
    "name": "bedtools BEDPE to BAM",
    "description": "converter",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** Converts feature records to BAM format. .. class:: warningmark BED files must be at least BED4 to create BAM (needs name field). ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "unsorted.bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_reldistbed/2.31.1",
    "name": "bedtools ReldistBed",
    "description": "calculate the distribution of relative distances",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Traditional approaches to summarizing the similarity between two sets of genomic intervals are based upon the number or proportion of intersecting intervals. However, such measures are largely blind to spatial correlations between the two sets where, dpesite consistent spacing or proximity, intersections are rare (for example, enhancers and transcription start sites rarely overlap, yet they are much closer to one another than two sets of random intervals). Favorov et al proposed a relative distance metric that describes distribution of relative distances between each interval in one set nd the two closest intervals in another set (see figure above). If there is no spatial correlation between the two sets, one would expect the relative distances to be uniformaly distributed among the relative distances ranging from 0 to 0.5. If, however, the intervals tend to be much closer than expected by chance, the distribution of observed relative distances would be shifted towards low relative distance values (e.g., the figure below). .. image:: $PATH_TO_IMAGES/reldist-glyph.png .. class:: infomark ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_getfastabed/2.31.1+galaxy0",
    "name": "bedtools getfasta",
    "description": "use intervals to extract sequences from a FASTA file",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** bedtools getfasta will extract the sequence defined by the coordinates in a BED interval and create a new FASTA entry in the output file for each extracted sequence. By default, the FASTA header for each extracted sequence will be formatted as follows: >chrom>:&lt;start>-&lt;end>. .. image:: $PATH_TO_IMAGES/getfasta-glyph.png .. class:: warningmark 1. The headers in the input FASTA file must exactly match the chromosome column in the BED file. 2. You can use the UNIX fold command to set the line width of the FASTA output. For example, fold -w 60 will make each line of the FASTA file have at most 60 nucleotides for easy viewing. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "fasta"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_closestbed/2.31.1",
    "name": "bedtools ClosestBed",
    "description": "find the closest, potentially non-overlapping interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Similar to intersectBed, closestBed searches for overlapping features in A and B. In the event that no feature in B overlaps the current feature in A, closestBed will report the closest (that is, least genomic distance from the start or end of A) feature in B. For example, one might want to find which is the closest gene to a significant GWAS polymorphism. Note that closestBed will report an overlapping feature as the closestthat is, it does not restrict to closest non-overlapping feature. .. image:: $PATH_TO_IMAGES/closest-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_subtractbed/2.31.1",
    "name": "bedtools SubtractBed",
    "description": "remove intervals based on overlaps",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** bedtools subtract searches for features in B that overlap A. If an overlapping feature is found in B, the overlapping portion is removed from A and the remaining portion of A is reported. If a feature in B overlaps all of a feature in A, the A feature will not be reported. .. image:: $PATH_TO_IMAGES/subtract-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multiintersectbed/2.31.1",
    "name": "bedtools Multiple Intersect",
    "description": "identifies common intervals among multiple interval files",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** This tool identifies common intervals among multiple, sorted BED files. Intervals can be common among 0 to N of the N input BED files. .. class:: warningmark This tool requires that each BED file is reference-sorted (chrom, then start). .. class:: infomark The output file will contain five fixed columns, plus additional columns for each BED file: * 1. Chromosome name (or 'genome' for whole-genome coverage). * 2. The zero-based start position of the interval. * 3. The one-based end position of the interval. * 4. The number of input files that had at least one feature overlapping this interval. * 5. A list of input files or labels that had at least one feature overlapping this interval. * 6. For each input file, an indication (1 = Yes, 0 = No) of whether or not the file had at least one feature overlapping this interval. ------ **Example input**:: # a.bed chr1 6 12bed chr1 10 20 chr1 22 27 chr1 24 30 # b.bed chr1 12 32 chr1 14 30 # c.bed chr1 8 15 chr1 10 14 chr1 32 34 ------ **Example without a header and without reporting intervals with zero coverage**:: chr1 6 8 1 1 1 0 0 chr1 8 12 2 1,3 1 0 1 chr1 12 15 3 1,2,3 1 1 1 chr1 15 20 2 1,2 1 1 0 chr1 20 22 1 2 0 1 0 chr1 22 30 2 1,2 1 1 0 chr1 30 32 1 2 0 1 0 chr1 32 34 1 3 0 0 1 **Example adding a header line**:: chrom start end num list a.bed b.bed c.bed chr1 6 8 1 1 1 0 0 chr1 8 12 2 1,3 1 0 1 chr1 12 15 3 1,2,3 1 1 1 chr1 15 20 2 1,2 1 1 0 chr1 20 22 1 2 0 1 0 chr1 22 30 2 1,2 1 1 0 chr1 30 32 1 2 0 1 0 chr1 32 34 1 3 0 0 1 **Example adding a header line and custom file labels**:: chrom start end num list joe bob sue chr1 6 8 1 joe 1 0 0 chr1 8 12 2 joe,sue 1 0 1 chr1 12 15 3 joe,bob,sue 1 1 1 chr1 15 20 2 joe,bob 1 1 0 chr1 20 22 1 bob 0 1 0 chr1 22 30 2 joe,bob 1 1 0 chr1 30 32 1 bob 0 1 0 chr1 32 34 1 sue 0 0 1 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_spacingbed/2.31.1",
    "name": "bedtools SpacingBed",
    "description": "reports the distances between features",
    "categories": [
      "BED"
    ],
    "version": "2.31.1",
    "help": "**What it does** Report the spacing between intervals in a file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_sortbed/2.31.1+galaxy0",
    "name": "bedtools SortBED",
    "description": "order the intervals",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** Sorts a feature file by chromosome and other criteria. .. class:: warningmark It should be noted that sortBed is merely a convenience utility, as the UNIX sort utility will sort BED files more quickly while using less memory. For example, UNIX sort will sort a BED file by chromosome then by start position in the following manner: sort -k 1,1 -k2,2 -n a.bed ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_shufflebed/2.31.1+galaxy1",
    "name": "bedtools ShuffleBed",
    "description": "randomly redistrubute intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy1",
    "help": "**What it does** bedtools shuffle will randomly permute the genomic locations of a feature file among a genome defined in a genome file. One can also provide an exclusions BED/bedGraph/GFF/VCF/EncodePeak file that lists regions where you do not want the permuted features to be placed. For example, one might want to prevent features from being placed in known genome gaps. shuffle is useful as a null basis against which to test the significance of associations of one feature with another. .. image:: $PATH_TO_IMAGES/shuffle-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_groupbybed/2.31.1+galaxy0",
    "name": "bedtools GroupByBed",
    "description": "group by common cols and summarize other cols",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** Replicate lines in a file based on columns of comma-separated values. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_makewindowsbed/2.31.1+galaxy0",
    "name": "bedtools MakeWindowsBed",
    "description": "make interval windows across a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy0",
    "help": "**What it does** Makes adjacent or sliding windows across a genome or BED file. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak",
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_randombed/2.31.1+galaxy1",
    "name": "bedtools RandomBed",
    "description": "generate random intervals in a genome",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy1",
    "help": "**What it does** bedtools random will generate a random set of intervals in BED6 format. One can specify both the number (-n) and the size (-l) of the intervals that should be generated. ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_mergebed/2.31.1+galaxy2",
    "name": "bedtools MergeBED",
    "description": "combine overlapping/nearby intervals into a single interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy2",
    "help": "**What it does** bedtools merge combines overlapping or \"book-ended\" features in an interval file into a single feature which spans all of the combined features. .. image:: $PATH_TO_IMAGES/merge-glyph.png .. class:: warningmark bedtools merge requires that you presort your data by chromosome and then by start position. Default behavior By default, ``bedtools merge`` combines overlapping (by at least 1 bp) and/or bookended intervals into a single, \"flattened\" or \"merged\" interval. :: $ cat A.bed chr1 100 200 chr1 180 250 chr1 250 500 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 500 chr1 501 1000 *-s* Enforcing \"strandedness\" The ``-s`` option will only merge intervals that are overlapping/bookended *and* are on the same strand. :: $ cat A.bed chr1 100 200 a1 1 + chr1 180 250 a2 2 + chr1 250 500 a3 3 - chr1 501 1000 a4 4 + $ bedtools merge -i A.bed -s chr1 100 250 + chr1 501 1000 + chr1 250 500 - *-d* Controlling how close two features must be in order to merge By default, only overlapping or book-ended features are combined into a new feature. However, one can force ``merge`` to combine more distant features with the ``-d`` option. For example, were one to set ``-d`` to 1000, any features that overlap or are within 1000 base pairs of one another will be combined. :: $ cat A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed chr1 100 200 chr1 501 1000 $ bedtools merge -i A.bed -d 1000 chr1 100 200 1000 ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bam",
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": [
      "bed"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_closestbed/2.31.1+galaxy1",
    "name": "bedtools ClosestBed",
    "description": "find the closest, potentially non-overlapping interval",
    "categories": [
      "BED"
    ],
    "version": "2.31.1+galaxy1",
    "help": "**What it does** Similar to intersectBed, closestBed searches for overlapping features in A and B. In the event that no feature in B overlaps the current feature in A, closestBed will report the closest (that is, least genomic distance from the start or end of A) feature in B. For example, one might want to find which is the closest gene to a significant GWAS polymorphism. Note that closestBed will report an overlapping feature as the closestthat is, it does not restrict to closest non-overlapping feature. .. image:: $PATH_TO_IMAGES/closest-glyph.png ------ This tool is part of the `bedtools package`_ from the `Quinlan laboratory`_. .. _bedtools package: https://github.com/arq5x/bedtools2 .. _Quinlan laboratory: http://quinlanlab.org **Citation** If you use this tool in Galaxy, please cite: Bjoern A. Gruening (2014), `Galaxy wrapper `_",
    "input_formats": [
      "bed",
      "bedgraph",
      "gff",
      "vcf",
      "encodepeak"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bedops_sortbed/bedops-sort-bed/2.4.42",
    "name": "bedops sort-bed",
    "description": "",
    "categories": [
      "BED"
    ],
    "version": "2.4.42",
    "help": "What this tool does The sort-bed utility sorts BED files of any size, even larger than system memory. BED files that are in lexicographic-chromosome order allow BEDOPS utilities to work efficiently with data from any species without software modifications. Further, sorted files can be traversed very quickly. Sorted BED order is defined first by lexicographic chromosome order, then ascending integer start coordinate order, and finally by ascending integer end coordinate order. To make the sort order unambiguous, a lexicographical sort is applied on fourth and subsequent columns, where present in the input BED dataset. Input The sort-bed utility requires one or more three-column BED file(s). Support for common headers (such as UCSC BED track headers) is included, although headers will be stripped from the output. Output Sort order is defined by a lexicographical sort on chromosome name, a numerical sort on start coordinates, a numerical sort on stop coordinates where there are start matches, and finally a lexicographical sort on the remainder of the BED element (if additional columns are present). Additional options may be specified to print only unique or duplicate elements.",
    "input_formats": [
      "bed"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_tag2tag/bcftools_plugin_tag2tag/1.10+galaxy1",
    "name": "bcftools tag2tag",
    "description": "plugin Convert between similar tags, such as GL and GP",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.10+galaxy1",
    "help": "bcftools tag2tag plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.10+galaxy1",
    "name": "bcftools stats",
    "description": "Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.10+galaxy1",
    "help": "bcftools stats Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats. When two files are given, the program generates separate stats for intersection and the complements. By default only sites are compared, -s/-S must given to include also sample columns. When one VCF file is specified, then stats by non-reference allele frequency, depth distribution, stats by quality and per-sample counts, singleton stats, etc. are printed. When two VCF files are given, then stats such as concordance (Genotype concordance by non-reference allele frequency, Genotype concordance by sample, Non-Reference Discordance) and correlation are also printed. Per-site discordance (PSD) is also printed in --verbose mode. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#stats https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "fasta"
    ],
    "output_formats": [
      "txt",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.10+galaxy1",
    "name": "bcftools cnv",
    "description": "Call copy number variation from VCF B-allele frequency (BAF) and Log R Ratio intensity (LRR) values",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.10+galaxy1",
    "help": "bcftools cnv Copy number variation caller, requires Illumina's B-allele frequency (BAF) and Log R Ratio intensity (LRR). The HMM considers the following copy number states: CN 2 (normal), 1 (single-copy loss), 0 (complete loss), 3 (single-copy gain) Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#cnv https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_tag2tag/bcftools_plugin_tag2tag/1.15.1+galaxy2",
    "name": "bcftools tag2tag",
    "description": "plugin Convert between similar tags, such as GL and GP",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools tag2tag plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query/bcftools_query/1.15.1+galaxy2",
    "name": "bcftools query",
    "description": "Extracts fields from VCF/BCF file and prints them in user-defined format",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools query Extracts fields from VCF/BCF file and prints them in user-defined format Format: :: ``%CHROM`` The CHROM column (similarly also other columns: POS, ID, REF, ALT, QUAL, FILTER) ``%INFO/TAG`` Any tag in the INFO column ``%TYPE`` Variant type (REF, SNP, MNP, INDEL, OTHER) ``%MASK`` Indicates presence of the site in other files (with multiple files) ``%TAG{INT}`` Curly brackets to subscript vectors (0-based) ``%FIRST_ALT`` Alias for %ALT{0} ``[]`` The brackets loop over all samples ``%GT`` Genotype (e.g. 0/1) ``%TBCSQ`` Translated FORMAT/BCSQ. See the csq command above for explanation and examples. ``%TGT`` Translated genotype (e.g. C/A) ``%IUPACGT`` Genotype translated to IUPAC ambiguity codes (e.g. M instead of C/A) ``%LINE`` Prints the whole line ``%SAMPLE`` Sample name ``%POS0`` POS in 0-based coordinates ``%END`` End position of the REF allele ``%END0`` End position of the REF allele in 0-based cordinates ``\\n`` new line ``\\t`` tab character Examples: :: # Print chromosome, position, ref allele and the first alternate allele bcftools query -f '%CHROM %POS %REF %ALT{0}\\n' file.vcf.gz # Similar to above, but use tabs instead of spaces, add sample name and genotype bcftools query -f '%CHROM\\t%POS\\t%REF\\t%ALT[\\t%SAMPLE=%GT]\\n' file.vcf.gz # Print FORMAT/GT fields followed by FORMAT/GT fields bcftools query -f 'GQ:[ %GQ] \\t GT:[ %GT]\\n' file.vcf # Make a BED file: chr, pos (0-based), end pos (1-based), id bcftools query -f'%CHROM\\t%POS0\\t%END\\t%ID\\n' file.bcf Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_dosage/bcftools_plugin_dosage/1.15.1+galaxy2",
    "name": "bcftools dosage",
    "description": "plugin genotype dosage",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools dosage plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_annotate/bcftools_annotate/1.15.1+galaxy2",
    "name": "bcftools annotate",
    "description": "Annotate and edit VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools annotate Annotate and edit VCF/BCF files. Examples: # Remove three fields bcftools annotate -x ID,INFO/DP,FORMAT/DP file.vcf.gz # Remove all INFO fields and all FORMAT fields except for GT and PL bcftools annotate -x INFO,^FORMAT/GT,FORMAT/PL file.vcf # Add ID, QUAL and INFO/TAG, not replacing TAG if already present bcftools annotate -a src.bcf -c ID,QUAL,+TAG dst.bcf # Carry over all INFO and FORMAT annotations except FORMAT/GT bcftools annotate -a src.bcf -c INFO,^FORMAT/GT dst.bcf # Annotate from a tab-delimited file with six columns (the fifth is ignored), # first indexing with tabix. The coordinates are 1-based. tabix -s1 -b2 -e2 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,POS,REF,ALT,-,TAG file.vcf # Annotate from a tab-delimited file with regions (1-based coordinates, inclusive) tabix -s1 -b2 -e3 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,FROM,TO,TAG inut.vcf # Annotate from a bed file (0-based coordinates, half-closed, half-open intervals) bcftools annotate -a annots.bed.gz -h annots.hdr -c CHROM,FROM,TO,TAG input.vcf Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#annotate https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "bed",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_csq/bcftools_csq/1.15.1+galaxy2",
    "name": "bcftools csq",
    "description": "Haplotype aware consequence predictor",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools csq Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#csq https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_filter/bcftools_filter/1.15.1+galaxy2",
    "name": "bcftools filter",
    "description": "Apply fixed-threshold filters",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools filter Apply fixed-threshold filters. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#filter https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_view/bcftools_view/1.15.1+galaxy2",
    "name": "bcftools view",
    "description": "VCF/BCF conversion, view, subset and filter VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools view VCF/BCF conversion, view, subset and filter VCF/BCF files. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#view https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_call/bcftools_call/1.15.1+galaxy2",
    "name": "bcftools call",
    "description": "SNP/indel variant calling from VCF/BCF",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools call SNP/indel variant calling from VCF/BCF. To be used in conjunction with samtools mpileup. - This command replaces the former \"bcftools view\" caller. - Some of the original functionality has been temporarily lost in the process of transition to htslib, but will be added back on popular demand. - The original calling model can be invoked with the -c option. The novel-rate option can be set to modify the likelihood of novel mutation for constrained -C trio calling. The trio genotype calling maximizes likelihood of a particular combination of genotypes for father, mother and the child P(F=i,M=j,C=k) = P(unconstrained) * Pn + P(constrained) * (1-Pn). By providing three values, the mutation rate Pn is set explicitly for SNPs, deletions and insertions, respectively. If two values are given, the first is interpreted as the mutation rate of SNPs and the second is used to calculate the mutation rate of indels according to their length as Pn=float*exp(-a-b*len), where a=22.8689, b=0.2994 for insertions and a=21.9313, b=0.2856 for deletions [pubmed:23975140]. If only one value is given, the same mutation rate Pn is used for SNPs and indels. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#call https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy2",
    "name": "bcftools roh",
    "description": "HMM model for detecting runs of homo/autozygosity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools roh HMM model for detecting runs of autozygosity. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#roh https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "data"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_merge/bcftools_merge/1.15.1+galaxy2",
    "name": "bcftools merge",
    "description": "Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools merge Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file. Note that only records from different files can be merged, never from the same file. For \"vertical\" merge take a look at \"bcftools norm\" instead. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#merge https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_isec/bcftools_isec/1.15.1+galaxy2",
    "name": "bcftools isec",
    "description": "Create intersections, unions and complements of VCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools isec Create intersections, unions and complements of VCF files. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#isec https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_tags/bcftools_plugin_fill_tags/1.15.1+galaxy2",
    "name": "bcftools fill-tags",
    "description": "plugin Set INFO tags AF, AN, AC, AC_Hom, AC_Het, AC_Hemi",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools fill-tags plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_an_ac/bcftools_plugin_fill_an_ac/1.15.1+galaxy2",
    "name": "bcftools fill-AN-AC",
    "description": "plugin Fill INFO fields AN and AC",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools fill-AN-AC plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.15.1+galaxy2",
    "name": "bcftools stats",
    "description": "Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools stats Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats. When two files are given, the program generates separate stats for intersection and the complements. By default only sites are compared, -s/-S must given to include also sample columns. When one VCF file is specified, then stats by non-reference allele frequency, depth distribution, stats by quality and per-sample counts, singleton stats, etc. are printed. When two VCF files are given, then stats such as concordance (Genotype concordance by non-reference allele frequency, Genotype concordance by sample, Non-Reference Discordance) and correlation are also printed. Per-site discordance (PSD) is also printed in --verbose mode. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#stats https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "fasta"
    ],
    "output_formats": [
      "txt",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_reheader/bcftools_reheader/1.15.1+galaxy2",
    "name": "bcftools reheader",
    "description": "Modify header of VCF/BCF files, change sample names",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools reheader Modify header of VCF/BCF files, change sample names. http://samtools.github.io/bcftools/bcftools.html#reheader https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_impute_info/bcftools_plugin_impute_info/1.15.1+galaxy2",
    "name": "bcftools impute-info",
    "description": "plugin Add imputation information metrics to the INFO field",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools impute-info plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_from_vcf/bcftools_convert_from_vcf/1.15.1+galaxy2",
    "name": "bcftools convert from vcf",
    "description": "Converts VCF/BCF to IMPUTE2/SHAPEIT formats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools convert from vcf Converts VCF/BCF to other formats. See man page for file formats details. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_consensus/bcftools_consensus/1.15.1+galaxy2",
    "name": "bcftools consensus",
    "description": "Create consensus sequence by applying VCF variants to a reference fasta file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools consensus plugin Create consensus sequence by applying VCF variants to a reference fasta file. http://samtools.github.io/bcftools/bcftools.html#consensus https://github.com/samtools/bcftools/wiki The option to set the new consensus' FASTA ID from the name of the VCF is provided by post-processing the bcftools consensus output. It is primarily intended for use when the VCF is coming from a list collection where the elements of the list are named meaningfully (e.g. named after sample names). This is useful when consensus sequences are being prepared for, for example, feeding a multiple sequence alignment to a phylogeny program.",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "fasta",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_concat/bcftools_concat/1.15.1+galaxy2",
    "name": "bcftools concat",
    "description": "Concatenate or combine VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools concat plugin Concatenate or combine VCF/BCF files. All source files must have the same sample columns appearing in the same order. The program can be used, for example, to concatenate chromosome VCFs into one VCF, or combine a SNP VCF and an indel VCF into one. The input files must be sorted by chr and position. The files must be given in the correct order to produce sorted VCF on output unless the -a, --allow-overlaps option is specified. Naive concatenation is useful when using a galaxy workflow that splits a BAM file by chromosome, processes each in parallel, then bcftools concat merges the results into a single VCF file: BAM -> bamtools split => bcftools mpileup => bcftools call => bcftools concat -> VCF Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#concat https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_mendelian/bcftools_plugin_mendelian/1.15.1+galaxy2",
    "name": "bcftools mendelian",
    "description": "plugin Count Mendelian consistent / inconsistent genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools mendelian plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_mpileup/bcftools_mpileup/1.15.1+galaxy2",
    "name": "bcftools mpileup",
    "description": "Generate VCF or BCF containing genotype likelihoods for one or multiple alignment (BAM or CRAM) files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools mpileup Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#mpileup https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "txt",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_counts/bcftools_plugin_counts/1.15.1+galaxy2",
    "name": "bcftools counts",
    "description": "plugin  counts number of samples, SNPs, INDELs, MNPs and total sites",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools counts plugin Counts number of samples, SNPs, INDELs, MNPs and total number of sites. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_setgt/bcftools_plugin_setgt/1.15.1+galaxy2",
    "name": "bcftools setGT",
    "description": "plugin Sets genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools setGT plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy2",
    "name": "bcftools cnv",
    "description": "Call copy number variation from VCF B-allele frequency (BAF) and Log R Ratio intensity (LRR) values",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools cnv Copy number variation caller, requires Illumina's B-allele frequency (BAF) and Log R Ratio intensity (LRR). The HMM considers the following copy number states: CN 2 (normal), 1 (single-copy loss), 0 (complete loss), 3 (single-copy gain) Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#cnv https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_missing2ref/bcftools_plugin_missing2ref/1.15.1+galaxy2",
    "name": "bcftools missing2ref",
    "description": "plugin Set missing genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools missing2ref plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query_list_samples/bcftools_query_list_samples/1.15.1+galaxy2",
    "name": "bcftools List Samples",
    "description": "in VCF/BCF file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools List Samples query Lists Samples from a VCF/BCF file http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_norm/bcftools_norm/1.15.1+galaxy2",
    "name": "bcftools norm",
    "description": "Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools norm Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#norm https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_to_vcf/bcftools_convert_to_vcf/1.15.1+galaxy2",
    "name": "bcftools convert to vcf",
    "description": "Converts other formats to VCF/BCFk",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools convert plugin Converts other variant formats to vcf. See man page for file formats details. http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "tabular",
      "fasta",
      "vcf"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fixploidy/bcftools_plugin_fixploidy/1.15.1+galaxy2",
    "name": "bcftools fixploidy",
    "description": "plugin  Fix ploidy",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools fixploidy plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_gtcheck/bcftools_gtcheck/1.15.1+galaxy2",
    "name": "bcftools gtcheck",
    "description": "Check sample identity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy2",
    "help": "bcftools gtcheck Check sample identity. With no -g BCF given, multi-sample cross-check is performed. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#gtcheck https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_tag2tag/bcftools_plugin_tag2tag/1.15.1+galaxy3",
    "name": "bcftools tag2tag",
    "description": "plugin Convert between similar tags, such as GL and GP",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools tag2tag plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query/bcftools_query/1.15.1+galaxy3",
    "name": "bcftools query",
    "description": "Extracts fields from VCF/BCF file and prints them in user-defined format",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools query Extracts fields from VCF/BCF file and prints them in user-defined format Format: :: ``%CHROM`` The CHROM column (similarly also other columns: POS, ID, REF, ALT, QUAL, FILTER) ``%INFO/TAG`` Any tag in the INFO column ``%TYPE`` Variant type (REF, SNP, MNP, INDEL, OTHER) ``%MASK`` Indicates presence of the site in other files (with multiple files) ``%TAG{INT}`` Curly brackets to subscript vectors (0-based) ``%FIRST_ALT`` Alias for %ALT{0} ``[]`` The brackets loop over all samples ``%GT`` Genotype (e.g. 0/1) ``%TBCSQ`` Translated FORMAT/BCSQ. See the csq command above for explanation and examples. ``%TGT`` Translated genotype (e.g. C/A) ``%IUPACGT`` Genotype translated to IUPAC ambiguity codes (e.g. M instead of C/A) ``%LINE`` Prints the whole line ``%SAMPLE`` Sample name ``%POS0`` POS in 0-based coordinates ``%END`` End position of the REF allele ``%END0`` End position of the REF allele in 0-based cordinates ``\\n`` new line ``\\t`` tab character Examples: :: # Print chromosome, position, ref allele and the first alternate allele bcftools query -f '%CHROM %POS %REF %ALT{0}\\n' file.vcf.gz # Similar to above, but use tabs instead of spaces, add sample name and genotype bcftools query -f '%CHROM\\t%POS\\t%REF\\t%ALT[\\t%SAMPLE=%GT]\\n' file.vcf.gz # Print FORMAT/GT fields followed by FORMAT/GT fields bcftools query -f 'GQ:[ %GQ] \\t GT:[ %GT]\\n' file.vcf # Make a BED file: chr, pos (0-based), end pos (1-based), id bcftools query -f'%CHROM\\t%POS0\\t%END\\t%ID\\n' file.bcf Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_dosage/bcftools_plugin_dosage/1.15.1+galaxy3",
    "name": "bcftools dosage",
    "description": "plugin genotype dosage",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools dosage plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_annotate/bcftools_annotate/1.15.1+galaxy3",
    "name": "bcftools annotate",
    "description": "Annotate and edit VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools annotate Annotate and edit VCF/BCF files. Examples: # Remove three fields bcftools annotate -x ID,INFO/DP,FORMAT/DP file.vcf.gz # Remove all INFO fields and all FORMAT fields except for GT and PL bcftools annotate -x INFO,^FORMAT/GT,FORMAT/PL file.vcf # Add ID, QUAL and INFO/TAG, not replacing TAG if already present bcftools annotate -a src.bcf -c ID,QUAL,+TAG dst.bcf # Carry over all INFO and FORMAT annotations except FORMAT/GT bcftools annotate -a src.bcf -c INFO,^FORMAT/GT dst.bcf # Annotate from a tab-delimited file with six columns (the fifth is ignored), # first indexing with tabix. The coordinates are 1-based. tabix -s1 -b2 -e2 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,POS,REF,ALT,-,TAG file.vcf # Annotate from a tab-delimited file with regions (1-based coordinates, inclusive) tabix -s1 -b2 -e3 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,FROM,TO,TAG inut.vcf # Annotate from a bed file (0-based coordinates, half-closed, half-open intervals) bcftools annotate -a annots.bed.gz -h annots.hdr -c CHROM,FROM,TO,TAG input.vcf Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#annotate https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "bed",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_csq/bcftools_csq/1.15.1+galaxy3",
    "name": "bcftools csq",
    "description": "Haplotype aware consequence predictor",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools csq Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#csq https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_filter/bcftools_filter/1.15.1+galaxy3",
    "name": "bcftools filter",
    "description": "Apply fixed-threshold filters",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools filter Apply fixed-threshold filters. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#filter https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_view/bcftools_view/1.15.1+galaxy3",
    "name": "bcftools view",
    "description": "VCF/BCF conversion, view, subset and filter VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools view VCF/BCF conversion, view, subset and filter VCF/BCF files. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#view https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_call/bcftools_call/1.15.1+galaxy3",
    "name": "bcftools call",
    "description": "SNP/indel variant calling from VCF/BCF",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools call SNP/indel variant calling from VCF/BCF. To be used in conjunction with samtools mpileup. - This command replaces the former \"bcftools view\" caller. - Some of the original functionality has been temporarily lost in the process of transition to htslib, but will be added back on popular demand. - The original calling model can be invoked with the -c option. The novel-rate option can be set to modify the likelihood of novel mutation for constrained -C trio calling. The trio genotype calling maximizes likelihood of a particular combination of genotypes for father, mother and the child P(F=i,M=j,C=k) = P(unconstrained) * Pn + P(constrained) * (1-Pn). By providing three values, the mutation rate Pn is set explicitly for SNPs, deletions and insertions, respectively. If two values are given, the first is interpreted as the mutation rate of SNPs and the second is used to calculate the mutation rate of indels according to their length as Pn=float*exp(-a-b*len), where a=22.8689, b=0.2994 for insertions and a=21.9313, b=0.2856 for deletions [pubmed:23975140]. If only one value is given, the same mutation rate Pn is used for SNPs and indels. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#call https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy3",
    "name": "bcftools roh",
    "description": "HMM model for detecting runs of homo/autozygosity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools roh HMM model for detecting runs of autozygosity. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#roh https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "data"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_merge/bcftools_merge/1.15.1+galaxy3",
    "name": "bcftools merge",
    "description": "Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools merge Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file. Note that only records from different files can be merged, never from the same file. For \"vertical\" merge take a look at \"bcftools norm\" instead. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#merge https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_isec/bcftools_isec/1.15.1+galaxy3",
    "name": "bcftools isec",
    "description": "Create intersections, unions and complements of VCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools isec Create intersections, unions and complements of VCF files. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#isec https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_tags/bcftools_plugin_fill_tags/1.15.1+galaxy3",
    "name": "bcftools fill-tags",
    "description": "plugin Set INFO tags AF, AN, AC, AC_Hom, AC_Het, AC_Hemi",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools fill-tags plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_an_ac/bcftools_plugin_fill_an_ac/1.15.1+galaxy3",
    "name": "bcftools fill-AN-AC",
    "description": "plugin Fill INFO fields AN and AC",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools fill-AN-AC plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.15.1+galaxy3",
    "name": "bcftools stats",
    "description": "Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools stats Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats. When two files are given, the program generates separate stats for intersection and the complements. By default only sites are compared, -s/-S must given to include also sample columns. When one VCF file is specified, then stats by non-reference allele frequency, depth distribution, stats by quality and per-sample counts, singleton stats, etc. are printed. When two VCF files are given, then stats such as concordance (Genotype concordance by non-reference allele frequency, Genotype concordance by sample, Non-Reference Discordance) and correlation are also printed. Per-site discordance (PSD) is also printed in --verbose mode. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#stats https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "fasta"
    ],
    "output_formats": [
      "txt",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_reheader/bcftools_reheader/1.15.1+galaxy3",
    "name": "bcftools reheader",
    "description": "Modify header of VCF/BCF files, change sample names",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools reheader Modify header of VCF/BCF files, change sample names. http://samtools.github.io/bcftools/bcftools.html#reheader https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_impute_info/bcftools_plugin_impute_info/1.15.1+galaxy3",
    "name": "bcftools impute-info",
    "description": "plugin Add imputation information metrics to the INFO field",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools impute-info plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_from_vcf/bcftools_convert_from_vcf/1.15.1+galaxy3",
    "name": "bcftools convert from vcf",
    "description": "Converts VCF/BCF to IMPUTE2/SHAPEIT formats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools convert from vcf Converts VCF/BCF to other formats. See man page for file formats details. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_consensus/bcftools_consensus/1.15.1+galaxy3",
    "name": "bcftools consensus",
    "description": "Create consensus sequence by applying VCF variants to a reference fasta file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools consensus plugin Create consensus sequence by applying VCF variants to a reference fasta file. http://samtools.github.io/bcftools/bcftools.html#consensus https://github.com/samtools/bcftools/wiki The option to set the new consensus' FASTA ID from the name of the VCF is provided by post-processing the bcftools consensus output. It is primarily intended for use when the VCF is coming from a list collection where the elements of the list are named meaningfully (e.g. named after sample names). This is useful when consensus sequences are being prepared for, for example, feeding a multiple sequence alignment to a phylogeny program.",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "fasta",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_concat/bcftools_concat/1.15.1+galaxy3",
    "name": "bcftools concat",
    "description": "Concatenate or combine VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools concat plugin Concatenate or combine VCF/BCF files. All source files must have the same sample columns appearing in the same order. The program can be used, for example, to concatenate chromosome VCFs into one VCF, or combine a SNP VCF and an indel VCF into one. The input files must be sorted by chr and position. The files must be given in the correct order to produce sorted VCF on output unless the -a, --allow-overlaps option is specified. Naive concatenation is useful when using a galaxy workflow that splits a BAM file by chromosome, processes each in parallel, then bcftools concat merges the results into a single VCF file: BAM -> bamtools split => bcftools mpileup => bcftools call => bcftools concat -> VCF Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#concat https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_mendelian/bcftools_plugin_mendelian/1.15.1+galaxy3",
    "name": "bcftools mendelian",
    "description": "plugin Count Mendelian consistent / inconsistent genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools mendelian plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_mpileup/bcftools_mpileup/1.15.1+galaxy3",
    "name": "bcftools mpileup",
    "description": "Generate VCF or BCF containing genotype likelihoods for one or multiple alignment (BAM or CRAM) files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools mpileup Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#mpileup https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "txt",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_counts/bcftools_plugin_counts/1.15.1+galaxy3",
    "name": "bcftools counts",
    "description": "plugin  counts number of samples, SNPs, INDELs, MNPs and total sites",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools counts plugin Counts number of samples, SNPs, INDELs, MNPs and total number of sites. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_setgt/bcftools_plugin_setgt/1.15.1+galaxy3",
    "name": "bcftools setGT",
    "description": "plugin Sets genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools setGT plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy3",
    "name": "bcftools cnv",
    "description": "Call copy number variation from VCF B-allele frequency (BAF) and Log R Ratio intensity (LRR) values",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools cnv Copy number variation caller, requires Illumina's B-allele frequency (BAF) and Log R Ratio intensity (LRR). The HMM considers the following copy number states: CN 2 (normal), 1 (single-copy loss), 0 (complete loss), 3 (single-copy gain) Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#cnv https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_missing2ref/bcftools_plugin_missing2ref/1.15.1+galaxy3",
    "name": "bcftools missing2ref",
    "description": "plugin Set missing genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools missing2ref plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query_list_samples/bcftools_query_list_samples/1.15.1+galaxy3",
    "name": "bcftools List Samples",
    "description": "in VCF/BCF file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools List Samples query Lists Samples from a VCF/BCF file http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_norm/bcftools_norm/1.15.1+galaxy3",
    "name": "bcftools norm",
    "description": "Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools norm Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#norm https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_to_vcf/bcftools_convert_to_vcf/1.15.1+galaxy3",
    "name": "bcftools convert to vcf",
    "description": "Converts other formats to VCF/BCFk",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools convert plugin Converts other variant formats to vcf. See man page for file formats details. http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "tabular",
      "fasta",
      "vcf"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fixploidy/bcftools_plugin_fixploidy/1.15.1+galaxy3",
    "name": "bcftools fixploidy",
    "description": "plugin  Fix ploidy",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools fixploidy plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_gtcheck/bcftools_gtcheck/1.15.1+galaxy3",
    "name": "bcftools gtcheck",
    "description": "Check sample identity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy3",
    "help": "bcftools gtcheck Check sample identity. With no -g BCF given, multi-sample cross-check is performed. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#gtcheck https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_mpileup/bcftools_mpileup/1.15.1+galaxy4",
    "name": "bcftools mpileup",
    "description": "Generate VCF or BCF containing genotype likelihoods for one or multiple alignment (BAM or CRAM) files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools mpileup Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#mpileup https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "txt",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_call/bcftools_call/1.15.1+galaxy4",
    "name": "bcftools call",
    "description": "SNP/indel variant calling from VCF/BCF",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools call SNP/indel variant calling from VCF/BCF. To be used in conjunction with samtools mpileup. - This command replaces the former \"bcftools view\" caller. - Some of the original functionality has been temporarily lost in the process of transition to htslib, but will be added back on popular demand. - The original calling model can be invoked with the -c option. The novel-rate option can be set to modify the likelihood of novel mutation for constrained -C trio calling. The trio genotype calling maximizes likelihood of a particular combination of genotypes for father, mother and the child P(F=i,M=j,C=k) = P(unconstrained) * Pn + P(constrained) * (1-Pn). By providing three values, the mutation rate Pn is set explicitly for SNPs, deletions and insertions, respectively. If two values are given, the first is interpreted as the mutation rate of SNPs and the second is used to calculate the mutation rate of indels according to their length as Pn=float*exp(-a-b*len), where a=22.8689, b=0.2994 for insertions and a=21.9313, b=0.2856 for deletions [pubmed:23975140]. If only one value is given, the same mutation rate Pn is used for SNPs and indels. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#call https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_tag2tag/bcftools_plugin_tag2tag/1.15.1+galaxy4",
    "name": "bcftools tag2tag",
    "description": "plugin Convert between similar tags, such as GL and GP",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools tag2tag plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query/bcftools_query/1.15.1+galaxy4",
    "name": "bcftools query",
    "description": "Extracts fields from VCF/BCF file and prints them in user-defined format",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools query Extracts fields from VCF/BCF file and prints them in user-defined format Format: :: ``%CHROM`` The CHROM column (similarly also other columns: POS, ID, REF, ALT, QUAL, FILTER) ``%INFO/TAG`` Any tag in the INFO column ``%TYPE`` Variant type (REF, SNP, MNP, INDEL, OTHER) ``%MASK`` Indicates presence of the site in other files (with multiple files) ``%TAG{INT}`` Curly brackets to subscript vectors (0-based) ``%FIRST_ALT`` Alias for %ALT{0} ``[]`` The brackets loop over all samples ``%GT`` Genotype (e.g. 0/1) ``%TBCSQ`` Translated FORMAT/BCSQ. See the csq command above for explanation and examples. ``%TGT`` Translated genotype (e.g. C/A) ``%IUPACGT`` Genotype translated to IUPAC ambiguity codes (e.g. M instead of C/A) ``%LINE`` Prints the whole line ``%SAMPLE`` Sample name ``%POS0`` POS in 0-based coordinates ``%END`` End position of the REF allele ``%END0`` End position of the REF allele in 0-based cordinates ``\\n`` new line ``\\t`` tab character Examples: :: # Print chromosome, position, ref allele and the first alternate allele bcftools query -f '%CHROM %POS %REF %ALT{0}\\n' file.vcf.gz # Similar to above, but use tabs instead of spaces, add sample name and genotype bcftools query -f '%CHROM\\t%POS\\t%REF\\t%ALT[\\t%SAMPLE=%GT]\\n' file.vcf.gz # Print FORMAT/GT fields followed by FORMAT/GT fields bcftools query -f 'GQ:[ %GQ] \\t GT:[ %GT]\\n' file.vcf # Make a BED file: chr, pos (0-based), end pos (1-based), id bcftools query -f'%CHROM\\t%POS0\\t%END\\t%ID\\n' file.bcf Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_dosage/bcftools_plugin_dosage/1.15.1+galaxy4",
    "name": "bcftools dosage",
    "description": "plugin genotype dosage",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools dosage plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_annotate/bcftools_annotate/1.15.1+galaxy4",
    "name": "bcftools annotate",
    "description": "Annotate and edit VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools annotate Annotate and edit VCF/BCF files. Examples: # Remove three fields bcftools annotate -x ID,INFO/DP,FORMAT/DP file.vcf.gz # Remove all INFO fields and all FORMAT fields except for GT and PL bcftools annotate -x INFO,^FORMAT/GT,FORMAT/PL file.vcf # Add ID, QUAL and INFO/TAG, not replacing TAG if already present bcftools annotate -a src.bcf -c ID,QUAL,+TAG dst.bcf # Carry over all INFO and FORMAT annotations except FORMAT/GT bcftools annotate -a src.bcf -c INFO,^FORMAT/GT dst.bcf # Annotate from a tab-delimited file with six columns (the fifth is ignored), # first indexing with tabix. The coordinates are 1-based. tabix -s1 -b2 -e2 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,POS,REF,ALT,-,TAG file.vcf # Annotate from a tab-delimited file with regions (1-based coordinates, inclusive) tabix -s1 -b2 -e3 annots.tab.gz bcftools annotate -a annots.tab.gz -h annots.hdr -c CHROM,FROM,TO,TAG inut.vcf # Annotate from a bed file (0-based coordinates, half-closed, half-open intervals) bcftools annotate -a annots.bed.gz -h annots.hdr -c CHROM,FROM,TO,TAG input.vcf Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#annotate https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "bed",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_csq/bcftools_csq/1.15.1+galaxy4",
    "name": "bcftools csq",
    "description": "Haplotype aware consequence predictor",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools csq Haplotype aware consequence predictor which correctly handles combined variants such as MNPs split over multiple VCF records, SNPs separated by an intron (but adjacent in the spliced transcript) or nearby frame-shifting indels which in combination in fact are not frame-shifting. The output VCF is annotated with INFO/BCSQ and FORMAT/BCSQ tag (configurable with the -c option). The latter is a bitmask of indexes to INFO/BCSQ, with interleaved haplotypes. See the usage examples below for using the %TBCSQ converter in query for extracting a more human readable form from this bitmask. The contruction of the bitmask limits the number of consequences that can be referenced in the FORMAT/BCSQ tags. By default this is 16, but if more are required, see the --ncsq option. The program requires on input a VCF/BCF file, the reference genome in fasta format (--fasta-ref) and genomic features in the GFF3 format downloadable from the Ensembl website (--gff-annot), and outputs an annotated VCF/BCF file. Currently, only Ensembl GFF3 files are supported. By default, the input VCF should be phased. If phase is unknown, or only partially known, the --phase option can be used to indicate how to handle unphased data. Alternatively, haplotype aware calling can be turned off with the --local-csq option. If conflicting (overlapping) variants within one haplotype are detected, a warning will be emitted and predictions will be based on only the first variant in the analysis. Symbolic alleles are not supported. They will remain unannotated in the output VCF and are ignored for the prediction analysis. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#csq https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_filter/bcftools_filter/1.15.1+galaxy4",
    "name": "bcftools filter",
    "description": "Apply fixed-threshold filters",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools filter Apply fixed-threshold filters. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#filter https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_view/bcftools_view/1.15.1+galaxy4",
    "name": "bcftools view",
    "description": "VCF/BCF conversion, view, subset and filter VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools view VCF/BCF conversion, view, subset and filter VCF/BCF files. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#view https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_call/bcftools_call/1.15.1+galaxy5",
    "name": "bcftools call",
    "description": "SNP/indel variant calling from VCF/BCF",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy5",
    "help": "bcftools call SNP/indel variant calling from VCF/BCF. To be used in conjunction with samtools mpileup. - This command replaces the former \"bcftools view\" caller. - Some of the original functionality has been temporarily lost in the process of transition to htslib, but will be added back on popular demand. - The original calling model can be invoked with the -c option. The novel-rate option can be set to modify the likelihood of novel mutation for constrained -C trio calling. The trio genotype calling maximizes likelihood of a particular combination of genotypes for father, mother and the child P(F=i,M=j,C=k) = P(unconstrained) * Pn + P(constrained) * (1-Pn). By providing three values, the mutation rate Pn is set explicitly for SNPs, deletions and insertions, respectively. If two values are given, the first is interpreted as the mutation rate of SNPs and the second is used to calculate the mutation rate of indels according to their length as Pn=float*exp(-a-b*len), where a=22.8689, b=0.2994 for insertions and a=21.9313, b=0.2856 for deletions [pubmed:23975140]. If only one value is given, the same mutation rate Pn is used for SNPs and indels. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#call https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_roh/bcftools_roh/1.15.1+galaxy4",
    "name": "bcftools roh",
    "description": "HMM model for detecting runs of homo/autozygosity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools roh HMM model for detecting runs of autozygosity. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#roh https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "data"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_merge/bcftools_merge/1.15.1+galaxy4",
    "name": "bcftools merge",
    "description": "Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools merge Merge multiple VCF/BCF files from non-overlapping sample sets to create one multi-sample file. Note that only records from different files can be merged, never from the same file. For \"vertical\" merge take a look at \"bcftools norm\" instead. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#merge https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_isec/bcftools_isec/1.15.1+galaxy4",
    "name": "bcftools isec",
    "description": "Create intersections, unions and complements of VCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools isec Create intersections, unions and complements of VCF files. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#isec https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_tags/bcftools_plugin_fill_tags/1.15.1+galaxy4",
    "name": "bcftools fill-tags",
    "description": "plugin Set INFO tags AF, AN, AC, AC_Hom, AC_Het, AC_Hemi",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools fill-tags plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fill_an_ac/bcftools_plugin_fill_an_ac/1.15.1+galaxy4",
    "name": "bcftools fill-AN-AC",
    "description": "plugin Fill INFO fields AN and AC",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools fill-AN-AC plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.15.1+galaxy4",
    "name": "bcftools stats",
    "description": "Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools stats Parses VCF or BCF and produces stats which can be plotted using plot-vcfstats. When two files are given, the program generates separate stats for intersection and the complements. By default only sites are compared, -s/-S must given to include also sample columns. When one VCF file is specified, then stats by non-reference allele frequency, depth distribution, stats by quality and per-sample counts, singleton stats, etc. are printed. When two VCF files are given, then stats such as concordance (Genotype concordance by non-reference allele frequency, Genotype concordance by sample, Non-Reference Discordance) and correlation are also printed. Per-site discordance (PSD) is also printed in --verbose mode. Collapse -------- Controls how to treat records with duplicate positions and defines compatible records across multiple input files. Here by \"compatible\" we mean records which should be considered as identical by the tools. For example, when performing line intersections, the desire may be to consider as identical all sites with matching positions (bcftools isec -c all), or only sites with matching variant type (bcftools isec -c snps -c indels), or only sites with all alleles identical (bcftools isec -c none). +------------+----------------------------------------------------------------+ | Flag value | Result | + + + | none | only records with identical REF and ALT alleles are compatible | +------------+----------------------------------------------------------------+ | some | only records where some subset of ALT alleles match are | | | compatible | +------------+----------------------------------------------------------------+ | all | all records are compatible, regardless of whether the ALT | | | alleles match or not. In the case of records with the same | | | position, only the first wil lbe considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | snps | any SNP records are compatible, regardless of whether the ALT | | | alleles match or not. For duplicate positions, only the first | | | SNP record will be considered and appear on output. | +------------+----------------------------------------------------------------+ | indels | all indel records are compatible, regardless of whether the | | | REF and ALT alleles match or not. For duplicate positions, | | | only the first indel record will be considered and appear on | | | output. | +------------+----------------------------------------------------------------+ | both | abbreviation of \"-c indels -c snps\" | +------------+----------------------------------------------------------------+ | id | only records with identical ID column are compatible. | | | Supportedby bcftools merge only. | +------------+----------------------------------------------------------------+ Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#stats https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "fasta"
    ],
    "output_formats": [
      "txt",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_reheader/bcftools_reheader/1.15.1+galaxy4",
    "name": "bcftools reheader",
    "description": "Modify header of VCF/BCF files, change sample names",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools reheader Modify header of VCF/BCF files, change sample names. http://samtools.github.io/bcftools/bcftools.html#reheader https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_impute_info/bcftools_plugin_impute_info/1.15.1+galaxy4",
    "name": "bcftools impute-info",
    "description": "plugin Add imputation information metrics to the INFO field",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools impute-info plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_from_vcf/bcftools_convert_from_vcf/1.15.1+galaxy4",
    "name": "bcftools convert from vcf",
    "description": "Converts VCF/BCF to IMPUTE2/SHAPEIT formats",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools convert from vcf Converts VCF/BCF to other formats. See man page for file formats details. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_consensus/bcftools_consensus/1.15.1+galaxy4",
    "name": "bcftools consensus",
    "description": "Create consensus sequence by applying VCF variants to a reference fasta file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools consensus plugin Create consensus sequence by applying VCF variants to a reference fasta file. http://samtools.github.io/bcftools/bcftools.html#consensus https://github.com/samtools/bcftools/wiki The option to set the new consensus' FASTA ID from the name of the VCF is provided by post-processing the bcftools consensus output. It is primarily intended for use when the VCF is coming from a list collection where the elements of the list are named meaningfully (e.g. named after sample names). This is useful when consensus sequences are being prepared for, for example, feeding a multiple sequence alignment to a phylogeny program.",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "fasta",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_concat/bcftools_concat/1.15.1+galaxy4",
    "name": "bcftools concat",
    "description": "Concatenate or combine VCF/BCF files",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools concat plugin Concatenate or combine VCF/BCF files. All source files must have the same sample columns appearing in the same order. The program can be used, for example, to concatenate chromosome VCFs into one VCF, or combine a SNP VCF and an indel VCF into one. The input files must be sorted by chr and position. The files must be given in the correct order to produce sorted VCF on output unless the -a, --allow-overlaps option is specified. Naive concatenation is useful when using a galaxy workflow that splits a BAM file by chromosome, processes each in parallel, then bcftools concat merges the results into a single VCF file: BAM -> bamtools split => bcftools mpileup => bcftools call => bcftools concat -> VCF Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. http://samtools.github.io/bcftools/bcftools.html#concat https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_mendelian/bcftools_plugin_mendelian/1.15.1+galaxy4",
    "name": "bcftools mendelian",
    "description": "plugin Count Mendelian consistent / inconsistent genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools mendelian plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular",
      "txt"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_counts/bcftools_plugin_counts/1.15.1+galaxy4",
    "name": "bcftools counts",
    "description": "plugin  counts number of samples, SNPs, INDELs, MNPs and total sites",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools counts plugin Counts number of samples, SNPs, INDELs, MNPs and total number of sites. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_setgt/bcftools_plugin_setgt/1.15.1+galaxy4",
    "name": "bcftools setGT",
    "description": "plugin Sets genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools setGT plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_cnv/bcftools_cnv/1.15.1+galaxy4",
    "name": "bcftools cnv",
    "description": "Call copy number variation from VCF B-allele frequency (BAF) and Log R Ratio intensity (LRR) values",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools cnv Copy number variation caller, requires Illumina's B-allele frequency (BAF) and Log R Ratio intensity (LRR). The HMM considers the following copy number states: CN 2 (normal), 1 (single-copy loss), 0 (complete loss), 3 (single-copy gain) Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#cnv https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_missing2ref/bcftools_plugin_missing2ref/1.15.1+galaxy4",
    "name": "bcftools missing2ref",
    "description": "plugin Set missing genotypes",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools missing2ref plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_query_list_samples/bcftools_query_list_samples/1.15.1+galaxy4",
    "name": "bcftools List Samples",
    "description": "in VCF/BCF file",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools List Samples query Lists Samples from a VCF/BCF file http://samtools.github.io/bcftools/bcftools.html#query https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_norm/bcftools_norm/1.15.1+galaxy4",
    "name": "bcftools norm",
    "description": "Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools norm Left-align and normalize indels; check if REF alleles match the reference; split multiallelic sites into multiple rows; recover multiallelics from multiple rows. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#norm https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_convert_to_vcf/bcftools_convert_to_vcf/1.15.1+galaxy4",
    "name": "bcftools convert to vcf",
    "description": "Converts other formats to VCF/BCFk",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools convert plugin Converts other variant formats to vcf. See man page for file formats details. http://samtools.github.io/bcftools/bcftools.html#convert https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "tabular",
      "fasta",
      "vcf"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_fixploidy/bcftools_plugin_fixploidy/1.15.1+galaxy4",
    "name": "bcftools fixploidy",
    "description": "plugin  Fix ploidy",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools fixploidy plugin Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz Expressions ----------- Valid expressions may contain: - numerical constants, string constants :: 1, 1.0, 1e-4 \"String\" - arithmetic operators :: +,*,-,/ - comparison operators :: (same as =), >, >=, 0.3 DP4[*] 0 CSQ[*] ~ \"missense_variant.*deleterious\" - function on FORMAT tags (over samples) and INFO tags (over vector fields) :: MAX, MIN, AVG, SUM, STRLEN, ABS - variables calculated on the fly if not present: number of alternate alleles; number of samples; count of alternate alleles; minor allele count (similar to AC but is always smaller than 0.5); frequency of alternate alleles (AF=AC/AN); frequency of minor alleles (MAF=MAC/AN); number of alleles in called genotypes :: N_ALT, N_SAMPLES, AC, MAC, AF, MAF, AN **Notes:** - String comparisons and regular expressions are case-insensitive - If the subscript \"*\" is used in regular expression search, the whole field is treated as one string. For example, the regex ``STR[*]~\"B,C\"`` will be true for the string vector INFO/STR=AB,CD. - Variables and function names are case-insensitive, but not tag names. For example, \"qual\" can be used instead of \"QUAL\", \"strlen()\" instead of \"STRLEN()\" , but not \"dp\" instead of \"DP\". **Examples:** :: MIN(DV)>5 MIN(DV/DP)>0.3 MIN(DP)>10 & MIN(DV)>3 FMT/DP>10 & FMT/GQ>10 .. both conditions must be satisfied within one sample FMT/DP>10 && FMT/GQ>10 .. the conditions can be satisfied in different samples QUAL>10 | FMT/GQ>10 .. selects only GQ>10 samples QUAL>10 || FMT/GQ>10 .. selects all samples at QUAL>10 sites TYPE=\"snp\" && QUAL>=10 && (DP4[2]+DP4[3] > 2) MIN(DP)>35 && AVG(GQ)>50 ID=@file .. selects lines with ID present in the file ID!=@~/file .. skip lines with ID present in the ~/file MAF[0]<0.05 .. select rare variants at 5% cutoff",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_gtcheck/bcftools_gtcheck/1.15.1+galaxy4",
    "name": "bcftools gtcheck",
    "description": "Check sample identity",
    "categories": [
      "VCF/BCF"
    ],
    "version": "1.15.1+galaxy4",
    "help": "bcftools gtcheck Check sample identity. With no -g BCF given, multi-sample cross-check is performed. Region Selections ----------------- Regions can be specified in a VCF, BED, or tab-delimited file (the default). The columns of the tab-delimited file are: CHROM, POS, and, optionally, POS_TO, where positions are 1-based and inclusive. Uncompressed files are stored in memory, while bgzip-compressed and tabix-indexed region files are streamed. Note that sequence names must match exactly, \"chr20\" is not the same as \"20\". Also note that chromosome ordering in FILE will be respected, the VCF will be processed in the order in which chromosomes first appear in FILE. However, within chromosomes, the VCF will always be processed in ascending genomic coordinate order no matter what order they appear in FILE. Note that overlapping regions in FILE can result in duplicated out of order positions in the output. This option requires indexed VCF/BCF files. Targets ------- Similar to regions, but the next position is accessed by streaming the whole VCF/BCF rather than using the tbi/csi index. Both regions and targets options can be applied simultaneously: regions uses the index to jump to a region and targets discards positions which are not in the targets. Unlike regions, targets can be prefixed with \"^\" to request logical complement. For example, \"^X,Y,MT\" indicates that sequences X, Y and MT should be skipped. Yet another difference between the two is that regions checks both start and end positions of indels, whereas targets checks start positions only. For the bcftools call command, with the option -C alleles, third column of the targets file must be comma-separated list of alleles, starting with the reference allele. Note that the file must be compressed and index. Such a file can be easily created from a VCF using:: bcftools query -f'%CHROM\\t%POS\\t%REF,%ALT\\n' file.vcf | bgzip -c > als.tsv.gz && tabix -s1 -b2 -e2 als.tsv.gz http://samtools.github.io/bcftools/bcftools.html#gtcheck https://github.com/samtools/bcftools/wiki",
    "input_formats": [
      "vcf",
      "vcf_bgzip",
      "bcf",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/1.3.2+galaxy0",
    "name": "medaka variant tool",
    "description": "Probability decoding",
    "categories": [
      "Nanopore"
    ],
    "version": "1.3.2+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) **Output** - decoded probabilities (VCF) **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/1.4.4+galaxy0",
    "name": "medaka variant tool",
    "description": "decodes variant calls from medaka consensus output",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. ---- .. class:: infomark **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) ---- .. class:: infomark **Output** - decoded probabilities (VCF) ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus/medaka_consensus/1.4.4+galaxy0",
    "name": "medaka consensus tool",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *consensus* runs inference from a trained model and alignments. ---- .. class:: infomark **Inputs and outputs** Medaka requires a BAM file as input, and generates a Hierarchical Data Format (H5/HDF) datafile. ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "h5",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant_pipeline/medaka_variant_pipeline/1.4.4+galaxy0",
    "name": "medaka variant pipeline",
    "description": "via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *medaka_variant* performs a variant calling via neural networks. ---- .. class:: infomark **Input** It is unlikely that the model arguments should be changed from their defaults. - reads aligned to reference (BAM), should be aligned to the reference against which to call variants - reference (FASTA) ---- .. class:: infomark **Output** - round_0_hap_mixed_phased.bam - round_0_hap_mixed_phased.vcf - round_0_hap_mixed_probs.hdf - round_0_hap_mixed_unphased.vcf - round_1_hap_1_probs.hdf - round_1_hap_1.vcf - round_1_hap_2_probs.hdf - round_1_hap_2.vcf - round_1_phased.vcf - round_1_unfiltered.vcf - round_1.vcf - log ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "vcf",
      "h5",
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus_pipeline/medaka_consensus_pipeline/1.4.4+galaxy0",
    "name": "medaka consensus pipeline",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The *medaka_consensus* pipeline performs assembly polishing via neural networks. ---- .. class:: infomark **Input** An *assembly* in .fasta format and *basecalls* in .fasta or .fastq format are required. See `Creating a Draft Assembly `_ for a detailed example of one method of obtaining these. ---- .. class:: infomark **Output** - Consensus polished assembly (FASTA) - Consensus Probabilities (H5/HDF) - Calls To Draft (BAM) - Draft To Consensus (chain, TXT) - Variants: VCF of changes (VCF) - Polished: BED file of polished regions (BED) ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "fasta",
      "h5",
      "bam",
      "bed",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/pycoqc/pycoqc/2.5.2+galaxy0",
    "name": "Pycoqc",
    "description": "quality control for Nanopore sequencing data",
    "categories": [
      "Nanopore"
    ],
    "version": "2.5.2+galaxy0",
    "help": ".. class:: infomark **What it does** *pycoqc* computes metrics and generates interactive QC plots for Oxford Nanopore technologies sequencing data. **Input** - Guppy Sequencing Summary Output (tsv) - Aligned Reads (bam) (Optional) **Output** - Output QC Report (HTML) - Output QC Metrics (JSON) **References** More information are available on the `pycoQC website `_.",
    "input_formats": [
      "txt",
      "tabular",
      "bam"
    ],
    "output_formats": [
      "html",
      "json"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.8.2+galaxy0",
    "name": "Flye assembly",
    "description": "of long and error-prone reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.8.2+galaxy0",
    "help": "Input reads could be in FASTA or FASTQ format, uncompressed or compressed with gz. Currenlty, raw and corrected reads from PacBio and ONT are supported. The expected error rates are <30% for raw and <2% for corrected reads. Additionally, --subassemblies option performs a consensus assembly of multiple sets of high-quality contigs. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. You must provide an estimate of the genome size as input, which is used for solid k-mers selection. The estimate could be rough (e.g. withing 0.5x-2x range) and does not affect the other assembly stages. Standard size modificators are supported (e.g. 5m or 2.6g).",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.8.3+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.8.3+galaxy0",
    "help": ".. class:: infomark **Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- .. class:: infomark **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. Additionally, the *--subassemblies* option performs a consensus assembly of multiple sets of high-quality contigs. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- .. class:: infomark **Outputs** The main output files are: :: - Final assembly: contains contigs and possibly scaffolds (see below). - Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. - Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: :: - Contig/scaffold id - Length - Coverage - Is circular, (Y)es or (N)o - Is repetitive, (Y)es or (N)o - Multiplicity (based on coverage) - Alternative group - Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with ?? symbols, and * symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by *. ---- .. class:: infomark **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: :: - K-mer counting / erroneous k-mer pre-filtering - Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) - Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: :: - Repeat graph is constructed from the (possibly misassembled) contigs - In this graph all repeats longer than minimum overlap are collapsed - The algorithm resolves repeats using the read information and graph structure - The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: :: - Alignment of all reads to the current assembly using minimap2 - Partition the alignment into mini-alignments (bubbles) - Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9+galaxy0",
    "help": ".. class:: infomark **Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- .. class:: infomark **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- .. class:: infomark **Outputs** The main output files are: :: - Final assembly: contains contigs and possibly scaffolds (see below). - Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. - Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: :: - Contig/scaffold id - Length - Coverage - Is circular, (Y)es or (N)o - Is repetitive, (Y)es or (N)o - Multiplicity (based on coverage) - Alternative group - Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with ?? symbols, and * symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by *. ---- .. class:: infomark **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: :: - K-mer counting / erroneous k-mer pre-filtering - Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) - Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: :: - Repeat graph is constructed from the (possibly misassembled) contigs - In this graph all repeats longer than minimum overlap are collapsed - The algorithm resolves repeats using the read information and graph structure - The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: :: - Alignment of all reads to the current assembly using minimap2 - Partition the alignment into mini-alignments (bubbles) - Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.36.2+galaxy1",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.36.2+galaxy1",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular",
      "png"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/porechop/porechop/0.2.4+galaxy0",
    "name": "Porechop",
    "description": "adapter trimmer for Oxford Nanopore reads",
    "categories": [
      "Nanopore"
    ],
    "version": "0.2.4+galaxy0",
    "help": "Porechop is a tool for finding and removing adapters from Oxford Nanopore reads. Adapters on the ends of reads are trimmed off, and when a read has an adapter in its middle, it is treated as chimeric and chopped into separate reads. Porechop performs thorough alignments to effectively find adapters, even at low sequence identity. Porechop also supports demultiplexing of Nanopore reads that were barcoded with the Native Barcoding Kit, PCR Barcoding Kit or Rapid Barcoding Kit.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fastq",
      "fastq.gz"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/1.4.4+galaxy1",
    "name": "medaka variant tool",
    "description": "decodes variant calls from medaka consensus output",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy1",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. ---- .. class:: infomark **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) ---- .. class:: infomark **Output** - decoded probabilities (VCF) ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant_pipeline/medaka_variant_pipeline/1.4.4+galaxy1",
    "name": "medaka variant pipeline",
    "description": "via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy1",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *medaka_variant* performs a variant calling via neural networks. ---- .. class:: infomark **Input** It is unlikely that the model arguments should be changed from their defaults. - reads aligned to reference (BAM), should be aligned to the reference against which to call variants - reference (FASTA) ---- .. class:: infomark **Output** - round_0_hap_mixed_phased.bam - round_0_hap_mixed_phased.vcf - round_0_hap_mixed_probs.hdf - round_0_hap_mixed_unphased.vcf - round_1_hap_1_probs.hdf - round_1_hap_1.vcf - round_1_hap_2_probs.hdf - round_1_hap_2.vcf - round_1_phased.vcf - round_1_unfiltered.vcf - round_1.vcf - log ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "bam",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "vcf",
      "h5",
      "bam",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus_pipeline/medaka_consensus_pipeline/1.4.4+galaxy1",
    "name": "medaka consensus pipeline",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.4.4+galaxy1",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The *medaka_consensus* pipeline performs assembly polishing via neural networks. ---- .. class:: infomark **Input** An *assembly* in .fasta format and *basecalls* in .fasta or .fastq format are required. See `Creating a Draft Assembly `_ for a detailed example of one method of obtaining these. ---- .. class:: infomark **Output** - Consensus polished assembly (FASTA) - Consensus Probabilities (H5/HDF) - Calls To Draft (BAM) - Draft To Consensus (chain, TXT) - Variants: VCF of changes (VCF) - Polished: BED file of polished regions (BED) ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "fasta",
      "h5",
      "bam",
      "bed",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/porechop/porechop/0.2.4",
    "name": "Porechop",
    "description": "adapter trimmer for Oxford Nanopore reads",
    "categories": [
      "Nanopore"
    ],
    "version": "0.2.4",
    "help": "Porechop is a tool for finding and removing adapters from Oxford Nanopore reads. Adapters on the ends of reads are trimmed off, and when a read has an adapter in its middle, it is treated as chimeric and chopped into separate reads. Porechop performs thorough alignments to effectively find adapters, even at low sequence identity. Porechop also supports demultiplexing of Nanopore reads that were barcoded with the Native Barcoding Kit, PCR Barcoding Kit or Rapid Barcoding Kit.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastqsanger",
      "fastqsanger.gz"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/1.7.2+galaxy0",
    "name": "medaka variant tool",
    "description": "decodes variant calls from medaka consensus output",
    "categories": [
      "Nanopore"
    ],
    "version": "1.7.2+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. ---- .. class:: infomark **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) ---- .. class:: infomark **Output** - decoded probabilities (VCF) ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus/medaka_consensus/1.7.2+galaxy0",
    "name": "medaka consensus tool",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.7.2+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *consensus* runs inference from a trained model and alignments. ---- .. class:: infomark **Inputs and outputs** Medaka requires a BAM file as input, and generates a Hierarchical Data Format (H5/HDF) datafile. ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "h5",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus_pipeline/medaka_consensus_pipeline/1.7.2+galaxy0",
    "name": "medaka consensus pipeline",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.7.2+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The *medaka_consensus* pipeline performs assembly polishing via neural networks. ---- .. class:: infomark **Input** An *assembly* in .fasta format and *basecalls* in .fasta or .fastq format are required. See `Creating a Draft Assembly `_ for a detailed example of one method of obtaining these. ---- .. class:: infomark **Output** - Consensus polished assembly (FASTA) - Consensus Probabilities (H5/HDF) - Calls To Draft (BAM) - Draft To Consensus (chain, TXT) - Variants: VCF of changes (VCF) - Polished: BED file of polished regions (BED) ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "fasta",
      "h5",
      "bam",
      "bed",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.1+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.1+galaxy0",
    "help": ".. class:: infomark **Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- .. class:: infomark **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- .. class:: infomark **Outputs** The main output files are: :: - Final assembly: contains contigs and possibly scaffolds (see below). - Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. - Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: :: - Contig/scaffold id - Length - Coverage - Is circular, (Y)es or (N)o - Is repetitive, (Y)es or (N)o - Multiplicity (based on coverage) - Alternative group - Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with ?? symbols, and * symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by *. ---- .. class:: infomark **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: :: - K-mer counting / erroneous k-mer pre-filtering - Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) - Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: :: - Repeat graph is constructed from the (possibly misassembled) contigs - In this graph all repeats longer than minimum overlap are collapsed - The algorithm resolves repeats using the read information and graph structure - The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: :: - Alignment of all reads to the current assembly using minimap2 - Partition the alignment into mini-alignments (bubbles) - Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.41.0+galaxy0",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.41.0+galaxy0",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular",
      "png"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.42.0+galaxy0",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.42.0+galaxy0",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/1.7.2+galaxy1",
    "name": "medaka variant tool",
    "description": "decodes variant calls from medaka consensus output",
    "categories": [
      "Nanopore"
    ],
    "version": "1.7.2+galaxy1",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. ---- .. class:: infomark **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) ---- .. class:: infomark **Output** - decoded probabilities (VCF) ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus_pipeline/medaka_consensus_pipeline/1.7.2+galaxy1",
    "name": "medaka consensus pipeline",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "1.7.2+galaxy1",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The *medaka_consensus* pipeline performs assembly polishing via neural networks. ---- .. class:: infomark **Input** An *assembly* in .fasta format and *basecalls* in .fasta or .fastq format are required. See `Creating a Draft Assembly `_ for a detailed example of one method of obtaining these. ---- .. class:: infomark **Output** - Consensus polished assembly (FASTA) - Consensus Probabilities (H5/HDF) - Calls To Draft (BAM) - Draft To Consensus (chain, TXT) - Variants: VCF of changes (VCF) - Polished: BED file of polished regions (BED) ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `manual `_ and `github `_.",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "fasta",
      "h5",
      "bam",
      "bed",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.3+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.3+galaxy0",
    "help": "**Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- **Outputs** The main output files are: * Final assembly: contains contigs and possibly scaffolds (see below). * Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. * Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: * Contig/scaffold id * Length * Coverage * Is circular, (Y)es or (N)o * Is repetitive, (Y)es or (N)o * Multiplicity (based on coverage) * Alternative group * Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with `??` symbols, and `*` symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by `*`. ---- **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: * K-mer counting / erroneous k-mer pre-filtering * Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) * Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: * Repeat graph is constructed from the (possibly misassembled) contigs * In this graph all repeats longer than minimum overlap are collapsed * The algorithm resolves repeats using the read information and graph structure * The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: * Alignment of all reads to the current assembly using minimap2 * Partition the alignment into mini-alignments (bubbles) * Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.42.0+galaxy1",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.42.0+galaxy1",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.43.0+galaxy0",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.43.0+galaxy0",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.4+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.4+galaxy0",
    "help": "**Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- **Outputs** The main output files are: * Final assembly: contains contigs and possibly scaffolds (see below). * Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. * Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: * Contig/scaffold id * Length * Coverage * Is circular, (Y)es or (N)o * Is repetitive, (Y)es or (N)o * Multiplicity (based on coverage) * Alternative group * Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with `??` symbols, and `*` symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by `*`. ---- **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: * K-mer counting / erroneous k-mer pre-filtering * Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) * Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: * Repeat graph is constructed from the (possibly misassembled) contigs * In this graph all repeats longer than minimum overlap are collapsed * The algorithm resolves repeats using the read information and graph structure * The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: * Alignment of all reads to the current assembly using minimap2 * Partition the alignment into mini-alignments (bubbles) * Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "gfa",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.5+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.5+galaxy0",
    "help": "**Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- **Outputs** The main output files are: * Final assembly: contains contigs and possibly scaffolds (see below). * Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. * Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: * Contig/scaffold id * Length * Coverage * Is circular, (Y)es or (N)o * Is repetitive, (Y)es or (N)o * Multiplicity (based on coverage) * Alternative group * Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with `??` symbols, and `*` symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by `*`. ---- **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: * K-mer counting / erroneous k-mer pre-filtering * Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) * Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: * Repeat graph is constructed from the (possibly misassembled) contigs * In this graph all repeats longer than minimum overlap are collapsed * The algorithm resolves repeats using the read information and graph structure * The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: * Alignment of all reads to the current assembly using minimap2 * Partition the alignment into mini-alignments (bubbles) * Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "gfa",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/clair3/clair3/1.0.8+galaxy1",
    "name": "Clair3",
    "description": "germline small variant caller for long-reads",
    "categories": [
      "Nanopore"
    ],
    "version": "1.0.8+galaxy1",
    "help": "Clair3 is a germline small variant caller for long-reads. Clair3 makes the best of two major method categories: pileup calling handles most variant candidates with speed, and full-alignment tackles complicated candidates to maximize precision and recall. Clair3 runs fast and has superior performance, especially at lower coverage. Clair3 is simple and modular for easy deployment and integration. https://github.com/HKU-BAL/Clair3 LICENSE: Copyright 2021 The University of Hong Kong, Department of Computer Science Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "bed",
      "vcf"
    ],
    "output_formats": [
      "vcf_bgzip"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/clair3/clair3/0.1.12+galaxy0",
    "name": "Clair3",
    "description": "germline small variant caller for long-reads",
    "categories": [
      "Nanopore"
    ],
    "version": "0.1.12+galaxy0",
    "help": "Clair3 is a germline small variant caller for long-reads. Clair3 makes the best of two major method categories: pileup calling handles most variant candidates with speed, and full-alignment tackles complicated candidates to maximize precision and recall. Clair3 runs fast and has superior performance, especially at lower coverage. Clair3 is simple and modular for easy deployment and integration. https://github.com/HKU-BAL/Clair3 LICENSE: Copyright 2021 The University of Hong Kong, Department of Computer Science Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "bed",
      "vcf"
    ],
    "output_formats": [
      "vcf_bgzip",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.5+galaxy1",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.5+galaxy1",
    "help": "**Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- **Outputs** The main output files are: * Final assembly: contains contigs and possibly scaffolds (see below). * Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. * Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: * Contig/scaffold id * Length * Coverage * Is circular, (Y)es or (N)o * Is repetitive, (Y)es or (N)o * Multiplicity (based on coverage) * Alternative group * Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with `??` symbols, and `*` symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by `*`. ---- **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: * K-mer counting / erroneous k-mer pre-filtering * Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) * Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: * Repeat graph is constructed from the (possibly misassembled) contigs * In this graph all repeats longer than minimum overlap are collapsed * The algorithm resolves repeats using the read information and graph structure * The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: * Alignment of all reads to the current assembly using minimap2 * Partition the alignment into mini-alignments (bubbles) * Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "gfa1",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.44.1+galaxy0",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.44.1+galaxy0",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/porechop/porechop/0.2.4+galaxy1",
    "name": "Porechop",
    "description": "adapter trimmer for Oxford Nanopore reads",
    "categories": [
      "Nanopore"
    ],
    "version": "0.2.4+galaxy1",
    "help": "Porechop is a tool for finding and removing adapters from Oxford Nanopore reads. Adapters on the ends of reads are trimmed off, and when a read has an adapter in its middle, it is treated as chimeric and chopped into separate reads. Porechop performs thorough alignments to effectively find adapters, even at low sequence identity. Porechop also supports demultiplexing of Nanopore reads that were barcoded with the Native Barcoding Kit, PCR Barcoding Kit or Rapid Barcoding Kit.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fastq",
      "fastq.gz"
    ],
    "output_formats": [
      "fasta",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/clair3/clair3/1.0.10+galaxy1",
    "name": "Clair3",
    "description": "germline small variant caller for long-reads",
    "categories": [
      "Nanopore"
    ],
    "version": "1.0.10+galaxy1",
    "help": "Clair3 is a germline small variant caller for long-reads. Clair3 makes the best of two major method categories: pileup calling handles most variant candidates with speed, and full-alignment tackles complicated candidates to maximize precision and recall. Clair3 runs fast and has superior performance, especially at lower coverage. Clair3 is simple and modular for easy deployment and integration. The tool can use models from the Oxford Nanopore Technologies Rerio_ repository, which are covered by a license that restricts their use to non-commercial use. If you select one of these models, you must agree to the terms of the Oxford Nanopore Technologies, Ltd. Public License, which can be found in the Rerio repository in the file LICENSE.txt. https://github.com/HKU-BAL/Clair3 LICENSE: Copyright 2021 The University of Hong Kong, Department of Computer Science Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. .. _Rerio: https://github.com/nanoporetech/rerio",
    "input_formats": [
      "bam",
      "cram",
      "fasta",
      "bed",
      "vcf"
    ],
    "output_formats": [
      "vcf_bgzip"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/flye/flye/2.9.6+galaxy0",
    "name": "Flye",
    "description": "de novo assembler for single molecule sequencing reads",
    "categories": [
      "Nanopore"
    ],
    "version": "2.9.6+galaxy0",
    "help": "**Purpose** Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PacBio/ONT reads as input and outputs polished contigs. Flye also has a special mode for metagenome assembly. ---- **Quick usage** Input reads can be in FASTA or FASTQ format, uncompressed or compressed with gz. Currently, PacBio (raw, corrected, HiFi) and ONT reads (raw, corrected) are supported. Expected error rates are <30% for raw, <3% for corrected, and <1% for HiFi. Note that Flye was primarily developed to run on raw reads. You may specify multiple files with reads (separated by spaces). Mixing different read types is not yet supported. The *--meta* o ption enables the mode for metagenome/uneven coverage assembly. Genome size estimate is no longer a required option. You need to provide an estimate if using *--asm-coverage* option. To reduce memory consumption for large genome assemblies, you can use a subset of the longest reads for initial disjointig assembly by specifying *--asm-coverage* and *--genome-size* options. Typically, 40x coverage is enough to produce good disjointigs. ---- **Outputs** The main output files are: * Final assembly: contains contigs and possibly scaffolds (see below). * Final repeat graph: note that the edge sequences might be different (shorter) than contig sequences, because contigs might include multiple graph edges. * Extra information about contigs (such as length or coverage). Each contig is formed by a single unique graph edge. If possible, unique contigs are extended with the sequence from flanking unresolved repeats on the graph. Thus, a contig fully contains the corresponding graph edge (with the same id), but might be longer then this edge. This is somewhat similar to unitig-contig relation in OLC assemblers. In a rare case when a repetitive graph edge is not covered by the set of \"extended\" contigs, it will be also output in the assembly file. Sometimes it is possible to further order contigs into scaffolds based on the repeat graph structure. These ordered contigs will be output as a part of scaffold in the assembly file (with a scaffold prefix). Since it is hard to give a reliable estimate of the gap size, those gaps are represented with the default 100 Ns. assembly_info.txt file (below) contains additional information about how scaffolds were formed. Extra information about contigs/scaffolds is output into the assembly_info.txt file. It is a tab-delimited table with the columns as follows: * Contig/scaffold id * Length * Coverage * Is circular, (Y)es or (N)o * Is repetitive, (Y)es or (N)o * Multiplicity (based on coverage) * Alternative group * Graph path (graph path corresponding to this contig/scaffold). Scaffold gaps are marked with `??` symbols, and `*` symbol denotes a terminal graph node. Alternative contigs (representing alternative haplotypes) will have the same alt. group ID. Primary contigs are marked by `*`. ---- **Algorithm Description** This is a brief description of the Flye algorithm. Please refer to the manuscript for more detailed information. The draft contig extension is organized as follows: * K-mer counting / erroneous k-mer pre-filtering * Solid k-mer selection (k-mers with sufficient frequency, which are unlikely to be erroneous) * Contig extension. The algorithm starts from a single read and extends it with a next overlapping read (overlaps are dynamically detected using the selected solid k-mers). Note that we do not attempt to resolve repeats at this stage, thus the reconstructed contigs might contain misassemblies. Flye then aligns the reads on these draft contigs using minimap2 and calls a consensus. Afterwards, Flye performs repeat analysis as follows: * Repeat graph is constructed from the (possibly misassembled) contigs * In this graph all repeats longer than minimum overlap are collapsed * The algorithm resolves repeats using the read information and graph structure * The unbranching paths in the graph are output as contigs If enabled, after resolving bridged repeats, Trestle module attempts to resolve simple unbridged repeats (of multiplicity 2) using the heterogeneities between repeat copies. Finally, Flye performs polishing of the resulting assembly to correct the remaining errors: * Alignment of all reads to the current assembly using minimap2 * Partition the alignment into mini-alignments (bubbles) * Error correction of each bubble using a maximum likelihood approach The polishing steps could be repeated, which might slightly increase quality for some datasets.",
    "input_formats": [
      "fasta",
      "fasta.gz",
      "fastq",
      "fastq.gz",
      "fastqsanger.gz",
      "fastqsanger"
    ],
    "output_formats": [
      "fasta",
      "graph_dot",
      "gfa1",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/nanoplot/nanoplot/1.46.1+galaxy0",
    "name": "NanoPlot",
    "description": "Plotting suite for Oxford Nanopore sequencing data and alignments",
    "categories": [
      "Nanopore"
    ],
    "version": "1.46.1+galaxy0",
    "help": "**What it does** NanoPlot_ is a plotting tool for long read sequencing data and alignments written by `Wouter De Coster`_ .. _NanoPlot: https://github.com/wdecoster/NanoPlot .. _`Wouter De Coster`: https://github.com/wdecoster **Input** NanoPlot requires 1 or more files as input. They can either be fastq (can be generated by albacore, guppy or MinKNOW containing additional information), fasta, sorted bam, sorted cram or sequencing summary. **Output** NanoPlot produces different number of plots depending on the data and customizations. A detailed view can be seen on here_. Additionally a file showing the statistics is generated. .. _here: https://github.com/wdecoster/NanoPlot#plots-generated",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "vcf_bgzip",
      "fasta",
      "fasta.gz",
      "txt",
      "zip",
      "bam",
      "cram"
    ],
    "output_formats": [
      "html",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_variant/medaka_variant/2.1.1+galaxy0",
    "name": "medaka vcf tool",
    "description": "decodes variant calls from medaka consensus output",
    "categories": [
      "Nanopore"
    ],
    "version": "2.1.1+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *variant* decodes probabilities. ---- .. class:: infomark **Input** - reference sequence (FASTA) - (several) consensus files (H5/HDF) ---- .. class:: infomark **Output** - decoded probabilities (VCF) ---- .. class:: infomark **References** More information are available in the `github `_.",
    "input_formats": [
      "h5",
      "fasta",
      "fasta.gz",
      "bam"
    ],
    "output_formats": [
      "vcf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus/medaka_consensus/2.1.1+galaxy0",
    "name": "medaka inference tool",
    "description": "inference from a trained model and alignments.",
    "categories": [
      "Nanopore"
    ],
    "version": "2.1.1+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The module *consensus* runs inference from a trained model and alignments. ---- .. class:: infomark **Inputs and outputs** Medaka requires a BAM file as input, and generates a Hierarchical Data Format (H5/HDF) datafile. ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `github `_.",
    "input_formats": [
      "bam",
      "bed"
    ],
    "output_formats": [
      "h5",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus_pipeline/medaka_consensus_pipeline/2.1.1+galaxy0",
    "name": "medaka consensus pipeline",
    "description": "Assembly polishing via neural networks",
    "categories": [
      "Nanopore"
    ],
    "version": "2.1.1+galaxy0",
    "help": ".. class:: infomark **What it does** *medaka* is a tool suite to create a consensus sequence from nanopore sequencing data. This task is performed using neural networks applied from a pileup of individual sequencing reads against a draft assembly. It outperforms graph-based methods operating on basecalled data, and can be competitive with state-of-the-art signal-based methods, whilst being much faster. The *medaka_consensus* pipeline performs assembly polishing via neural networks. ---- .. class:: infomark **Input** An *assembly* in .fasta format and *basecalls* in .fasta or .fastq format are required. ---- .. class:: infomark **Output** - Consensus polished assembly (FASTA) - Consensus Probabilities (H5/HDF) - Calls To Draft (BAM) - Draft To Consensus (chain, TXT) - Variants: VCF of changes (VCF) - Polished: BED file of polished regions (BED) ---- .. class:: infomark **Models** For best results it is important to specify the correct model, -m in the above, according to the basecaller used. Allowed values can be found by running medaka tools list\\_models. Medaka models are named to indicate i) the pore type, ii) the sequencing device (MinION or PromethION), iii) the basecaller variant, and iv) the basecaller version, with the format: :: {pore}_{device}_{caller variant}_{caller version} For example the model named r941_min_fast_g303 should be used with data from MinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version 3.0.3. By contrast the model r941_prom_hac_g303 should be used with PromethION data and the high accuracy basecaller (termed \"hac\" in Guppy configuration files). Where a version of Guppy has been used without an exactly corresponding medaka model, the medaka model with the highest version equal to or less than the guppy version should be selected. ---- .. class:: infomark **References** More information are available in the `github `_.",
    "input_formats": [
      "fastq",
      "fastq.gz",
      "fastqsanger",
      "fastqsanger.gz",
      "fasta",
      "fasta.gz"
    ],
    "output_formats": [
      "fasta",
      "h5",
      "bam",
      "bed",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinotate/trinotate/3.2.2+galaxy0",
    "name": "Trinotate",
    "description": "functional transcript annotation",
    "categories": [
      "RNA-seq"
    ],
    "version": "3.2.2+galaxy0",
    "help": ".. class:: infomark **What it does** Trinotate_ is a comprehensive annotation suite designed for automatic functional annotation of transcriptomes, particularly de novo assembled transcriptomes, from model or non-model organisms. Trinotate makes use of a number of different well referenced methods for functional annotation including homology search to known sequence data (BLAST+/SwissProt), protein domain identification (HMMER/PFAM), protein signal peptide and transmembrane domain prediction (signalP/tmHMM), and leveraging various annotation databases (eggNOG/GO/Kegg databases). All functional annotation data derived from the analysis of transcripts is integrated into a SQLite database which allows fast efficient searching for terms with specific qualities related to a desired scientific hypothesis or a means to create a whole annotation report for a transcriptome. .. _Trinotate: https://trinotate.github.io/ -------- **Suggested upstream Galaxy tools** Transcripts - Trinity: iuc/trinity_ .. _trinity: https://toolshed.g2.bx.psu.edu/repository?repository_id=faf6028922d9220a Peptides - TransDecoder: iuc/transdecoder_ .. _transdecoder: https://toolshed.g2.bx.psu.edu/repository?repository_id=7a2a8151a50f8099 Genes to transcripts map - Generate gene to transcript map for Trinity assembly: iuc/trinity_gene_to_trans_map_ .. _trinity_gene_to_trans_map: https://toolshed.g2.bx.psu.edu/repository?repository_id=faf6028922d9220a BLASTP: Peptides vs Uniprot.SwissProt - NCBI BLAST+ blastp: devteam/ncbi_blast_plus_ .. _ncbi_blast_plus: https://toolshed.g2.bx.psu.edu/repository?repository_id=1d92ebdf7e8d466c BLASTX: Transcripts vs Uniprot.SwissProt - NCBI BLAST+ blastx: devteam/ncbi_blast_plus_ .. _ncbi_blast_plus: https://toolshed.g2.bx.psu.edu/repository?repository_id=1d92ebdf7e8d466c HMMER hmmscan: Peptides vs PFAM - HMMER hmmscan: iuc/hmmer_hmmscan_ .. _hmmer_hmmscan: https://toolshed.g2.bx.psu.edu/repository?repository_id=a2cc4683090b1800 TMHMM on Peptides - TMHMM 2.0: peterjc/tmhmm_and_signalp_ .. _tmhmm_and_signalp: https://toolshed.g2.bx.psu.edu/repository?repository_id=292389a45f1a238a SignalP on Peptides - SignalP 3.0: peterjc/tmhmm_and_signalp_ .. _tmhmm_and_signalp: https://toolshed.g2.bx.psu.edu/repository?repository_id=292389a45f1a238a -------- **Output** The output has the following column headers: Column Description ------ ----------------------- 0 #gene_id 1 transcript_id 2 sprot_Top_BLASTX_hit 3 RNAMMER 4 prot_id 5 prot_coords 6 sprot_Top_BLASTP_hit 7 custom_pombe_pep_BLASTX 8 custom_pombe_pep_BLASTP 9 Pfam 10 SignalP 11 TmHMM 12 eggnog 13 Kegg 14 gene_ontology_blast 15 gene_ontology_pfam 16 transcript 17 peptide",
    "input_formats": [
      "fasta",
      "tabular",
      "txt",
      "sqlite"
    ],
    "output_formats": [
      "tabular",
      "sqlite"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/limma_voom/limma_voom/3.48.0+galaxy2",
    "name": "limma",
    "description": "Perform differential expression with limma-voom or limma-trend",
    "categories": [
      "RNA-seq"
    ],
    "version": "3.48.0+galaxy2",
    "help": ".. class:: infomark **What it does** Given a matrix of counts (e.g. from featureCounts) and optional information about the genes, this tool performs differential expression (DE) using the limma_ Bioconductor package and produces plots and tables useful in DE analysis. Interactive Glimma_ plots and tables can also be generated and links to the Glimma plots will be provided in the report. See an example workflow here_. In the `limma approach`_ to RNA-seq, read counts are converted to log2-counts-per-million (logCPM) and the mean-variance relationship is modelled either with precision weights or with an empirical Bayes prior trend. The precision weights approach is called voom and the prior trend approach is called limma-trend. For more information, see the Help section below. ----- **Inputs** **Differential Expression Method:** Option to use the limma-voom or limma-trend approach for differential expression. The default is limma-voom. If the sequencing depth is reasonably consistent across the RNA samples, then the simplest and most robust approach to differential expression is to use limma-trend. This approach will usually work well if the ratio of the largest library size to the smallest is not more than about 3-fold. When the library sizes are quite variable between samples, then the voom approach is theoretically more powerful than limma-trend. For more information see the excellent `limma User's Guide`_. **Counts Data:** The counts data can either be input as separate counts files (one sample per file) or a single count matrix (one sample per column). The rows correspond to genes, and columns correspond to the counts for the samples. Values must be tab separated, with the first row containing the sample/column labels and the first column containing the row/gene labels. The sample labels must start with a letter. Gene identifiers can be of any type but must be unique and not repeated within a counts file. Example - **Separate Count Files**: **GeneID** **WT1** ---------- ------- 11287 1699 11298 1905 11302 6 11303 2099 11304 356 11305 2528 Example - **Single Count Matrix**: **GeneID** **WT1** **WT2** **WT3** **Mut1** **Mut2** **Mut3** ---------- ------- ------- ------- -------- -------- -------- 11287 1699 1528 1601 1463 1441 1495 11298 1905 1744 1834 1345 1291 1346 11302 6 8 7 5 6 5 11303 2099 1974 2100 1574 1519 1654 11304 356 312 337 361 397 346 11305 2528 2438 2493 1762 1942 2027 **Gene Annotations:** Optional input for gene annotations, this can contain more information about the genes than just an ID number. The annotations will be available in the differential expression results table and the optional normalised counts table. They will also be used to generate interactive Glimma_ Volcano, MD plots and tables of differential expression. The input annotation file must contain a header row and have the gene IDs in the first column. The second column will be used to label the genes in the Volcano plot and interactive Glimma plots, additional columns will be available in the Glimma interactive table. The number of rows should match that of the counts files, add NA for any gene IDs with no annotation. The Galaxy tool **annotateMyIDs** can be used to obtain annotations for human, mouse, fly and zebrafish. Example: **GeneID** **Symbol** **GeneName** ---------- ---------- --------------------------------------------------- 11287 Pzp pregnancy zone protein 11298 Aanat arylalkylamine N-acetyltransferase 11302 Aatk apoptosis-associated tyrosine kinase 11303 Abca1 ATP-binding cassette, sub-family A (ABC1), member 1 11304 Abca4 ATP-binding cassette, sub-family A (ABC1), member 4 11305 Abca2 ATP-binding cassette, sub-family A (ABC1), member 2 **Factor Information:** Enter factor names and groups in the tool form, or provide a tab-separated file that has the names of the samples in the first column and one header row. The sample names must be the same as the names in the columns of the count matrix. The second column should contain the primary factor levels (e.g. WT, Mut) with optional additional columns for any secondary factors. Example: **Sample** **Genotype** **Batch** ---------- ------------ --------- WT1 WT b1 WT2 WT b2 WT3 WT b3 Mut1 Mut b1 Mut2 Mut b2 Mut3 Mut b3 *Factor Name:* The name of the experimental factor being investigated e.g. Genotype, Treatment. One factor must be entered and spaces must not be used. Optionally, additional factors can be included, these are variables that might influence your experiment e.g. Batch, Gender, Subject. If additional factors are entered, an additive linear model will be used. *Groups:* The names of the groups for the factor. The names should only contain letters, numbers and underscores, other characters such as spaces and hyphens MUST not be used. If entered into the tool form above, the order must be the same as the samples (to which the groups correspond) are listed in the columns of the counts matrix, with the values separated by commas. If the group names begin with a number an X will be added as a prefix. **Contrasts of Interest:** The contrasts you wish to make between levels. A common contrast would be a simple difference between two levels: \"Mut-WT\" represents the difference between the mutant and wild type genotypes. Multiple contrasts must be entered separately using the Insert Contrast button, spaces must not be used. Alternatively, a tab-separated file can be input that has the names of the comparisons in the first column and one header row, as shown below. Example: = **Contrasts** ------------- - Mut-WT WT-Mut = **Filter Low Counts:** Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discreteness of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. As a rule of thumb, genes are dropped if they cant possibly be expressed in all the samples for any of the conditions. Users can set their own definition of genes being expressed. Usually a gene is required to have a count of 5-10 in a library to be considered expressed in that library. Users should also filter with count-per-million (CPM) rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. Option to ignore the genes that do not show significant levels of expression, this filtering is dependent on two criteria: CPM/count and number of samples. You can specify to filter on CPM (Minimum CPM) or count (Minimum Count) values: * **Minimum CPM:** This is the minimum count per million that a gene must have in at least the number of samples specified under Minimum Samples. * **Minimum Count:** This is the minimum count that a gene must have. It can be combined with either Filter on Total Count or Minimum Samples. * **Filter on Total Count:** This can be used with the Minimum Count filter to keep genes with a minimum total read count. * **Minimum Samples:** This is the number of samples in which the Minimum CPM/Count requirement must be met in order for that gene to be kept. If the Minimum Samples filter is applied, only genes that exhibit a CPM/count greater than the required amount in at least the number of samples specified will be used for analysis. Care should be taken to ensure that the sample requirement is appropriate. In the case of an experiment with two experimental groups each with two members, if there is a change from insignificant CPM/count to significant CPM/count but the sample requirement is set to 3, then this will cause that gene to fail the criteria. When in doubt simply do not filter or consult the `limma User's Guide`_ for filtering recommendations. **Advanced Options:** By default error rate for multiple testing is controlled using Benjamini and Hochberg's false discovery rate control at a threshold value of 0.05. However there are options to change this to custom values. * **Minimum log2-fold-change Required:** In addition to meeting the requirement for the adjusted statistic for multiple testing, the observation must have an absolute log2-fold-change greater than this threshold to be considered significant, thus highlighted in the MD plot. * **Adjusted Threshold:** Set the threshold for the resulting value of the multiple testing control method. Only observations whose statistic falls below this value is considered significant, thus highlighted in the MD plot. * **P-Value Adjustment Method:** Change the multiple testing control method, the options are BH(1995) and BY(2001) which are both false discovery rate controls. There is also Holm(1979) which is a method for family-wise error rate control. **Testing relative to a threshold (TREAT):** If there are a lot of differentially expressed genes, a fold change threshold can be applied in addition to the P-value threshold to select genes that are more likely to be biologically significant. However, ranking by P-value and discarding genes with small logFCs can increase the false discovery rate. Using the limma TREAT function performs this analysis correctly (`McCarthy and Smyth, 2009`_). **Normalisation Method:** The most obvious technical factor that affects the read counts, other than gene expression levels, is the sequencing depth of each RNA sample. edgeR adjusts any differential expression analysis for varying sequencing depths as represented by differing library sizes. This is part of the basic modeling procedure and flows automatically into fold-change or p-value calculations. It is always present, and doesnt require any user intervention. The second most important technical influence on differential expression is one that is less obvious. RNA-seq provides a measure of the relative abundance of each gene in each RNA sample, but does not provide any measure of the total RNA output on a per-cell basis. This commonly becomes important when a small number of genes are very highly expressed in one sample, but not in another. The highly expressed genes can consume a substantial proportion of the total library size, causing the remaining genes to be under-sampled in that sample. Unless this RNA composition effect is adjusted for, the remaining genes may falsely appear to be down-regulated in that sample . The edgeR `calcNormFactors` function normalizes for RNA composition by finding a set of scaling factors for the library sizes that minimize the log-fold changes between the samples for most genes. The default method for computing these scale factors uses a trimmed mean of M values (TMM) between each pair of samples. We call the product of the original library size and the scaling factor the *effective library size*. The effective library size replaces the original library size in all downsteam analyses. TMM is the recommended method for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. You can change the normalisation method under **Advanced Options** above. For more information, see the `calcNormFactors` section in the `edgeR User's Guide`_. **Robust Settings** Option to use robust settings with eBayes or TREAT, used by both limma-voom and limma-trend. Using robust settings is usually recommended to protect against outlier genes, for more information see the `limma User's Guide`_ and `Phipson et al. 2016`_. This is turned on by default. **Prior Count:** If the limma-trend method is used, a count (`prior.count`) is added to all counts to avoid taking a log of zero, and damp down the variances of logarithms of low counts. A default of 3 is used, as recommended in the `limma User's Guide`_. **Apply Sample Weights:** If the limma-voom method is used, an option is available to downweight outlier samples, such that their information is still used in the statistical analysis but their impact is reduced. Use this whenever significant outliers are present. The MDS plotting tool in this package is useful for identifying outliers. For more information on this option see Liu et al. (2015). **Outputs** This tool outputs * a table of differentially expressed genes for each contrast of interest * a HTML report with plots and additional information Optionally, under **Output Options** you can choose to output * interactive Glimma plots and tables: MDS plot, and (if annotation file is input) Volcano plot and MD plot (default: Yes) * additional plots in the report and as PDFs * a normalised counts table * a library size information file * the R script used by this tool * an RData file ----- **Citations:** Please try to cite the appropriate articles when you publish results obtained using software, as such citation is the main means by which the authors receive credit for their work. limma Please cite the paper below for the limma software itself. Please also try to cite the appropriate methodology articles that describe the statistical methods implemented in limma, depending on which limma functions you are using. The methodology articles are listed in Section 2.1 of the `limma User's Guide`_. * Smyth GK (2005). Limma: linear models for microarray data. In: 'Bioinformatics and Computational Biology Solutions using R and Bioconductor'. R. Gentleman, V. Carey, S. Dudoit, R. Irizarry, W. Huber (eds), Springer, New York, pages 397-420. * Law CW, Chen Y, Shi W, and Smyth GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29. * Liu R, Holik AZ, Su S, Jansz N, Chen K, Leong HS, Blewitt ME, Asselin-Labat ML, Smyth GK, Ritchie ME (2015). Why weight? Modelling sample and observational level variability improves power in RNA-seq analyses. Nucleic Acids Research, 43(15), e97. * Ritchie, M. E., Diyagama, D., Neilson, J., van Laar, R., Dobrovic, A., Holloway, A., and Smyth, G. K. (2006). Empirical array quality weights for microarray data. BMC Bioinformatics 7, Article 261. edgeR Please cite the first paper for the software itself and the other papers for the various original statistical methods implemented in edgeR. See Section 1.2 in the `edgeR User's Guide`_ for more detail. * Robinson MD, McCarthy DJ and Smyth GK (2010). edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26, 139-140 * Robinson MD and Smyth GK (2007). Moderated statistical tests for assessing differences in tag abundance. Bioinformatics 23, 2881-2887 * Robinson MD and Smyth GK (2008). Small-sample estimation of negative binomial dispersion, with applications to SAGE data. Biostatistics, 9, 321-332 * McCarthy DJ, Chen Y and Smyth GK (2012). Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation. Nucleic Acids Research 40, 4288-4297 Please report problems or suggestions to: su.s@wehi.edu.au .. _limma: http://www.bioconductor.org/packages/release/bioc/html/limma.html .. _Glimma: https://bioconductor.org/packages/release/bioc/html/Glimma.html .. _here: https://f1000research.com/articles/5-1408/v3 .. _limma approach: https://www.ncbi.nlm.nih.gov/pubmed/25605792 .. _limma User's Guide: http://bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf .. _edgeR: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html .. _edgeR User's Guide: https://bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf .. _McCarthy and Smyth, 2009: https://www.ncbi.nlm.nih.gov/pubmed/19176553 .. _Phipson et al. 2016: https://www.ncbi.nlm.nih.gov/pubmed/28367255",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/edger/edger/3.34.0+galaxy2",
    "name": "edgeR",
    "description": "Perform differential expression of count data",
    "categories": [
      "RNA-seq"
    ],
    "version": "3.34.0+galaxy2",
    "help": ".. class:: infomark **What it does** Given a counts matrix, or a set of counts files, for example from **featureCounts**, and optional information about the genes, this tool produces plots and tables useful in the analysis of differential gene expression. This tool uses the `edgeR`_ quasi-likelihood pipeline (edgeR-quasi) for differential expression analysis. This statistical methodology uses negative binomial generalized linear models, but with F-tests instead of likelihood ratio tests. This method provides stricter error rate control than other negative binomial based pipelines, including the traditional edgeR pipelines or DESeq2. While the limma pipelines are recommended for large-scale datasets, because of their speed and flexibility, the edgeR-quasi pipeline gives better performance in low-count situations. For the data analyzed in this `edgeR workflow article`_ ,the edgeR-quasi, limma-voom and limma-trend pipelines are all equally suitable and give similar results. .. _edgeR: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html .. _edgeR workflow article: https://f1000research.com/articles/5-1438 ----- **Inputs** **Counts Data:** The counts data can either be input as separate counts files (one sample per file) or a single count matrix (one sample per column). The rows correspond to genes, and columns correspond to the counts for the samples. Values must be tab separated, with the first row containing the sample/column labels and the first column containing the row/gene labels. The sample labels must start with a letter. Gene identifiers can be of any type but must be unique and not repeated within a counts file. Example - **Separate Count Files**: **GeneID** **WT1** ---------- ------- 11287 1699 11298 1905 11302 6 11303 2099 11304 356 11305 2528 Example - **Single Count Matrix**: **GeneID** **WT1** **WT2** **WT3** **Mut1** **Mut2** **Mut3** ---------- ------- ------- ------- -------- -------- -------- 11287 1699 1528 1601 1463 1441 1495 11298 1905 1744 1834 1345 1291 1346 11302 6 8 7 5 6 5 11303 2099 1974 2100 1574 1519 1654 11304 356 312 337 361 397 346 11305 2528 2438 2493 1762 1942 2027 **Gene Annotations:** Optional input for gene annotations, this can contain more information about the genes than just an ID number. The annotations will be available in the differential expression results table and the optional normalised counts table. The file must contain a header row and have the gene IDs in the first column. The number of rows should match that of the counts files, add NA for any gene IDs with no annotation. The Galaxy tool **annotateMyIDs** can be used to obtain annotations for human, mouse, fly and zebrafish. Example: **GeneID** **Symbol** **GeneName** ---------- ---------- --------------------------------------------------- 11287 Pzp pregnancy zone protein 11298 Aanat arylalkylamine N-acetyltransferase 11302 Aatk apoptosis-associated tyrosine kinase 11303 Abca1 ATP-binding cassette, sub-family A (ABC1), member 1 11304 Abca4 ATP-binding cassette, sub-family A (ABC1), member 4 11305 Abca2 ATP-binding cassette, sub-family A (ABC1), member 2 **Factor Information:** Enter factor names and groups in the tool form, or provide a tab-separated file that has the names of the samples in the first column and one header row. The sample names must be the same as the names in the columns of the count matrix. The second column should contain the primary factor levels (e.g. WT, Mut) with optional additional columns for any secondary factors. Example: **Sample** **Genotype** **Batch** ---------- ------------ --------- WT1 WT b1 WT2 WT b2 WT3 WT b3 Mut1 Mut b1 Mut2 Mut b2 Mut3 Mut b3 *Factor Name:* The name of the experimental factor being investigated e.g. Genotype, Treatment. One factor must be entered, the name should start with a letter and spaces must not be used. Optionally, additional factors can be included, these are variables that might influence your experiment e.g. Batch, Gender, Subject. If additional factors are entered, an additive linear model will be used. *Groups:* The names of the groups for the factor. The names should start with a letter, and only contain letters, numbers and underscores, other characters such as spaces and hyphens must not be used. If entered into the tool form above, the order must be the same as the samples (to which the groups correspond) are listed in the columns of the counts matrix, with the values separated by commas. **Contrasts of Interest:** The contrasts you wish to make between levels. A common contrast would be a simple difference between two levels: \"Mut-WT\" represents the difference between the mutant and wild type genotypes. Multiple contrasts must be entered separately using the Insert Contrast button, spaces must not be used. **Filter Low Counts:** Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discreteness of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. As a rule of thumb, genes are dropped if they cant possibly be expressed in all the samples for any of the conditions. Users can set their own definition of genes being expressed. Usually a gene is required to have a count of 5-10 in a library to be considered expressed in that library. Users should also filter with count-per-million (CPM) rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. Option to ignore the genes that do not show significant levels of expression, this filtering is dependent on two criteria: CPM/count and number of samples. You can specify to filter on CPM (Minimum CPM) or count (Minimum Count) values: * **Minimum CPM:** This is the minimum count per million that a gene must have in at least the number of samples specified under Minimum Samples. * **Minimum Count:** This is the minimum count that a gene must have. It can be combined with either Filter on Total Count or Minimum Samples. * **Filter on Total Count:** This can be used with the Minimum Count filter to keep genes with a minimum total read count. * **Minimum Samples:** This is the number of samples in which the Minimum CPM/Count requirement must be met in order for that gene to be kept. If the Minimum Samples filter is applied, only genes that exhibit a CPM/count greater than the required amount in at least the number of samples specified will be used for analysis. Care should be taken to ensure that the sample requirement is appropriate. In the case of an experiment with two experimental groups each with two members, if there is a change from insignificant CPM/count to significant CPM/count but the sample requirement is set to 3, then this will cause that gene to fail the criteria. When in doubt simply do not filter or consult the `edgeR workflow article`_ for filtering recommendations. **Advanced Options:** By default error rate for multiple testing is controlled using Benjamini and Hochberg's false discovery rate control at a threshold value of 0.05. However there are options to change this to custom values. * **Minimum log2-fold-change Required:** In addition to meeting the requirement for the adjusted statistic for multiple testing, the observation must have an absolute log2-fold-change greater than this threshold to be considered significant, thus highlighted in the MD plot. * **Adjusted Threshold:** Set the threshold for the resulting value of the multiple testing control method. Only observations whose statistic falls below this value is considered significant, thus highlighted in the MD plot. * **P-Value Adjustment Method:** Change the multiple testing control method, the options are BH(1995) and BY(2001) which are both false discovery rate controls. There is also Holm(1979) which is a method for family-wise error rate control. **Normalisation Method:** The most obvious technical factor that affects the read counts, other than gene expression levels, is the sequencing depth of each RNA sample. edgeR adjusts any differential expression analysis for varying sequencing depths as represented by differing library sizes. This is part of the basic modeling procedure and flows automatically into fold-change or p-value calculations. It is always present, and doesnt require any user intervention. The second most important technical influence on differential expression is one that is less obvious. RNA-seq provides a measure of the relative abundance of each gene in each RNA sample, but does not provide any measure of the total RNA output on a per-cell basis. This commonly becomes important when a small number of genes are very highly expressed in one sample, but not in another. The highly expressed genes can consume a substantial proportion of the total library size, causing the remaining genes to be under-sampled in that sample. Unless this RNA composition effect is adjusted for, the remaining genes may falsely appear to be down-regulated in that sample . The edgeR `calcNormFactors` function normalizes for RNA composition by finding a set of scaling factors for the library sizes that minimize the log-fold changes between the samples for most genes. The default method for computing these scale factors uses a trimmed mean of M values (TMM) between each pair of samples. We call the product of the original library size and the scaling factor the *effective library size*. The effective library size replaces the original library size in all downsteam analyses. TMM is the recommended method for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. You can change the normalisation method under **Advanced Options** above. For more information, see the `calcNormFactors` section in the `edgeR User's Guide`_. **Robust Settings** Option to use robust settings. Using robust settings (robust=TRUE) with the edgeR estimateDisp and glmQLFit functions is usually recommended to protect against outlier genes. This is turned on by default. Note that it is only used with the quasi-likelihood F test method. For more information, see the `edgeR workflow article`_. **Test Method** Option to use the likelihood ratio test instead of the quasi-likelihood F test. For more information, see the `edgeR workflow article`_. .. _edgeR User's Guide: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html ----- **Outputs** This tool outputs * a table of differentially expressed genes for each contrast of interest * a HTML report with plots and additional information Optionally, under **Output Options** you can choose to output * a normalised counts table * the R script used by this tool * an RData file ----- **Citations** Please try to cite the appropriate articles when you publish results obtained using software, as such citation is the main means by which the authors receive credit for their work. For the edgeR method itself, please cite Robinson et al., 2010, and for this tool (which was developed from the Galaxy limma-voom tool) please cite Liu et al., 2015.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/featurecounts/featurecounts/2.0.1+galaxy2",
    "name": "featureCounts",
    "description": "Measure gene expression in RNA-Seq experiments from SAM or BAM files",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.1+galaxy2",
    "help": "featureCounts ############# Overview -------- FeatureCounts is a light-weight read counting program written entirely in the C programming language. It can be used to count both gDNA-seq and RNA-seq reads for genomic features in in SAM/BAM files. FeatureCounts is part of the Subread_ package. Input formats ------------- Alignments should be provided in either: - SAM format, http://samtools.sourceforge.net/samtools.shtml#5 - BAM format Annotations for gene regions should be provided in the GFF/GTF format: - http://genome.ucsc.edu/FAQ/FAQformat.html#format3 - http://www.ensembl.org/info/website/upload/gff.html Alternatively, the featureCounts built-in annotations for genomes hg38, hg19, mm10 and mm9 can be used through selecting the built-in option above. These annotation files are in simplified annotation format (SAF) as shown below. The GeneID column contains Entrez gene identifiers and each entry (row) is taken as a feature (e.g. an exon). Example - **Built-in annotation format**: GeneID Chr Start End Strand 497097 chr1 3204563 3207049 - 497097 chr1 3411783 3411982 - 497097 chr1 3660633 3661579 - These annotation files can be found in the `Subread package`_. You can see the version of Subread used by this wrapper in the tool form above under `Options > Requirements`. To create the files, the annotations were downloaded from NCBI RefSeq database and then adapted by merging overlapping exons from the same gene to form a set of disjoint exons for each gene. Genes with the same Entrez gene identifiers were also merged into one gene. See the `Subread User's Guide`_ for more information. Gene names can be obtained for these Entrez identifiers with the Galaxy **annotateMyIDs** tool. Output format ------------- FeatureCounts produces a table containing counted reads, per gene, per row. Optionally the last column can be set to be the effective gene-length. These tables are compatible with the DESeq2, edgeR and limma-voom Galaxy wrappers by IUC. .. _Subread: http://subread.sourceforge.net/ .. _`Subread User's Guide`: https://bioconductor.org/packages/release/bioc/vignettes/Rsubread/inst/doc/SubreadUsersGuide.pdf .. _`Subread package`: https://sourceforge.net/projects/subread/files/",
    "input_formats": [
      "bam",
      "sam",
      "gff",
      "gtf",
      "gff3",
      "fasta"
    ],
    "output_formats": [
      "tabular",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie_merge/2.1.7+galaxy1",
    "name": "StringTie merge",
    "description": "transcripts",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.1.7+galaxy1",
    "help": "**What it does?** This is a special usage mode of StringTie_, distinct from the assembly usage mode. In the merge mode, StringTie takes as input a list of GTF/GFF files and merges/assembles these transcripts into a non-redundant set of transcripts. This mode is used in the new differential analysis pipeline to generate a global, unified set of transcripts (isoforms) across multiple RNA-Seq samples. If a reference annotation is provided, StringTie will assemble the transfrags from the input GTF files with the reference transcripts. .. _StringTie: http://ccb.jhu.edu/software/stringtie/",
    "input_formats": [
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "gtf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie/2.1.7+galaxy1",
    "name": "StringTie",
    "description": "transcript assembly and quantification",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.1.7+galaxy1",
    "help": ".. class:: infomark **What it does** StringTie_ is a fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional *de novo* assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus. Its input can include not only the alignments of raw reads used by other transcript assemblers, but also alignments of longer sequences that have been assembled from those reads. In order to identify differentially expressed genes between experiments, StringTie's output can be processed by specialized software like Ballgown_, Cuffdiff_ or other programs (DESeq2_, edgeR_, limma_ etc.). ----- **Inputs** StringTie takes as input a BAM (or SAM) file of paired-end RNA-seq reads, which must be sorted by genomic location (coordinate position). This file contains spliced read alignments and can be produced directly by programs such as HISAT2_. We recommend using HISAT2 as it is a fast and accurate alignment program. Every spliced read alignment (i.e. an alignment across at least one junction) in the input BAM file must contain the tag XS to indicate the genomic strand that produced the RNA from which the read was sequenced. Alignments produced by HISAT2 (when run with --dta option) already include this tag, but if you use a different read mapper you should check that this XS tag is included for spliced alignments. *NOTE: be sure to run HISAT2 with the --dta option for alignment (under Spliced alignment options), or your results will suffer.* Also note that if your reads are from a stranded library, you need to choose the appropriate setting under **Specify strand information** above. As, if Forward (FR) is selected, StringTie will assume the reads are from a --fr library, while if Reverse (RF) is selected, StringTie will assume the reads are from a --rf library, otherwise it is assumed that the reads are from an unstranded library (The widely-used, although now deprecated, TopHat had a similar --library-type option, where fr-firststrand corresponded to RF; fr-secondstrand corresponded to FR). If you don't know whether your reads are from are a stranded library or not, you could use the tool **RSeQC Infer Experiment** to try to determine. As an option, a reference annotation file in `GTF/GFF3`_ format can be provided to StringTie. In this case, StringTie will prefer to use these \"known\" genes from the annotation file, and for the ones that are expressed it will compute coverage, TPM and FPKM values. It will also produce additional transcripts to account for RNA-seq data that aren't covered by (or explained by) the annotation. Note that if option -e is not used the reference transcripts need to be fully covered by reads in order to be included in StringTie's output. In that case, other transcripts assembled from the data by StringTie and not present in the reference file will be printed as well. *NOTE: we highly recommend that you provide annotation if you are analyzing a genome that is well-annotated, such as human, mouse, or other model organisms.* ----- **Outputs** StringTie's primary output is * a GTF file containing the **Assembled transcripts** Optionally, it can output * a TSV (tab-delimited) file of **Gene abundances** If a reference GTF/GFF3 file is used as a guide, StringTie can also output: * a GTF file containing all **fully-covered reference transcripts** in the provided reference file that are covered end-to-end by reads * Files (tables) for **Ballgown** and/or **DESeq2/edgeR/limma-voom**, which can use them to estimate differential expression **StringTie's primary GTF output** The primary output of StringTie is a Gene Transfer Format (GTF) file that contains details of the transcripts that StringTie assembles from RNA-Seq data. GTF is an extension of GFF (Gene Finding Format, also called General Feature Format), and is very similar to GFF2 and GFF3. The field definitions for the 9 columns of GTF output can be found at the `Ensembl site here`_. The following is an example of a transcript assembled by StringTie as shown in a GTF file: **seqname** **source** **feature** **start** **end** **score** **strand** **frame** **attributes** ----------- ---------- ----------- --------- ------- --------- ---------- --------- ------------------------------------------------------------------------------------------- chrX StringTie transcript 281394 303355 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"101.256691\"; FPKM \"530.078918\"; TPM \"705.667908\"; chrX StringTie exon 281394 281684 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; exon_number \"1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"116.270836\"; * **seqname**: Denotes the chromosome, contig, or scaffold for this transcript. Here the assembled transcript is on chromosome X. * **source**: The source of the GTF file. Since this example was produced by StringTie, this column simply shows 'StringTie'. * **feature**: Feature type (e.g., exon, transcript, mRNA, 5'UTR). * **start**: Start position of the feature (exon, transcript, etc), using a 1-based index. * **end**: End position of the feature, using a 1-based index. * **score**: A confidence score for the assembled transcript. Currently this field is not used, and StringTie reports a constant value of 1000 if the transcript has a connection to a read alignment bundle. * **strand**: If the transcript resides on the forward strand, '+'. If the transcript resides on the reverse strand, '-'. * **frame**: Frame or phase of CDS features. StringTie does not use this field and simply records a \".\". * **attributes**: A semicolon-separated list of tag-value pairs, providing additional information about each feature. Depending on whether an instance is a transcript or an exon and on whether the transcript matches the reference annotation file provided by the user, the content of the attributes field will differ. The following list describes the possible attributes shown in this column: * *gene_id*: A unique identifier for a single gene and its child transcript and exons based on the alignments' file name. * *transcript_id*: A unique identifier for a single transcript and its child exons based on the alignments' file name. * *exon_number*: A unique identifier for a single exon, starting from 1, within a given transcript. * *reference_id*: The transcript_id in the reference annotation (optional) that the instance matched. * *ref_gene_id*: The gene_id in the reference annotation (optional) that the instance matched. * *ref_gene_name*: The gene_name in the reference annotation (optional) that the instance matched. * *cov*: The average per-base coverage for the transcript or exon. * *FPKM*: Fragments per kilobase of transcript per million read pairs. This is the number of pairs of reads aligning to this feature, normalized by the total number of fragments sequenced (in millions) and the length of the transcript (in kilobases). * *TPM*: Transcripts per million. This is the number of transcripts from this particular gene normalized first by gene length, and then by sequencing depth (in millions) in the sample. A detailed explanation and a comparison of TPM and FPKM can be found here_, and TPM was defined `by B. Li and C. Dewey here`_. **Gene abundances in tab-delimited format** If StringTie is run with the -A option, it returns a file containing gene abundances. The tab-delimited gene abundances output file has nine fields; below is an example of a gene abundance file produced by StringTie using reference annotation: **Gene ID** **Gene Name** **Reference** **Strand** **Start** **End** **Coverage** **FPKM** **TPM** ----------- ------------- ------------- ---------- --------- ------- ------------ -------- -------- NM_000451 SHOX chrX \\+ 624344 646823 0.000000 0.000000 0.000000 NM_006883 SHOX chrX \\+ 624344 659411 0.000000 0.000000 0.000000 * **Gene ID**: The gene identifier comes from the reference annotation provided with the -G option. If no reference is provided this field is replaced with the name prefix for output transcripts (-l). * **Gene Name**: This field contains the gene name in the reference annotation provided with the -G option. If no reference is provided this field is populated with '-'. * **Reference**: Name of the reference sequence that was used in the alignment of the reads. Equivalent to the 3rd column in the .SAM alignment. * **Strand**: '+' denotes that the gene is on the forward strand, '-' for the reverse strand. * **Start**: Start position of the gene (1-based index). * **End**: End position of the gene (1-based index). * **Coverage**: Per-base coverage of the gene. * **FPKM**: normalized expression level in FPKM units (see previous section). * **TPM**: normalized expression level in RPM units (see previous section). **Fully covered transcripts matching the reference annotation transcripts (in GTF format)** If StringTie is run with the use reference guide option (-G), it will also return a file with all the transcripts in the reference annotation that are fully covered, end to end, by reads. The output format is a GTF file as described above. Each line of the GTF is corresponds to a gene or transcript in the reference annotation. **Ballgown Input Table Files** An option to output files for Ballgown can be selected under **Output files for differential expression?** above. If selected, StringTie will return Ballgown input table files containing coverage data for the reference transcripts given with the -G option. These tables have these specific names: (1) e2t.ctab, (2) e_data.ctab, (3) i2t.ctab, (4) i_data.ctab, and (5) t_data.ctab. A detailed description of each of these five required inputs to Ballgown can be found at `this link`. With this option StringTie can be used as a direct replacement of the tablemaker program included with the Ballgown distribution. **DESeq2/edgeR/limma-voom Input Table Files** DESeq2_, edgeR_ and limma_ are three popular Bioconductor_ packages for analyzing differential expression, which take as input a matrix of read counts mapped to particular genomic features (e.g., genes). This read count information can be extracted directly from the files generated by StringTie (run with the -e parameter) by selecting DESeq2/edgeR/limma-voom under **Output files for differential expression?** above. This uses the StringTie helper script ``prepDE.py`` to convert the GTF output from StringTie into two tab-delimited (TSV) files, containing the count matrices for genes and transcripts, using the coverage values found in the output of StringTie -e. ----- **More Information** *Evaluating transcript assemblies:* A simple way of getting more information about the transcripts assembled by StringTie (summary of gene and transcript counts, novel vs. known etc.), or even performing basic tracking of assembled isoforms across multiple RNA-Seq experiments, is to use the **gffcompare** program. Basic usage information for this program can be found on the `GFF utilities page`_. *Differential expression analysis:* Together with HISAT and Ballgown (or DESeq2/edgeR/limma-voom), StringTie can be used for estimating differential expression across multiple RNA-Seq samples and generating plots and differential expression tables as described in our `protocol paper`_ and shown in a diagram in the `StringTie manual here`_. Our recommended workflow includes the following steps: 1. For each RNA-Seq sample, map the reads to the genome with HISAT2 using the --dta option. It is highly recommended to use the reference annotation information when mapping the reads, which can be either embedded in the genome index (built with the --ss and --exon options, see HISAT2 manual), or provided separately at run time (using the --known-splicesite-infile option of HISAT2). The SAM output of each HISAT2 run must be sorted and converted to BAM using samtools as explained above. 2. For each RNA-Seq sample, use this StringTie tool to assemble the read alignments obtained in the previous step; it is recommended to run StringTie with the -G option if the reference annotation is available. 3. Run the separate **StringTie merge** tool in order to generate a non-redundant set of transcripts observed in all the RNA-Seq samples assembled previously. ``StringTie merge`` takes as input a list of all the assembled transcripts files (in GTF format) previously obtained for each sample, as well as a reference annotation file (-G option) if available. 4. For each RNA-Seq sample, run this StringTie tool selecting to output files for Ballgown (or DESeq2/edgeR/limma-voom), which will generate tables of transcript and gene estimated abundances (count files). The option -e (*Use Reference transcripts only*) is not required but is recommended for this run in order to produce more accurate abundance estimations of the input transcripts. Each StringTie run in this step will take as input the sorted read alignments (BAM file) obtained in step 1 for the corresponding sample and the -G option with the merged transcripts (GTF file) generated by ``stringtie merge`` in step 3. Please note that this is the only case where the -G option is not used with a reference annotation, but with the global, merged set of transcripts as observed across all samples. (This step is the equivalent of the *Tablemaker* step described in the original Ballgown pipeline.) 5. Ballgown (or DESeq2/edgeR/limma-voom) can now be used to load the coverage tables generated in the previous step and perform various statistical analyses for differential expression, generate plots etc. An alternate, faster differential expression analysis workflow can be pursued if there is no interest in novel isoforms (i.e. assembled transcripts present in the samples but missing from the reference annotation), or if only a well known set of transcripts of interest are targeted by the analysis. This simplified protocol has only 3 steps (depicted in the `StringTie manual here`_) as it bypasses the individual assembly of each RNA-Seq sample and the \"transcript merge\" step. This simplified workflow attempts to directly estimate and analyze the expression of a known set of transcripts as given in the reference annotation file. .. _StringTie: http://ccb.jhu.edu/software/stringtie/ .. _Ballgown: https://www.biorxiv.org/content/early/2014/09/05/003665 .. _Cuffdiff: http://cole-trapnell-lab.github.io/cufflinks/cuffdiff/ .. _DESeq2: https://bioconductor.org/packages/release/bioc/html/DESeq2.html .. _edgeR: https://bioconductor.org/packages/release/bioc/html/edgeR.html .. _limma: https://bioconductor.org/packages/release/bioc/html/limma.html .. _Bioconductor: https://www.bioconductor.org/ .. _SAM: http://samtools.github.io/hts-specs/SAMv1.pdf .. _HISAT2: http://ccb.jhu.edu/software/hisat2 .. _`GTF/GFF3`: http://ccb.jhu.edu/software/stringtie/gff.shtml .. _`this link`: https://github.com/alyssafrazee/ballgown#ballgown-readable-expression-output .. _`Ensembl site here`: http://useast.ensembl.org/info/website/upload/gff.html .. _here: http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/ .. _`by B. Li and C. Dewey here`: http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-323 .. _`GFF utilities page`: http://ccb.jhu.edu/software/stringtie/gff.shtml#gffcompare .. _`protocol paper`: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5032908/ .. _`StringTie manual here`: http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
    "input_formats": [
      "sam",
      "bam",
      "gtf",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "gtf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/deseq2/deseq2/2.11.40.7+galaxy1",
    "name": "DESeq2",
    "description": "Determines differentially expressed features from count tables",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.11.40.7+galaxy1",
    "help": ".. class:: infomark **What it does** Estimate variance-mean dependence in count data from high-throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution ----- **Inputs** **Count Files** DESeq2_ takes count tables generated from **featureCounts**, **HTSeq-count** or **StringTie** as input. Count tables must be generated for each sample individually. One header row is assumed, but files with no header (e.g from HTSeq) can be input with the *Files have header?* option set to No. DESeq2 is capable of handling multiple factors that affect your experiment. The first factor you input is considered as the primary factor that affects gene expressions. Optionally, you can input one or more secondary factors that might influence your experiment. But the final output will be changes in genes due to primary factor in presence of secondary factors. Each factor has two levels/states. You need to select appropriate count table from your history for each factor level. The following table gives some examples of factors and their levels: Factor Factor level 1 Factor level 2 --------- -------------- --------------- Treatment Treated Untreated --------- -------------- --------------- Condition Knockdown Wildtype --------- -------------- --------------- TimePoint Day4 Day1 --------- -------------- --------------- SeqType SingleEnd PairedEnd --------- -------------- --------------- Gender Female Male *Note*: Output log2 fold changes are based on primary factor level 1 vs. factor level2. Here the order of factor levels is important. For example, for the factor 'Treatment' given in above table, DESeq2 computes fold changes of 'Treated' samples against 'Untreated', i.e. the values correspond to up or down regulations of genes in Treated samples. DESeq2_ can also take transcript-level counts from quantification tools such as, **kallisto**, **Salmon** and **Sailfish**, and this Galaxy wrapper incorporates the Bioconductor tximport_ package to process the transcript counts for DESeq2. **Salmon or Sailfish Files** Salmon or Sailfish ``quant.sf`` files can be imported by setting type to *Salmon* or *Sailfish* respectively above. Note: for previous version of Salmon or Sailfish, in which the quant.sf files start with comment lines you will need to remove the comment lines before inputting here. An example of the format is shown below. Example: Name Length EffectiveLength TPM NumReads ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 2.47415 109.165 NR_015380 2129 2139.53 1.77331 85.5821 NM_001198818 9360 7796.58 2.38616e-07 4.19648e-05 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 0.0481114 8.37255 **kallisto Files** kallisto ``abundance.tsv`` files can be imported by setting type to *kallisto* above. An example of the format is shown below. Example: target_id length eff_length est_counts tpm ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 109.165 2.47415 NR_015380 2129 2139.53 85.5821 1.77331 NM_001198818 9360 7796.58 4.19648e-05 2.38616e-07 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 8.37255 0.0481114 ----- **Output** DESeq2_ generates a tabular file containing the different columns and optional visualized results as PDF. Column Description ------ ---------------------------------------------------------- 1 Gene Identifiers 2 mean normalised counts, averaged over all samples from both conditions 3 the logarithm (to basis 2) of the fold change (See the note in inputs section) 4 standard error estimate for the log2 fold change estimate 5 Wald statistic 6 p value for the statistical significance of this change 7 p value adjusted for multiple testing with the Benjamini-Hochberg procedure which controls false discovery rate (FDR) By selecting ``Output sample size factors`` in the \"Output options\" selection box, the size factors used to normalize the samples can also be output as a tabular file. .. _DESeq2: http://master.bioconductor.org/packages/release/bioc/html/DESeq2.html .. _tximport: https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html",
    "input_formats": [
      "tabular",
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "tabular",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/masigpro/masigpro/1.49.3.1+galaxy0",
    "name": "maSigPro",
    "description": "Significant Gene Expression Profile Differences in Time Course Gene Expression Data",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.49.3.1+galaxy0",
    "help": ".. class:: infomark **What it does** maSigPro_ is a regression based approach to find genes for which there are significant gene expression profile differences between experimental groups in time course microarray and RNA-Seq experiments. **Inputs** The maSigPro wrapper has two options for input data: - directly through two seperate text files containing the experiment design (edesign) and the data or - count tables generated from HTSeq-count. Count tables must be generated for each sample individually. To set up an experimental design from seperate count files you first have to select which files belong to a certain time point. Likewise you can specify which files are replicates. In a third step you have to create the experimental groups and select the related files. For a more comfortable setup in future analysis you have the option to output the generated edesign and data files. **Output** maSigPro_ generates a summary file containing the list of significant genes. Additionally you can obtain a PDF file containing plots of profiles and groups that visualize the clustering analysis. .. _maSigPro: https://bioconductor.org/packages/release/bioc/html/maSigPro.html",
    "input_formats": [
      "tabular",
      "txt"
    ],
    "output_formats": [
      "txt",
      "pdf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/seurat/seurat/4.0.5+galaxy0",
    "name": "Seurat",
    "description": "- toolkit for exploration of single-cell RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "4.0.5+galaxy0",
    "help": ".. class:: infomark **What it does** Seurat_ is a toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. It is developed and maintained by the `Satija Lab`_ at NYGC. Seurat aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See the `Seurat Guided Clustering tutorial`_ for more information. ----- **Inputs** * Gene count matrix in TAB-separated format ----- **Outputs** * HTML of plots Optionally you can choose to output * R commands used to generate plots printed alongside figures .. _Seurat: https://www.nature.com/articles/nbt.4096 .. _Satija Lab: https://satijalab.org/seurat/ .. _Seurat Guided Clustering tutorial: https://satijalab.org/seurat/pbmc3k_tutorial.html",
    "input_formats": [
      "tabular",
      "tsv"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/slamdunk/alleyoop/0.4.3+galaxy1",
    "name": "Alleyoop",
    "description": "- post-processing and QC of Slamdunk analyses",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.4.3+galaxy1",
    "help": "SLAMseq SLAMseq is a novel sequencing protocol that directly uncovers 4-thiouridine incorporation events in RNA by high-throughput sequencing. When combined with metabolic labeling protocols, SLAM-seq allows to study the intracellular RNA dynamics, from transcription, RNA processing to RNA stability. Original publication: `Herzog et al., Nature Methods, 2017; doi:10.1038/nmeth.4435 `_ Alleyoop Alleyoop (Additional sLamdunk heLpEr tools for anY diagnOstics Or Plots) is a collection of tools for post-processing and running diagnostics on Slamdunk analyses. This tool works on the output of the **Slamdunk** tool and requires all the inputs listed in the table below. Parameter Description **Genome** The reference fasta file (Genome assembly). **Reference** BED-file containing coordinates for 3' UTRs. **Reads** Slamdunk Filtered BAM files. **Counts** Slamdunk Count TSV files. **Variants** Slandunk VCF files. **Read length** Maximum length of reads (usually 50, 100, 150). This tool runs the **Alleyoop** *summary*, *rates*, *utrrates*, *tcperreadpos* and *tcperutrpos* modules and outputs: * Tab-separated *summary* files from the summary module with mapping and PCA statistics * Tab-separated *stats* files from the rates, utrrates, tcperreadpos and tcperutrpos modules Optionally, the *read-separator* module can be run to output BAM files of separated T>C and non T>C reads. The summary and stats files can be summarised and visualised with MultiQC. An example MultiQC report can be seen here_. For information on these modules see the `Alleyoop documentation`_. .. _`Alleyoop documentation`: http://t-neumann.github.io/slamdunk/docs.html#document-Alleyoop .. _here: http://t-neumann.github.io/slamdunk/multiqc_example/multiqc_report.html",
    "input_formats": [
      "fasta",
      "bed",
      "sam",
      "bam",
      "tabular",
      "vcf"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/slamdunk/slamdunk/0.4.3+galaxy1",
    "name": "Slamdunk",
    "description": "- streamlining SLAM-seq analysis with ultra-high sensitivity",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.4.3+galaxy1",
    "help": "SLAM-seq SLAM-seq is a novel sequencing protocol that directly uncovers 4-thiouridine incorporation events in RNA by high-throughput sequencing. When combined with metabolic labeling protocols, SLAM-seq allows to study the intracellular RNA dynamics, from transcription, RNA processing to RNA stability. Original publication: `Herzog et al., Nature Methods, 2017; doi:10.1038/nmeth.4435 `_ Slamdunk To analyze a given SLAM-seq dataset with *slamdunk* without recovering multimappers, you only need to provide the following files and keep everything else to the default parameters. Parameter Description **Genome** The reference fasta file (Genome assembly). **Reference** BED-file containing coordinates for 3' UTRs. **Reads** Sample FASTQ(gz) files. **Read length** Maximum length of reads (usually 50, 100, 150). This will run the entire *slamdunk* analysis (`slamdunk all`) with the most relevant output files being: * Tab-separated *tcount* file (Count TSV) containing the SLAM-seq statistics per UTR * BAM-file with the final filtered mapped reads * VCF file of variants called on the final filtered alignments These files can be input to the **Alleyoop** tool for visualization and further processing. See the `Slamdunk documentation`_ for more information. ------------------------------------------------------ Multimapper recovery -------------------- To utilize multimapper recovery, modify the following parameters. You must either choose a separate 3' UTR file or activate filtering on the supplied reference file. Will only yield different results than a unique-mapping run by specifying a number > 1 as maximum number of multimapper aligments to consider. Parameter Description **Maximum number of alignments to report per read** The maximum number of multimapper alignments to consider. **Use separate 3' UTR bed to filter multimappers.** 3' UTR bed file to filter. **Use reference bed file to resolve multimappers.** Use reference as 3' UTR bed file to filter. ------------------------------------------------------ T>C conversions --------------- Depending on the use case, more stringent or more lenient measures of T>C conversion and T>C reads are required such as 2 T>C by `Muhar et al., Science, 2018; http://doi.org/10.1126/science.aao2793 `_ This can be controlled by the following parameter: Parameter Description **T>C conversion threshold** Minimum number of T>C conversions to consider a read as T>C read. .. _`Slamdunk documentation`: http://t-neumann.github.io/slamdunk/docs.html",
    "input_formats": [
      "fasta",
      "bed",
      "fastqsanger",
      "fastqsanger.gz",
      "vcf"
    ],
    "output_formats": [
      "bam",
      "tabular",
      "vcf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/transdecoder/transdecoder/5.5.0+galaxy2",
    "name": "TransDecoder",
    "description": "finds coding regions within transcripts",
    "categories": [
      "RNA-seq"
    ],
    "version": "5.5.0+galaxy2",
    "help": ".. class:: infomark **What it does** TransDecoder identifies candidate coding regions within transcript sequences such as those generated by de novo RNA-Seq transcript assembly using Trinity or constructed based on RNA-Seq alignments to the genome using Tophat and Cufflinks. TransDecoder identifies likely coding sequences based on the following criteria: - a minimum length open reading frame (ORF) is found in a transcript sequence. - a log-likelihood score similar to what is computed by the GeneID software is > 0. - the above coding score is greatest when the ORF is scored in the 1st reading frame as compared to scores in the other 5 reading frames. - if a candidate ORF is found fully encapsulated by the coordinates of another candidate ORF, the longer one is reported. However, a single transcript can report multiple ORFs (allowing for operons, chimeras, etc). - a PSSM is built/trained/used to refine the start codon prediction. - optional the putative peptide has a match to a Pfam domain above the noise cutoff score. *Step 1*: Extract long open reading frames By default, TransDecoder.LongOrfs will identify ORFs that are at least 100 amino acids long. You can lower this via the '-m' parameter, but know that the rate of false positive ORF predictions increases drastically with shorter minimum length criteria. *Step 2*: (optional and not part of this wrapper) The result \"longest ORFs (PEP)\" can be used to identify ORFs with homology to known proteins via BlastP or Pfam searches (`details `_). *Step 3*: Predict the likely coding regions Optionally apply results of homology searches in this step and re-run the whole analysis. **Input** - FASTA file with transcripts - (optional) gene-to-transcript identifier mapping file - (optional) BLAST or Pfam database file (`details `_) **Output** *LongOrfs* - longest ORFs (PEP/FASTA): all ORFs meeting the minimum length criteria, regardless of coding potential - longest ORFs (GFF3): positions of all ORFs as found in the target transcripts - longest ORFs (CDS/FASTA): the nucleotide coding sequence for all detected ORFs *Predict* - Results (PEP/FASTA): peptide sequences for the final candidate ORFs; all shorter candidates within longer ORFs were removed - Results (CDS/FASTA): nucleotide sequences for coding regions of the final candidate ORFs - Results (GFF3): positions within the target transcripts of the final selected ORFs - Results (BED): BED-formatted file describing ORF positions, best for viewing using GenomeView or IGV - Plots: sequence logos and scores (compressed PDF) *Other* - Log file .. class:: infomark **References** More information are available on `GitHub `_.",
    "input_formats": [
      "fasta",
      "tabular",
      "txt"
    ],
    "output_formats": [
      "fasta",
      "gff3",
      "bed",
      "zip",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity/trinity/2.9.1+galaxy2",
    "name": "Trinity",
    "description": "de novo assembly of RNA-Seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.9.1+galaxy2",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. .. _Trinity: http://trinityrnaseq.github.io",
    "input_formats": [
      "fasta",
      "fastqsanger",
      "fastqsanger.gz",
      "bam"
    ],
    "output_formats": [
      "fasta",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/tximport/tximport/1.22.0",
    "name": "tximport",
    "description": "Summarize transcript-level estimates for gene-level analysis",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.22.0",
    "help": ".. class:: infomark Current version only works in 'merge' mode: A single table of gene summarizations is generated with one column for each sample file. Take into account that DEseq2 package in Galaxy requires one table per sample.",
    "input_formats": [
      "tabular",
      "gff"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/mirdeep2_mapper/rbc_mirdeep2_mapper/2.0.0.8.1",
    "name": "MiRDeep2 Mapper",
    "description": "process and map reads to a reference genome",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.0.8.1",
    "help": "**What it does** The MiRDeep2 Mapper module is designed as a tool to process deep sequencing reads and/or map them to the reference genome. The module works in sequence space, and can process or map data that is in sequence FASTA format. A number of the functions of the mapper module are implemented specifically with Solexa/Illumina data in mind. **Input** Default input is a file in FASTA format, seq.txt or qseq.txt format. More input can be given depending on the options used. **Output** The output depends on the options used. Either a FASTA file with processed reads or an arf file with with mapped reads, or both, are output. Arf format: Is a proprietary file format generated and processed by miRDeep2. It contains information of reads mapped to a reference genome. Each line in such a file contains 13 columns: 1. read identifier 2. length of read sequence 3. start position in read sequence that is mapped 4. end position in read sequence that is mapped 5. read sequence 6. identifier of the genome-part to which a read is mapped to. This is either a scaffold id or a chromosome name 7. length of the genome sequence a read is mapped to 8. start position in the genome where a read is mapped to 9. end position in the genome where a read is mapped to 10. genome sequence to which a read is mapped 11. genome strand information. Plus means the read is aligned to the sense-strand of the genome. Minus means it is aligned to the antisense-strand of the genome. 12. Number of mismatches in the read mapping 13. Edit string that indicates matches by lowercase 'm' and mismatches by uppercase 'M'",
    "input_formats": [
      "fastq",
      "fasta"
    ],
    "output_formats": [
      "fasta",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/mirdeep2_quantifier/rbc_mirdeep2_quantifier/2.0.0",
    "name": "MiRDeep2 Quantifier",
    "description": "fast quantitation of reads mapping to known miRBase precursors",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.0",
    "help": "**What it does** The module maps the deep sequencing reads to predefined miRNA precursors and determines by that the expression of the corresponding miRNAs. First, the predefined mature miRNA sequences are mapped to the predefined precursors. Optionally, predefined star sequences can be mapped to the precursors too. By that the mature and star sequence in the precursors are determined. Second, the deep sequencing reads are mapped to the precursors. The number of reads falling into an interval 2nt upstream and 5nt downstream of the mature/star sequence is determined. **Input** A FASTA file with precursor sequences, a FASTA file with mature miRNA sequences, a FASTA file with deep sequencing reads and optionally a FASTA file with star sequences and the 3 letter code of the species of interest. **Output** A tab separated file with miRNA identifiers and its read count, a signature file, a html file that gives an overview of all miRNAs the input data and a pdfs that contains for each miRNA a pdf file showing its signature and structure.",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "tabular",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/mirdeep2/rbc_mirdeep2/2.0.1.2+galaxy0",
    "name": "MiRDeep2",
    "description": "identification of novel and known miRNAs",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.1.2+galaxy0",
    "help": "**What it does** MiRDeep2 is a software package for identification of novel and known miRNAs in deep sequencing data. Furthermore, it can be used for miRNA expression profiling across samples. **Input** A FASTA file with deep sequencing reads, a FASTA file of the corresponding genome, a file of mapped reads to the genome in miRDeep2 arf format, an optional fasta file with known miRNAs of the analysing species and an option fasta file of known miRNAs of related species. Arf format: Is a proprietary file format generated and processed by miRDeep2. It contains information of reads mapped to a reference genome. Each line in such a file contains 13 columns: 1. read identifier 2. length of read sequence 3. start position in read sequence that is mapped 4. end position in read sequence that is mapped 5. read sequence 6. identifier of the genome-part to which a read is mapped to. This is either a scaffold id or a chromosome name 7. length of the genome sequence a read is mapped to 8. start position in the genome where a read is mapped to 9. end position in the genome where a read is mapped to 10. genome sequence to which a read is mapped 11. genome strand information. Plus means the read is aligned to the sense-strand of the genome. Minus means it is aligned to the antisense-strand of the genome. 12. Number of mismatches in the read mapping 13. Edit string that indicates matches by lowercase 'm' and mismatches by uppercase 'M'",
    "input_formats": [
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html",
      "bed",
      "txt",
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_gene_to_trans_map/trinity_gene_to_trans_map/2.9.1",
    "name": "Generate gene to transcript map",
    "description": "for Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.9.1",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool produces a file containing correspondance between gene ids and transcript ids based on the name of transcripts assembled by Trinity. The output file is intended to be used by the \"Align reads and estimate abundance\" tool. The same file is automatically generated when running Trinity, this tool is only intended to be used when you don't (or no longer) have access to the one produced by Trinity. .. _Trinity: http://trinityrnaseq.github.io",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/limma_voom/limma_voom/3.50.1+galaxy0",
    "name": "limma",
    "description": "Perform differential expression with limma-voom or limma-trend",
    "categories": [
      "RNA-seq"
    ],
    "version": "3.50.1+galaxy0",
    "help": ".. class:: infomark **What it does** Given a matrix of counts (e.g. from featureCounts) and optional information about the genes, this tool performs differential expression (DE) using the limma_ Bioconductor package and produces plots and tables useful in DE analysis. Interactive Glimma_ plots and tables can also be generated and links to the Glimma plots will be provided in the report. See an example workflow here_. In the `limma approach`_ to RNA-seq, read counts are converted to log2-counts-per-million (logCPM) and the mean-variance relationship is modelled either with precision weights or with an empirical Bayes prior trend. The precision weights approach is called voom and the prior trend approach is called limma-trend. For more information, see the Help section below. ----- **Inputs** **Differential Expression Method:** Option to use the limma-voom or limma-trend approach for differential expression. The default is limma-voom. If the sequencing depth is reasonably consistent across the RNA samples, then the simplest and most robust approach to differential expression is to use limma-trend. This approach will usually work well if the ratio of the largest library size to the smallest is not more than about 3-fold. When the library sizes are quite variable between samples, then the voom approach is theoretically more powerful than limma-trend. For more information see the excellent `limma User's Guide`_. **Counts Data:** The counts data can either be input as separate counts files (one sample per file) or a single count matrix (one sample per column). The rows correspond to genes, and columns correspond to the counts for the samples. Values must be tab separated, with the first row containing the sample/column labels and the first column containing the row/gene labels. The sample labels must start with a letter. Gene identifiers can be of any type but must be unique and not repeated within a counts file. Example - **Separate Count Files**: **GeneID** **WT1** ---------- ------- 11287 1699 11298 1905 11302 6 11303 2099 11304 356 11305 2528 Example - **Single Count Matrix**: **GeneID** **WT1** **WT2** **WT3** **Mut1** **Mut2** **Mut3** ---------- ------- ------- ------- -------- -------- -------- 11287 1699 1528 1601 1463 1441 1495 11298 1905 1744 1834 1345 1291 1346 11302 6 8 7 5 6 5 11303 2099 1974 2100 1574 1519 1654 11304 356 312 337 361 397 346 11305 2528 2438 2493 1762 1942 2027 **Gene Annotations:** Optional input for gene annotations, this can contain more information about the genes than just an ID number. The annotations will be available in the differential expression results table and the optional normalised counts table. They will also be used to generate interactive Glimma_ Volcano, MD plots and tables of differential expression. The input annotation file must contain a header row and have the gene IDs in the first column. The second column will be used to label the genes in the Volcano plot and interactive Glimma plots, additional columns will be available in the Glimma interactive table. The number of rows should match that of the counts files, add NA for any gene IDs with no annotation. The Galaxy tool **annotateMyIDs** can be used to obtain annotations for human, mouse, fly and zebrafish. Example: **GeneID** **Symbol** **GeneName** ---------- ---------- --------------------------------------------------- 11287 Pzp pregnancy zone protein 11298 Aanat arylalkylamine N-acetyltransferase 11302 Aatk apoptosis-associated tyrosine kinase 11303 Abca1 ATP-binding cassette, sub-family A (ABC1), member 1 11304 Abca4 ATP-binding cassette, sub-family A (ABC1), member 4 11305 Abca2 ATP-binding cassette, sub-family A (ABC1), member 2 **Factor Information:** Enter factor names and groups in the tool form, or provide a tab-separated file that has the names of the samples in the first column and one header row. The sample names must be the same as the names in the columns of the count matrix. The second column should contain the primary factor levels (e.g. WT, Mut) with optional additional columns for any secondary factors. Example: **Sample** **Genotype** **Batch** ---------- ------------ --------- WT1 WT b1 WT2 WT b2 WT3 WT b3 Mut1 Mut b1 Mut2 Mut b2 Mut3 Mut b3 *Factor Name:* The name of the experimental factor being investigated e.g. Genotype, Treatment. One factor must be entered and spaces must not be used. Optionally, additional factors can be included, these are variables that might influence your experiment e.g. Batch, Gender, Subject. If additional factors are entered, an additive linear model will be used. *Groups:* The names of the groups for the factor. The names should only contain letters, numbers and underscores, other characters such as spaces and hyphens MUST not be used. If entered into the tool form above, the order must be the same as the samples (to which the groups correspond) are listed in the columns of the counts matrix, with the values separated by commas. If the group names begin with a number an X will be added as a prefix. **Contrasts of Interest:** The contrasts you wish to make between levels. A common contrast would be a simple difference between two levels: \"Mut-WT\" represents the difference between the mutant and wild type genotypes. Multiple contrasts must be entered separately using the Insert Contrast button, spaces must not be used. Alternatively, a tab-separated file can be input that has the names of the comparisons in the first column and one header row, as shown below. Example: = **Contrasts** ------------- - Mut-WT WT-Mut = **Filter Low Counts:** Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discreteness of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. As a rule of thumb, genes are dropped if they cant possibly be expressed in all the samples for any of the conditions. Users can set their own definition of genes being expressed. Usually a gene is required to have a count of 5-10 in a library to be considered expressed in that library. Users should also filter with count-per-million (CPM) rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. Option to ignore the genes that do not show significant levels of expression, this filtering is dependent on two criteria: CPM/count and number of samples. You can specify to filter on CPM (Minimum CPM) or count (Minimum Count) values: * **Minimum CPM:** This is the minimum count per million that a gene must have in at least the number of samples specified under Minimum Samples. * **Minimum Count:** This is the minimum count that a gene must have. It can be combined with either Filter on Total Count or Minimum Samples. * **Filter on Total Count:** This can be used with the Minimum Count filter to keep genes with a minimum total read count. * **Minimum Samples:** This is the number of samples in which the Minimum CPM/Count requirement must be met in order for that gene to be kept. If the Minimum Samples filter is applied, only genes that exhibit a CPM/count greater than the required amount in at least the number of samples specified will be used for analysis. Care should be taken to ensure that the sample requirement is appropriate. In the case of an experiment with two experimental groups each with two members, if there is a change from insignificant CPM/count to significant CPM/count but the sample requirement is set to 3, then this will cause that gene to fail the criteria. When in doubt simply do not filter or consult the `limma User's Guide`_ for filtering recommendations. **Advanced Options:** By default error rate for multiple testing is controlled using Benjamini and Hochberg's false discovery rate control at a threshold value of 0.05. However there are options to change this to custom values. * **Minimum log2-fold-change Required:** In addition to meeting the requirement for the adjusted statistic for multiple testing, the observation must have an absolute log2-fold-change greater than this threshold to be considered significant, thus highlighted in the MD plot. * **Adjusted Threshold:** Set the threshold for the resulting value of the multiple testing control method. Only observations whose statistic falls below this value is considered significant, thus highlighted in the MD plot. * **P-Value Adjustment Method:** Change the multiple testing control method, the options are BH(1995) and BY(2001) which are both false discovery rate controls. There is also Holm(1979) which is a method for family-wise error rate control. **Testing relative to a threshold (TREAT):** If there are a lot of differentially expressed genes, a fold change threshold can be applied in addition to the P-value threshold to select genes that are more likely to be biologically significant. However, ranking by P-value and discarding genes with small logFCs can increase the false discovery rate. Using the limma TREAT function performs this analysis correctly (`McCarthy and Smyth, 2009`_). **Normalisation Method:** The most obvious technical factor that affects the read counts, other than gene expression levels, is the sequencing depth of each RNA sample. edgeR adjusts any differential expression analysis for varying sequencing depths as represented by differing library sizes. This is part of the basic modeling procedure and flows automatically into fold-change or p-value calculations. It is always present, and doesnt require any user intervention. The second most important technical influence on differential expression is one that is less obvious. RNA-seq provides a measure of the relative abundance of each gene in each RNA sample, but does not provide any measure of the total RNA output on a per-cell basis. This commonly becomes important when a small number of genes are very highly expressed in one sample, but not in another. The highly expressed genes can consume a substantial proportion of the total library size, causing the remaining genes to be under-sampled in that sample. Unless this RNA composition effect is adjusted for, the remaining genes may falsely appear to be down-regulated in that sample . The edgeR `calcNormFactors` function normalizes for RNA composition by finding a set of scaling factors for the library sizes that minimize the log-fold changes between the samples for most genes. The default method for computing these scale factors uses a trimmed mean of M values (TMM) between each pair of samples. We call the product of the original library size and the scaling factor the *effective library size*. The effective library size replaces the original library size in all downsteam analyses. TMM is the recommended method for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. You can change the normalisation method under **Advanced Options** above. For more information, see the `calcNormFactors` section in the `edgeR User's Guide`_. **Robust Settings** Option to use robust settings with eBayes or TREAT, used by both limma-voom and limma-trend. Using robust settings is usually recommended to protect against outlier genes, for more information see the `limma User's Guide`_ and `Phipson et al. 2016`_. This is turned on by default. **Prior Count:** If the limma-trend method is used, a count (`prior.count`) is added to all counts to avoid taking a log of zero, and damp down the variances of logarithms of low counts. A default of 3 is used, as recommended in the `limma User's Guide`_. **Apply Sample Weights:** If the limma-voom method is used, an option is available to downweight outlier samples, such that their information is still used in the statistical analysis but their impact is reduced. Use this whenever significant outliers are present. The MDS plotting tool in this package is useful for identifying outliers. For more information on this option see Liu et al. (2015). **Outputs** This tool outputs * a table of differentially expressed genes for each contrast of interest * a HTML report with plots and additional information Optionally, under **Output Options** you can choose to output * interactive Glimma plots and tables: MDS plot, and (if annotation file is input) Volcano plot and MD plot (default: Yes) * additional plots in the report and as PDFs * a normalised counts table * a library size information file * the R script used by this tool * an RData file ----- **Citations:** Please try to cite the appropriate articles when you publish results obtained using software, as such citation is the main means by which the authors receive credit for their work. limma Please cite the paper below for the limma software itself. Please also try to cite the appropriate methodology articles that describe the statistical methods implemented in limma, depending on which limma functions you are using. The methodology articles are listed in Section 2.1 of the `limma User's Guide`_. * Smyth GK (2005). Limma: linear models for microarray data. In: 'Bioinformatics and Computational Biology Solutions using R and Bioconductor'. R. Gentleman, V. Carey, S. Dudoit, R. Irizarry, W. Huber (eds), Springer, New York, pages 397-420. * Law CW, Chen Y, Shi W, and Smyth GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29. * Liu R, Holik AZ, Su S, Jansz N, Chen K, Leong HS, Blewitt ME, Asselin-Labat ML, Smyth GK, Ritchie ME (2015). Why weight? Modelling sample and observational level variability improves power in RNA-seq analyses. Nucleic Acids Research, 43(15), e97. * Ritchie, M. E., Diyagama, D., Neilson, J., van Laar, R., Dobrovic, A., Holloway, A., and Smyth, G. K. (2006). Empirical array quality weights for microarray data. BMC Bioinformatics 7, Article 261. edgeR Please cite the first paper for the software itself and the other papers for the various original statistical methods implemented in edgeR. See Section 1.2 in the `edgeR User's Guide`_ for more detail. * Robinson MD, McCarthy DJ and Smyth GK (2010). edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26, 139-140 * Robinson MD and Smyth GK (2007). Moderated statistical tests for assessing differences in tag abundance. Bioinformatics 23, 2881-2887 * Robinson MD and Smyth GK (2008). Small-sample estimation of negative binomial dispersion, with applications to SAGE data. Biostatistics, 9, 321-332 * McCarthy DJ, Chen Y and Smyth GK (2012). Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation. Nucleic Acids Research 40, 4288-4297 Please report problems or suggestions to: su.s@wehi.edu.au .. _limma: http://www.bioconductor.org/packages/release/bioc/html/limma.html .. _Glimma: https://bioconductor.org/packages/release/bioc/html/Glimma.html .. _here: https://f1000research.com/articles/5-1408/v3 .. _limma approach: https://www.ncbi.nlm.nih.gov/pubmed/25605792 .. _limma User's Guide: http://bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf .. _edgeR: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html .. _edgeR User's Guide: https://bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf .. _McCarthy and Smyth, 2009: https://www.ncbi.nlm.nih.gov/pubmed/19176553 .. _Phipson et al. 2016: https://www.ncbi.nlm.nih.gov/pubmed/28367255",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/edger/edger/3.36.0+galaxy0",
    "name": "edgeR",
    "description": "Perform differential expression of count data",
    "categories": [
      "RNA-seq"
    ],
    "version": "3.36.0+galaxy0",
    "help": ".. class:: infomark **What it does** Given a counts matrix, or a set of counts files, for example from **featureCounts**, and optional information about the genes, this tool produces plots and tables useful in the analysis of differential gene expression. This tool uses the `edgeR`_ quasi-likelihood pipeline (edgeR-quasi) for differential expression analysis. This statistical methodology uses negative binomial generalized linear models, but with F-tests instead of likelihood ratio tests. This method provides stricter error rate control than other negative binomial based pipelines, including the traditional edgeR pipelines or DESeq2. While the limma pipelines are recommended for large-scale datasets, because of their speed and flexibility, the edgeR-quasi pipeline gives better performance in low-count situations. For the data analyzed in this `edgeR workflow article`_ ,the edgeR-quasi, limma-voom and limma-trend pipelines are all equally suitable and give similar results. .. _edgeR: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html .. _edgeR workflow article: https://f1000research.com/articles/5-1438 ----- **Inputs** **Counts Data:** The counts data can either be input as separate counts files (one sample per file) or a single count matrix (one sample per column). The rows correspond to genes, and columns correspond to the counts for the samples. Values must be tab separated, with the first row containing the sample/column labels and the first column containing the row/gene labels. The sample labels must start with a letter. Gene identifiers can be of any type but must be unique and not repeated within a counts file. Example - **Separate Count Files**: **GeneID** **WT1** ---------- ------- 11287 1699 11298 1905 11302 6 11303 2099 11304 356 11305 2528 Example - **Single Count Matrix**: **GeneID** **WT1** **WT2** **WT3** **Mut1** **Mut2** **Mut3** ---------- ------- ------- ------- -------- -------- -------- 11287 1699 1528 1601 1463 1441 1495 11298 1905 1744 1834 1345 1291 1346 11302 6 8 7 5 6 5 11303 2099 1974 2100 1574 1519 1654 11304 356 312 337 361 397 346 11305 2528 2438 2493 1762 1942 2027 **Gene Annotations:** Optional input for gene annotations, this can contain more information about the genes than just an ID number. The annotations will be available in the differential expression results table and the optional normalised counts table. The file must contain a header row and have the gene IDs in the first column. The number of rows should match that of the counts files, add NA for any gene IDs with no annotation. The Galaxy tool **annotateMyIDs** can be used to obtain annotations for human, mouse, fly and zebrafish. Example: **GeneID** **Symbol** **GeneName** ---------- ---------- --------------------------------------------------- 11287 Pzp pregnancy zone protein 11298 Aanat arylalkylamine N-acetyltransferase 11302 Aatk apoptosis-associated tyrosine kinase 11303 Abca1 ATP-binding cassette, sub-family A (ABC1), member 1 11304 Abca4 ATP-binding cassette, sub-family A (ABC1), member 4 11305 Abca2 ATP-binding cassette, sub-family A (ABC1), member 2 **Factor Information:** Enter factor names and groups in the tool form, or provide a tab-separated file that has the names of the samples in the first column and one header row. The sample names must be the same as the names in the columns of the count matrix. The second column should contain the primary factor levels (e.g. WT, Mut) with optional additional columns for any secondary factors. Example: **Sample** **Genotype** **Batch** ---------- ------------ --------- WT1 WT b1 WT2 WT b2 WT3 WT b3 Mut1 Mut b1 Mut2 Mut b2 Mut3 Mut b3 *Factor Name:* The name of the experimental factor being investigated e.g. Genotype, Treatment. One factor must be entered, the name should start with a letter and spaces must not be used. Optionally, additional factors can be included, these are variables that might influence your experiment e.g. Batch, Gender, Subject. If additional factors are entered, an additive linear model will be used. *Groups:* The names of the groups for the factor. The names should start with a letter, and only contain letters, numbers and underscores, other characters such as spaces and hyphens must not be used. If entered into the tool form above, the order must be the same as the samples (to which the groups correspond) are listed in the columns of the counts matrix, with the values separated by commas. **Contrasts of Interest:** The contrasts you wish to make between levels. A common contrast would be a simple difference between two levels: \"Mut-WT\" represents the difference between the mutant and wild type genotypes. Multiple contrasts must be entered separately using the Insert Contrast button, spaces must not be used. **Filter Low Counts:** Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discreteness of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. As a rule of thumb, genes are dropped if they cant possibly be expressed in all the samples for any of the conditions. Users can set their own definition of genes being expressed. Usually a gene is required to have a count of 5-10 in a library to be considered expressed in that library. Users should also filter with count-per-million (CPM) rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. Option to ignore the genes that do not show significant levels of expression, this filtering is dependent on two criteria: CPM/count and number of samples. You can specify to filter on CPM (Minimum CPM) or count (Minimum Count) values: * **Minimum CPM:** This is the minimum count per million that a gene must have in at least the number of samples specified under Minimum Samples. * **Minimum Count:** This is the minimum count that a gene must have. It can be combined with either Filter on Total Count or Minimum Samples. * **Filter on Total Count:** This can be used with the Minimum Count filter to keep genes with a minimum total read count. * **Minimum Samples:** This is the number of samples in which the Minimum CPM/Count requirement must be met in order for that gene to be kept. If the Minimum Samples filter is applied, only genes that exhibit a CPM/count greater than the required amount in at least the number of samples specified will be used for analysis. Care should be taken to ensure that the sample requirement is appropriate. In the case of an experiment with two experimental groups each with two members, if there is a change from insignificant CPM/count to significant CPM/count but the sample requirement is set to 3, then this will cause that gene to fail the criteria. When in doubt simply do not filter or consult the `edgeR workflow article`_ for filtering recommendations. **Advanced Options:** By default error rate for multiple testing is controlled using Benjamini and Hochberg's false discovery rate control at a threshold value of 0.05. However there are options to change this to custom values. * **Minimum log2-fold-change Required:** In addition to meeting the requirement for the adjusted statistic for multiple testing, the observation must have an absolute log2-fold-change greater than this threshold to be considered significant, thus highlighted in the MD plot. * **Adjusted Threshold:** Set the threshold for the resulting value of the multiple testing control method. Only observations whose statistic falls below this value is considered significant, thus highlighted in the MD plot. * **P-Value Adjustment Method:** Change the multiple testing control method, the options are BH(1995) and BY(2001) which are both false discovery rate controls. There is also Holm(1979) which is a method for family-wise error rate control. **Normalisation Method:** The most obvious technical factor that affects the read counts, other than gene expression levels, is the sequencing depth of each RNA sample. edgeR adjusts any differential expression analysis for varying sequencing depths as represented by differing library sizes. This is part of the basic modeling procedure and flows automatically into fold-change or p-value calculations. It is always present, and doesnt require any user intervention. The second most important technical influence on differential expression is one that is less obvious. RNA-seq provides a measure of the relative abundance of each gene in each RNA sample, but does not provide any measure of the total RNA output on a per-cell basis. This commonly becomes important when a small number of genes are very highly expressed in one sample, but not in another. The highly expressed genes can consume a substantial proportion of the total library size, causing the remaining genes to be under-sampled in that sample. Unless this RNA composition effect is adjusted for, the remaining genes may falsely appear to be down-regulated in that sample . The edgeR `calcNormFactors` function normalizes for RNA composition by finding a set of scaling factors for the library sizes that minimize the log-fold changes between the samples for most genes. The default method for computing these scale factors uses a trimmed mean of M values (TMM) between each pair of samples. We call the product of the original library size and the scaling factor the *effective library size*. The effective library size replaces the original library size in all downsteam analyses. TMM is the recommended method for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. You can change the normalisation method under **Advanced Options** above. For more information, see the `calcNormFactors` section in the `edgeR User's Guide`_. **Robust Settings** Option to use robust settings. Using robust settings (robust=TRUE) with the edgeR estimateDisp and glmQLFit functions is usually recommended to protect against outlier genes. This is turned on by default. Note that it is only used with the quasi-likelihood F test method. For more information, see the `edgeR workflow article`_. **Test Method** Option to use the likelihood ratio test instead of the quasi-likelihood F test. For more information, see the `edgeR workflow article`_. .. _edgeR User's Guide: http://www.bioconductor.org/packages/release/bioc/html/edgeR.html ----- **Outputs** This tool outputs * a table of differentially expressed genes for each contrast of interest * a HTML report with plots and additional information Optionally, under **Output Options** you can choose to output * a normalised counts table * the R script used by this tool * an RData file ----- **Citations** Please try to cite the appropriate articles when you publish results obtained using software, as such citation is the main means by which the authors receive credit for their work. For the edgeR method itself, please cite Robinson et al., 2010, and for this tool (which was developed from the Galaxy limma-voom tool) please cite Liu et al., 2015.",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "html",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/hisat2/hisat2/2.2.1+galaxy1",
    "name": "HISAT2",
    "description": "A fast and sensitive alignment program",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.2.1+galaxy1",
    "help": "Introduction What is HISAT? -------------- `HISAT ` is a fast and sensitive spliced alignment program. As part of HISAT, we have developed a new indexing scheme based on the Burrows-Wheeler transform (`BWT ` ) and the `FM index ` , called hierarchical indexing, that employs two types of indexes: (1) one global FM index representing the whole genome, and (2) many separate local FM indexes for small regions collectively covering the genome. Our hierarchical index for the human genome (about 3 billion bp) includes ~48,000 local FM indexes, each representing a genomic region of ~64,000bp. As the basis for non-gapped alignment, the FM index is extremely fast with a low memory footprint, as demonstrated by `Bowtie ` . In addition, HISAT provides several alignment strategies specifically designed for mapping different types of RNA-seq reads. All these together, HISAT enables extremely fast and sensitive alignment of reads, in particular those spanning two exons or more. As a result, HISAT is much faster >50 times than `TopHat2 ` with better alignment quality. Although it uses a large number of indexes, the memory requirement of HISAT is still modest, approximately 4.3 GB for human. HISAT uses the `Bowtie2 ` implementation to handle most of the operations on the FM index. In addition to spliced alignment, HISAT handles reads involving indels and supports a paired-end alignment mode. Multiple processors can be used simultaneously to achieve greater alignment speed. HISAT outputs alignments in `SAM ` format, enabling interoperation with a large number of other tools that use SAM. HISAT is distributed under the `GPLv3 license ` , and it runs on the command line under Linux, Mac OS X and Windows. Running HISAT Reporting --------- The reporting mode governs how many alignments HISAT looks for, and how to report them. In general, when we say that a read has an alignment, we mean that it has a `valid alignment ` . When we say that a read has multiple alignments, we mean that it has multiple alignments that are valid and distinct from one another. Distinct alignments map a read to different places ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Two alignments for the same individual read are \"distinct\" if they map the same read to different places. Specifically, we say that two alignments are distinct if there are no alignment positions where a particular read offset is aligned opposite a particular reference offset in both alignments with the same orientation. E.g. if the first alignment is in the forward orientation and aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, and the second alignment is also in the forward orientation and also aligns the read character at read offset 10 to the reference character at chromosome 3, offset 3,445,245, they are not distinct alignments. Two alignments for the same pair are distinct if either the mate 1s in the two paired-end alignments are distinct or the mate 2s in the two alignments are distinct or both. Default mode: search for one or more alignments, report each ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ HISAT searches for up to N distinct, primary alignments for each read, where N equals the integer specified with the ``-k`` parameter. Primary alignments mean alignments whose alignment score is equal or higher than any other alignments. It is possible that multiple distinct alignments whave the same score. That is, if ``-k 2`` is specified, HISAT will search for at most 2 distinct alignments. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM 'secondary' bit (which equals 256) set in its FLAGS field. See the `SAM specification ` for details. HISAT does not \"find\" alignments in any specific order, so for reads that have more than N distinct, valid alignments, HISAT does not gaurantee that the N alignments reported are the best possible in terms of alignment score. Still, this mode can be effective and fast in situations where the user cares more about whether a read aligns (or aligns a certain number of times) than where exactly it originated. Alignment summmary ------------------ When HISAT finishes running, it prints messages summarizing what happened. These messages are printed to the \"standard error\" (\"stderr\") filehandle and can be optionally printed to a file. Choose `--new-summary` under **Summary Options** for compatibility with `MultiQC `_. For datasets consisting of unpaired reads, the summary might look like this: :: 20000 reads; of these: 20000 (100.00%) were unpaired; of these: 1247 (6.24%) aligned 0 times 18739 (93.69%) aligned exactly 1 time 14 (0.07%) aligned >1 times 93.77% overall alignment rate For datasets consisting of pairs, the summary might look like this: :: 10000 reads; of these: 10000 (100.00%) were paired; of these: 650 (6.50%) aligned concordantly 0 times 8823 (88.23%) aligned concordantly exactly 1 time 527 (5.27%) aligned concordantly >1 times ---- 650 pairs aligned concordantly 0 times; of these: 34 (5.23%) aligned discordantly 1 time ---- 616 pairs aligned 0 times concordantly or discordantly; of these: 1232 mates make up the pairs; of these: 660 (53.57%) aligned 0 times 571 (46.35%) aligned exactly 1 time 1 (0.08%) aligned >1 times 96.70% overall alignment rate The indentation indicates how subtotals relate to totals. .. class:: infomark **HISAT2 options** Galaxy wrapper for HISAT2 implements most, but not all, options available through the command line. Supported options are described below. ----- **Inputs** HISAT2 accepts files in FASTQ or FASTA format (single-end or paired-end). Note that if your reads are from a stranded library, you need to choose the appropriate setting under **Specify strand information** above. For single-end reads, use F or R. 'F' means a read corresponds to a transcript. 'R' means a read corresponds to the reverse complemented counterpart of a transcript. For paired-end reads, use either FR or RF. With this option being used, every read alignment will have an XS attribute tag: '+' means a read belongs to a transcript on '+' strand of genome. '-' means a read belongs to a transcript on '-' strand of genome. (TopHat has a similar option, --library-type option, where fr-firststrand corresponds to R and RF; fr-secondstrand corresponds to F and FR.) ------ **Input options**:: -s/--skip Skip (i.e. do not align) the first ` ` reads or pairs in the input. -u/--qupto Align the first ` ` reads or read pairs from the input (after the `-s`/`--skip` reads or pairs have been skipped), then stop. Default: no limit. -5/--trim5 Trim ` ` bases from 5' (left) end of each read before alignment (default: 0). -3/--trim3 Trim ` ` bases from 3' (right) end of each read before alignment (default: 0). --phred33 Input qualities are ASCII chars equal to the Phred quality plus 33. This is also called the \"Phred+33\" encoding, which is used by the very latest Illumina pipelines. --phred64 Input qualities are ASCII chars equal to the Phred quality plus 64. This is also called the \"Phred+64\" encoding. --solexa-quals Convert input qualities from Solexa Phred quality (which can be negative) to Phred Phred quality (which can't). This scheme was used in older Illumina GA Pipeline versions (prior to 1.3). Default: off. --int-quals Quality values are represented in the read input file as space-separated ASCII integers, e.g., `40 40 30 40`..., rather than ASCII characters, e.g., `II?I`.... Integers are treated as being on the Phred quality scale unless `--solexa-quals` is also specified. Default: off. ------ **Alignment options**:: --n-ceil Sets a function governing the maximum number of ambiguous characters (usually `N`s and/or `.`s) allowed in a read as a function of read length. For instance, specifying `-L,0,0.15` sets the N-ceiling function `f` to `f(x) = 0 + 0.15 * x`, where x is the read length. Reads exceeding this ceiling are filtered out. Default: `L,0,0.15`. --ignore-quals When calculating a mismatch penalty, always consider the quality value at the mismatched position to be the highest possible, regardless of the actual value. I.e. input is treated as though all quality values are high. This is also the default behavior when the input doesn't specify quality values (e.g. in `-f`, `-r`, or `-c` modes). --nofw/--norc If `--nofw` is specified, `hisat2` will not attempt to align unpaired reads to the forward (Watson) reference strand. If `--norc` is specified, `hisat2` will not attempt to align unpaired reads against the reverse-complement (Crick) reference strand. In paired-end mode, `--nofw` and `--norc` pertain to the fragments; i.e. specifying `--nofw` causes `hisat2` to explore only those paired-end configurations corresponding to fragments from the reverse-complement (Crick) strand. Default: both strands enabled. ----- **Scoring options**:: --mp MX,MN Sets the maximum (`MX`) and minimum (`MN`) mismatch penalties, both integers. A number less than or equal to `MX` and greater than or equal to `MN` is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an `N`. If `--ignore-quals` is specified, the number subtracted quals `MX`. Otherwise, the number subtracted is `MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )` where Q is the Phred quality value. Default: `MX` = 6, `MN` = 2. --sp MX,MN Sets the maximum (`MX`) and minimum (`MN`) penalties for soft-clipping per base, both integers. A number less than or equal to `MX` and greater than or equal to `MN` is subtracted from the alignment score for each position. The number subtracted is `MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) )` where Q is the Phred quality value. Default: `MX` = 2, `MN` = 1. --no-softclip Disallow soft-clipping. --np Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as `N`. Default: 1. --rdg , Sets the read gap open (` `) and extend (` `) penalties. A read gap of length N gets a penalty of ` ` + N * ` `. Default: 5, 3. --rfg , Sets the reference gap open (` `) and extend (` `) penalties. A reference gap of length N gets a penalty of ` ` + N * ` `. Default: 5, 3. --score-min Sets a function governing the minimum alignment score needed for an alignment to be considered \"valid\" (i.e. good enough to report). This is a function of read length. For instance, specifying `L,0,-0.6` sets the minimum-score function `f` to `f(x) = 0 + -0.6 * x`, where `x` is the read length. The default is `L,0,-0.2`. ----- **Spliced alignment options**:: --pen-cansplice Sets the penalty for each pair of canonical splice sites (e.g. GT/AG). Default: 0. --pen-noncansplice Sets the penalty for each pair of non-canonical splice sites (e.g. non-GT/AG). Default: 12. --pen-canintronlen Sets the penalty for long introns with canonical splice sites so that alignments with shorter introns are preferred to those with longer ones. Default: G,-8,1 --pen-noncanintronlen Sets the penalty for long introns with noncanonical splice sites so that alignments with shorter introns are preferred to those with longer ones. Default: G,-8,1 --min-intronlen Sets minimum intron length. Default: 20 --max-intronlen Sets maximum intron length. Default: 500000 --no-spliced-alignment Disable spliced alignment. -I/--minins The minimum fragment length for valid paired-end alignments.This option is valid only with `--no-spliced-alignment`. E.g. if `-I 60` is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 20-bp gap between them, that alignment is considered valid (as long as `-X` is also satisfied). A 19-bp gap would not be valid in that case. If trimming options `-3` or `-5` are also used, the `-I` constraint is applied with respect to the untrimmed mates. The larger the difference between `-I` and `-X`, the slower HISAT2 will run. This is because larger differences between `-I` and `-X` require that HISAT2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient. Default: 0 (essentially imposing no minimum) -X/--maxins The maximum fragment length for valid paired-end alignments. This option is valid only with `--no-spliced-alignment`. E.g. if `-X 100` is specified and a paired-end alignment consists of two 20-bp alignments in the proper orientation with a 60-bp gap between them, that alignment is considered valid (as long as `-I` is also satisfied). A 61-bp gap would not be valid in that case. If trimming options `-3` or `-5` are also used, the -X constraint is applied with respect to the untrimmed mates, not the trimmed mates. The larger the difference between `-I` and `-X`, the slower HISAT2 will run. This is because larger differences between `-I` and `-X` require that HISAT2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient. Default: 500. --known-splicesite-infile With this mode, you can provide a list of known splice sites, which HISAT2 makes use of to align reads with small anchors. You can create such a list using python hisat2_extract_splice_sites.py genes.gtf > splicesites.txt, where hisat2_extract_splice_sites.py is included in the HISAT2 package, genes.gtf is a gene annotation file, and splicesites.txt is a list of splice sites with which you provide HISAT2 in this mode. Note that it is better to use indexes built using annotated transcripts (such as genome_tran or genome_snp_tran), which works better than using this option. It has no effect to provide splice sites that are already included in the indexes. --tmo/--transcriptome-mapping-only Report only those alignments within known transcripts. --dta/--downstream-transcriptome-assembly Report alignments tailored for transcript assemblers including StringTie. With this option, HISAT2 requires longer anchor lengths for de novo discovery of splice sites. This leads to fewer alignments with short-anchors, which helps transcript assemblers improve significantly in computation and memory usage. --dta-cufflinks Report alignments tailored specifically for Cufflinks. In addition to what HISAT2 does with the above option (--dta), With this option, HISAT2 looks for novel splice sites with three signals (GT/AG, GC/AG, AT/AC), but all user-provided splice sites are used irrespective of their signals. HISAT2 produces an optional field, XS:A:[+-], for every spliced alignment. --no-templatelen-adjustment Disables template length adjustment for RNA-seq reads. --novel-splicesite-outfile In this mode, HISAT2 reports a list of splice sites in the file : chromosome name genomic position of the flanking base on the left side of an intron genomic position of the flanking base on the right strand (+, -, and .) '.' indicates an unknown strand for non-canonical splice sites. ----- **Reporting options**:: -k It searches for at most ` ` distinct, primary alignments for each read. Primary alignments mean alignments whose alignment score is equal or higher than any other alignments. The search terminates when it can't find more distinct valid alignments, or when it finds ` `, whichever happens first. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM 'secondary' bit (which equals 256) set in its FLAGS field. For reads that have more than ` ` distinct, valid alignments, hisat2 does not guarantee that the ` ` alignments reported are the best possible in terms of alignment score. Default: 5 (HFM) or 10 (HGFM) Note: HISAT2 is not designed with large values for `-k` in mind, and when aligning reads to long, repetitive genomes large `-k` can be very, very slow. ----- **Paired-end options**:: --fr/--rf/--ff The upstream/downstream mate orientations for a valid paired-end alignment against the forward reference strand. E.g., if `--fr` is specified and there is a candidate paired-end alignment where mate 1 appears upstream of the reverse complement of mate 2 and the fragment length constraints (`-I` and `-X`) are met, that alignment is valid. Also, if mate 2 appears upstream of the reverse complement of mate 1 and all other constraints are met, that too is valid. `--rf` likewise requires that an upstream mate1 be reverse-complemented and a downstream mate2 be forward-oriented. ` --ff` requires both an upstream mate 1 and a downstream mate 2 to be forward-oriented. Default: `--fr` (appropriate for Illumina's Paired-end Sequencing Assay). --no-mixed By default, when `hisat2` cannot find a concordant or discordant alignment for a pair, it then tries to find alignments for the individual mates. This option disables that behavior. --no-discordant By default, `hisat2` looks for discordant alignments if it cannot find any concordant alignments. A discordant alignment is an alignment where both mates align uniquely, but that does not satisfy the paired-end constraints (`--fr`/`--rf`/`--ff`, `-I`, `-X`). This option disables that behavior. ----- ** SAM options --no-unal Suppress SAM records for reads that failed to align. --rg-id Set the read group ID to . This causes the SAM @RG header line to be printed, with as the value associated with the ID: tag. It also causes the RG:Z: extra field to be attached to each SAM output record, with value set to . --rg Add (usually of the form TAG:VAL, e.g. SM:Pool1) as a field on the @RG header line. Note: in order for the @RG line to appear, --rg-id must also be specified. This is because the ID tag is required by the SAM Spec. Specify --rg multiple times to set multiple fields. See the SAM Spec for details about what fields are legal. --remove-chrname Remove chr from reference names in alignment (e.g., chr18 to 18) --add-chrname Add chr to reference names in alignment (e.g., 18 to chr18) --omit-sec-seq When printing secondary alignments, HISAT2 by default will write out the SEQ and QUAL strings. Specifying this option causes HISAT2 to print an asterisk in those fields instead. ----- **Output options**:: --un/--un-gz/--un-bz2 Write unpaired reads that fail to align to file at ` `. These reads correspond to the SAM records with the FLAGS `0x4` bit set and neither the `0x40` nor `0x80` bits set. If `--un-gz` is specified, output will be gzip compressed. If `--un-bz2` is specified, output will be bzip2 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input. --al/--al-gz/--al-bz2 Write unpaired reads that align at least once to file at ` `. These reads correspond to the SAM records with the FLAGS `0x4`, `0x40`, and `0x80` bits unset. If `--al-gz` is specified, output will be gzip compressed. If `--al-bz2` is specified, output will be bzip2 compressed. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input. --un-conc/--un-conc-gz/--un-conc-bz2 Write paired-end reads that fail to align concordantly to file(s) at ` `. These reads correspond to the SAM records with the FLAGS `0x4` bit set and either the `0x40` or `0x80` bit set (depending on whether it's mate #1 or #2). .1 and .2 strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, %, is used in , the percent symbol is replaced with 1 or 2 to make the per-mate filenames. Otherwise, .1 or .2 are added before the final dot in to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs. --al-conc/--al-conc-gz/--al-conc-bz2 Write paired-end reads that align concordantly at least once to file(s) at ` `. These reads correspond to the SAM records with the FLAGS `0x4` bit unset and either the `0x40` or `0x80` bit set (depending on whether it's mate #1 or #2). .1 and .2 strings are added to the filename to distinguish which file contains mate #1 and mate #2. If a percent symbol, %, is used in , the percent symbol is replaced with 1 or 2 to make the per-mate filenames. Otherwise, .1 or .2 are added before the final dot in ` ` to make the per-mate filenames. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs. **Other options**:: --seed Use ` ` as the seed for pseudo-random number generator. Default: 0. --non-deterministic Normally, HISAT2 re-initializes its pseudo-random generator for each read. It seeds the generator with a number derived from (a) the read name, (b) the nucleotide sequence, (c) the quality sequence, (d) the value of the `--seed` option. This means that if two reads are identical (same name, same nucleotides, same qualities) HISAT2 will find and report the same alignment(s) for both, even if there was ambiguity. When `--non-deterministic` is specified, HISAT2 re-initializes its pseudo-random generator for each read using the current time. This means that HISAT2 will not necessarily report the same alignment for two identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads.",
    "input_formats": [
      "fasta",
      "fastqsanger",
      "fastqsanger.gz",
      "fastqsanger.bz2",
      "gtf"
    ],
    "output_formats": [
      "bam",
      "fastqsanger",
      "txt",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/dexseq/1.28.1+galaxy2",
    "name": "DEXSeq",
    "description": "Determines differential exon usage from count tables",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.28.1+galaxy2",
    "help": ".. class:: infomark **What it does** Inference of differential exon usage in RNA-Seq. **Inputs** DEXSeq_ takes count tables generated from the dexseq_count as input. Count tables must be generated for each sample individually. DEXSeq_ is capable of handling multiple factors that affect your experiment. The first factor you input is considered to be the primary factor that affects gene expressions. You can also input several secondary factors that might influence your experiment but the final output will be changes in genes due to primary factor in the presence of secondary factors. Each factor has two levels/states. You need to select an appropriate count table from your history for each factor level. The following table gives some examples of factors and their levels: Factor Factor level 1 Factor level 2 --------- -------------- --------------- condition Knockdown Wildtype --------- -------------- --------------- treatment Treated Untreated --------- -------------- --------------- timePoint Day4 Day1 --------- -------------- --------------- SeqType SingleEnd PairedEnd --------- -------------- --------------- Gender Female Male *Note*: Output log2 fold changes are based on primary factor level 1 vs. factor level 2. Here the order of factor levels is important. For example, for the factor 'condition' given in the above table, DEXSeq computes fold changes of 'Knockdown' samples against 'Wildtype', i.e. the values correspond to up or down regulations of genes in Knockdown samples. **Output** DEXSeq_ generates a tabular file containing the different columns and an optional html report. It can also ouput the DEXSeqResults R object that can be used with the plotDEXSeq tool to visualise individual genes. Column Description ------ ---------------------------------------------------------- 1 Gene and exon Identifiers 2 group/gene identifier 3 feature/exon identifier 4 mean of the counts across samples in each feature/exon 5 exon dispersion estimate 6 LRT statistic 7 LRT p-value 8 BH adjusted p-values 9 exon usage coefficient factorLevel 2 10 exon usage coefficient factorLevel 1 11 relative exon usage fold changes 12 GRanges object of the coordinates of the exon/feature 13 matrix of integer counts, of each column containing a sample 14 list of transcripts overlapping with the exon .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "gtf",
      "gff",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html",
      "rds"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/dexseq_count/1.28.1.1",
    "name": "DEXSeq-Count",
    "description": "Prepare and count exon abundancies from RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.28.1.1",
    "help": ".. class:: infomark **What it does** The main goal of this tool is to count the number of reads/fragments per exon of each gene in RNA-seq samples. In addition, it also prepares your annotation GTF file, making it compatible for counting. **Inputs** Mode-preprare: Takes a normal GTF file as input. For example from Ensembl database. Mode-count: Inputs are flattened GTF file and BAM file. The flattened GTF file can be generated from 'prepare' mode of this tool. **Output** Mode-prepare: Flattened GTF file that contains only exons with corresponding gene ids from the input GTF file. Sometimes two or more genes sharing an exon will be merged into an 'aggregate gene' if the aggregate option was used. Mode-count: Two column tab-delimited file with exon ids and their read counts. .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "gff",
      "bam"
    ],
    "output_formats": [
      "tabular",
      "gtf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/plotdexseq/1.28.1.1",
    "name": "plotDEXSeq",
    "description": "Visualization of the per gene DEXSeq results",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.28.1.1",
    "help": ".. class:: infomark **What it does** This tool enables visualization of DEXSeq results for individual genes. The input is a DEXSeqResults rds file, which can be output from the DEXSeq tool, and a single gene ID or list of IDs to plot. .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "rdata",
      "tabular"
    ],
    "output_formats": [
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/deseq2/deseq2/2.11.40.7+galaxy2",
    "name": "DESeq2",
    "description": "Determines differentially expressed features from count tables",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.11.40.7+galaxy2",
    "help": ".. class:: infomark **What it does** Estimate variance-mean dependence in count data from high-throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution ----- **Inputs** **Count Files** DESeq2_ takes count tables generated from **featureCounts**, **HTSeq-count** or **StringTie** as input. Count tables must be generated for each sample individually. One header row is assumed, but files with no header (e.g from HTSeq) can be input with the *Files have header?* option set to No. DESeq2 is capable of handling multiple factors that affect your experiment. The first factor you input is considered as the primary factor that affects gene expressions. Optionally, you can input one or more secondary factors that might influence your experiment. But the final output will be changes in genes due to primary factor in presence of secondary factors. Each factor has two levels/states. You need to select appropriate count table from your history for each factor level. The following table gives some examples of factors and their levels: Factor Factor level 1 Factor level 2 --------- -------------- --------------- Treatment Treated Untreated --------- -------------- --------------- Condition Knockdown Wildtype --------- -------------- --------------- TimePoint Day4 Day1 --------- -------------- --------------- SeqType SingleEnd PairedEnd --------- -------------- --------------- Gender Female Male *Note*: Output log2 fold changes are based on primary factor level 1 vs. factor level2. Here the order of factor levels is important. For example, for the factor 'Treatment' given in above table, DESeq2 computes fold changes of 'Treated' samples against 'Untreated', i.e. the values correspond to up or down regulations of genes in Treated samples. DESeq2_ can also take transcript-level counts from quantification tools such as, **kallisto**, **Salmon** and **Sailfish**, and this Galaxy wrapper incorporates the Bioconductor tximport_ package to process the transcript counts for DESeq2. **Salmon or Sailfish Files** Salmon or Sailfish ``quant.sf`` files can be imported by setting type to *Salmon* or *Sailfish* respectively above. Note: for previous version of Salmon or Sailfish, in which the quant.sf files start with comment lines you will need to remove the comment lines before inputting here. An example of the format is shown below. Example: Name Length EffectiveLength TPM NumReads ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 2.47415 109.165 NR_015380 2129 2139.53 1.77331 85.5821 NM_001198818 9360 7796.58 2.38616e-07 4.19648e-05 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 0.0481114 8.37255 **kallisto Files** kallisto ``abundance.tsv`` files can be imported by setting type to *kallisto* above. An example of the format is shown below. Example: target_id length eff_length est_counts tpm ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 109.165 2.47415 NR_015380 2129 2139.53 85.5821 1.77331 NM_001198818 9360 7796.58 4.19648e-05 2.38616e-07 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 8.37255 0.0481114 ----- **Output** DESeq2_ generates a tabular file containing the different columns and optional visualized results as PDF. Column Description ------ ---------------------------------------------------------- 1 Gene Identifiers 2 mean normalised counts, averaged over all samples from both conditions 3 the logarithm (to basis 2) of the fold change (See the note in inputs section) 4 standard error estimate for the log2 fold change estimate 5 Wald statistic 6 p value for the statistical significance of this change 7 p value adjusted for multiple testing with the Benjamini-Hochberg procedure which controls false discovery rate (FDR) By selecting ``Output sample size factors`` in the \"Output options\" selection box, the size factors used to normalize the samples can also be output as a tabular file. .. _DESeq2: http://master.bioconductor.org/packages/release/bioc/html/DESeq2.html .. _tximport: https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html",
    "input_formats": [
      "tabular",
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "tabular",
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/seurat/seurat/4.1.1+galaxy0",
    "name": "Seurat",
    "description": "- toolkit for exploration of single-cell RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "4.1.1+galaxy0",
    "help": ".. class:: infomark **What it does** Seurat_ is a toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. It is developed and maintained by the `Satija Lab`_ at NYGC. Seurat aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See the `Seurat Guided Clustering tutorial`_ for more information. ----- **Inputs** * Gene count matrix in TAB-separated format ----- **Outputs** * HTML of plots Optionally you can choose to output * R commands used to generate plots printed alongside figures .. _Seurat: https://www.nature.com/articles/nbt.4096 .. _Satija Lab: https://satijalab.org/seurat/ .. _Seurat Guided Clustering tutorial: https://satijalab.org/seurat/pbmc3k_tutorial.html",
    "input_formats": [
      "tabular",
      "tsv"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/cemitool/cemitool/1.18.1+galaxy0",
    "name": "CEMiTool",
    "description": "gene co-expression network analyses",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.18.1+galaxy0",
    "help": ".. class:: infomark **Purpose** The CEMiTool R package provides users with an easy-to-use method to automatically implement gene co-expression network analyses, obtain key information about the discovered gene modules using additional downstream analyses and retrieve publication-ready results via a high-quality interactive report. .. class:: infomark **Purpose**",
    "input_formats": [
      "tabular",
      "txt"
    ],
    "output_formats": [
      "tabular",
      "txt",
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/lparsons/htseq_count/htseq_count/0.9.1+galaxy1",
    "name": "htseq-count",
    "description": "- Count aligned reads in a BAM file that overlap features in a GFF file",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.9.1+galaxy1",
    "help": "Overview -------- This tool takes an alignment file in SAM or BAM format and feature file in GFF format and calculates the number of reads mapping to each feature. It uses the *htseq-count* script that is part of the HTSeq python module. See http://www-huber.embl.de/users/anders/HTSeq/doc/count.html for details. A feature is an interval (i.e., a range of positions) on a chromosome or a union of such intervals. In the case of RNA-Seq, the features are typically genes, where each gene is considered here as the union of all its exons. One may also consider each exon as a feature, e.g., in order to check for alternative splicing. For comparative ChIP-Seq, the features might be binding regions from a pre-determined list. Overlap Modes ------------- Special care must be taken to decide how to deal with reads that align to or overlap with more than one feature. The ``htseq-count`` script allows to choose between three modes. See also the FAQ_, if the following explanation seems too technical. The three overlap resolution modes of `htseq-count` work as follows. For each position *i* in the read, a set *S(i)* is defined as the set of all features overlapping position *i*. Then, consider the set *S*, which is (with *i* running through all position within the read or a read pair) - the union of all the sets *S(i)* for mode ``union``. This mode is recommended for most use cases. - the intersection of all the sets *S(i)* for mode ``intersection-strict``. - the intersection of all non-empty sets *S(i)* for mode ``intersection-nonempty``. If *S* contains precisely one feature, the read (or read pair) is counted for this feature. If *S* is empty, the read (or read pair) is counted as ``no_feature``. If *S* contains more than one feature, ``htseq-count`` behaves differently based on the ``--nonunique`` option: - ``--nonunique none`` (default): the read (or read pair) is counted as ``ambiguous`` and not counted for any features. Also, if the read (or read pair) aligns to more than one location in the reference, it is scored as ``alignment_not_unique``. - ``--nonunique all``: the read (or read pair) is counted as ``ambiguous`` and is also counted in all features to which it was assigned. Also, if the read (or read pair) aligns to more than one location in the reference, it is scored as ``alignment_not_unique`` and also separately for each location. Notice that when using ``--nonunique all`` the sum of all counts will not be equal to the number of reads (or read pairs), because those with multiple alignments or overlaps get scored multiple times. The following figure illustrates the effect of these three modes and the ``--nonunique`` option: .. image:: count_modes.png Strandedness ------------ **Important: The default for strandedness is yes. Be sure to choose the correct value.** To check which value is correct, select forward and reverse independently. If the overall counts drop at one condition then the opposite condition is correct, otherwise your data is not stranded. Output ------ The script outputs a table with counts for each feature, followed by the special counters, which count reads that were not counted for any feature for various reasons, namely - *no_feature*: reads which could not be assigned to any feature (set S as described above was empty). - *ambiguous*: reads which could have been assigned to more than one feature and hence were not counted for any of these (set S had mroe than one element). - *too_low_aQual*: reads which were not counted due to the -a option, see below - *not_aligned*: reads in the SAM file without alignment - *alignment_not_unique*: reads with more than one reported alignment. These reads are recognized from the NH optional SAM field tag. (If the aligner does not set this field, multiply aligned reads will be counted multiple times.) Options Summary --------------- Usage: htseq-count [options] sam_file gff_file This script takes an alignment file in SAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it. See https://htseq.readthedocs.io/en/release_0.9.1/count.html for details. Options: -f , --format= Format of the input data. Possible values are sam (for text SAM files) and bam (for binary BAM files). Default is sam. -r , --order= For paired-end data, the alignment have to be sorted either by read name or by alignment position. If your data is not sorted, use the samtools sort function of samtools to sort it. Use this option, with name or pos for to indicate how the input data has been sorted. The default is name. If name is indicated, htseq-count expects all the alignments for the reads of a given read pair to appear in adjacent records in the input data. For pos, this is not expected; rather, read alignments whose mate alignment have not yet been seen are kept in a buffer in memory until the mate is found. While, strictly speaking, the latter will also work with unsorted data, sorting ensures that most alignment mates appear close to each other in the data and hence the buffer is much less likely to overflow. --max-reads-in-buffer= When is paired end sorted by position, allow only so many reads to stay in memory until the mates are found (raising this number will use more memory). Has no effect for single end or paired end sorted by name. (default: 30000000) -s , --stranded= whether the data is from a strand-specific assay (default: yes) For stranded=no, a read is considered overlapping with a feature regardless of whether it is mapped to the same or the opposite strand as the feature. For stranded=yes and single-end reads, the read has to be mapped to the same strand as the feature. For paired-end reads, the first read has to be on the same strand and the second read on the opposite strand. For stranded=reverse, these rules are reversed. -a , --a= skip all reads with alignment quality lower than the given minimum value (default: 10  Note: the default used to be 0 until version 0.5.4.) -t , --type= feature type (3rd column in GFF file) to be used, all features of other type are ignored (default, suitable for RNA-Seq analysis using an Ensembl GTF file: exon) -i , --idattr= GFF attribute to be used as feature ID. Several GFF lines with the same feature ID will be considered as parts of the same feature. The feature ID is used to identity the counts in the output table. The default, suitable for RNA-Seq analysis using an Ensembl GTF file, is gene_id. --additional-attr= Additional feature attributes, which will be printed as an additional column after the primary attribute column but before the counts column(s). The default is none, a suitable value to get gene names using an Ensembl GTF file is gene_name. -m , --mode= Mode to handle reads overlapping more than one feature. Possible values for are union, intersection-strict and intersection-nonempty (default: union) --nonunique= Mode to handle reads that align to or are assigned to more than one feature in the overlap of choice (see -m option). are none and all (default: none) --secondary-alignments= Mode to handle secondary alignments (SAM flag 0x100). can be score and ignore (default: score) --supplementary-alignments= Mode to handle supplementary/chimeric alignments (SAM flag 0x800). can be score and ignore (default: score) -o , --samout= write out all SAM alignment records into an output SAM file called , annotating each line with its assignment to a feature or a special counter (as an optional field with tag XF) -q, --quiet suppress progress report and warnings -h, --help Show a usage summary and exit .. _FAQ: https://htseq.readthedocs.io/en/release_0.9.1/count.html#frequenctly-asked-questions",
    "input_formats": [
      "sam",
      "bam",
      "gff",
      "fasta"
    ],
    "output_formats": [
      "tabular",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie_merge/2.2.1+galaxy0",
    "name": "StringTie merge",
    "description": "transcripts",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.2.1+galaxy0",
    "help": "**What it does?** This is a special usage mode of StringTie_, distinct from the assembly usage mode. In the merge mode, StringTie takes as input a list of GTF/GFF files and merges/assembles these transcripts into a non-redundant set of transcripts. This mode is used in the new differential analysis pipeline to generate a global, unified set of transcripts (isoforms) across multiple RNA-Seq samples. If a reference annotation is provided, StringTie will assemble the transfrags from the input GTF files with the reference transcripts. .. _StringTie: http://ccb.jhu.edu/software/stringtie/",
    "input_formats": [
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "gtf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie/2.2.1+galaxy0",
    "name": "StringTie",
    "description": "transcript assembly and quantification",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.2.1+galaxy0",
    "help": ".. class:: infomark **What it does** StringTie_ is a fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional *de novo* assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus. Its input can include not only the alignments of raw reads used by other transcript assemblers, but also alignments of longer sequences that have been assembled from those reads. In order to identify differentially expressed genes between experiments, StringTie's output can be processed by specialized software like Ballgown_, Cuffdiff_ or other programs (DESeq2_, edgeR_, limma_ etc.). ----- **Inputs** StringTie takes as input a BAM (or SAM) file of paired-end RNA-seq reads, which must be sorted by genomic location (coordinate position). This file contains spliced read alignments and can be produced directly by programs such as HISAT2_. We recommend using HISAT2 as it is a fast and accurate alignment program. Every spliced read alignment (i.e. an alignment across at least one junction) in the input BAM file must contain the tag XS to indicate the genomic strand that produced the RNA from which the read was sequenced. Alignments produced by HISAT2 (when run with --dta option) already include this tag, but if you use a different read mapper you should check that this XS tag is included for spliced alignments. *NOTE: be sure to run HISAT2 with the --dta option for alignment (under Spliced alignment options), or your results will suffer.* Also note that if your reads are from a stranded library, you need to choose the appropriate setting under **Specify strand information** above. As, if Forward (FR) is selected, StringTie will assume the reads are from a --fr library, while if Reverse (RF) is selected, StringTie will assume the reads are from a --rf library, otherwise it is assumed that the reads are from an unstranded library (The widely-used, although now deprecated, TopHat had a similar --library-type option, where fr-firststrand corresponded to RF; fr-secondstrand corresponded to FR). If you don't know whether your reads are from are a stranded library or not, you could use the tool **RSeQC Infer Experiment** to try to determine. As an option, a reference annotation file in `GTF/GFF3`_ format can be provided to StringTie. In this case, StringTie will prefer to use these \"known\" genes from the annotation file, and for the ones that are expressed it will compute coverage, TPM and FPKM values. It will also produce additional transcripts to account for RNA-seq data that aren't covered by (or explained by) the annotation. Note that if option -e is not used the reference transcripts need to be fully covered by reads in order to be included in StringTie's output. In that case, other transcripts assembled from the data by StringTie and not present in the reference file will be printed as well. *NOTE: we highly recommend that you provide annotation if you are analyzing a genome that is well-annotated, such as human, mouse, or other model organisms.* ----- **Outputs** StringTie's primary output is * a GTF file containing the **Assembled transcripts** Optionally, it can output * a TSV (tab-delimited) file of **Gene abundances** If a reference GTF/GFF3 file is used as a guide, StringTie can also output: * a GTF file containing all **fully-covered reference transcripts** in the provided reference file that are covered end-to-end by reads * Files (tables) for **Ballgown** and/or **DESeq2/edgeR/limma-voom**, which can use them to estimate differential expression **StringTie's primary GTF output** The primary output of StringTie is a Gene Transfer Format (GTF) file that contains details of the transcripts that StringTie assembles from RNA-Seq data. GTF is an extension of GFF (Gene Finding Format, also called General Feature Format), and is very similar to GFF2 and GFF3. The field definitions for the 9 columns of GTF output can be found at the `Ensembl site here`_. The following is an example of a transcript assembled by StringTie as shown in a GTF file: **seqname** **source** **feature** **start** **end** **score** **strand** **frame** **attributes** ----------- ---------- ----------- --------- ------- --------- ---------- --------- ------------------------------------------------------------------------------------------- chrX StringTie transcript 281394 303355 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"101.256691\"; FPKM \"530.078918\"; TPM \"705.667908\"; chrX StringTie exon 281394 281684 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; exon_number \"1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"116.270836\"; * **seqname**: Denotes the chromosome, contig, or scaffold for this transcript. Here the assembled transcript is on chromosome X. * **source**: The source of the GTF file. Since this example was produced by StringTie, this column simply shows 'StringTie'. * **feature**: Feature type (e.g., exon, transcript, mRNA, 5'UTR). * **start**: Start position of the feature (exon, transcript, etc), using a 1-based index. * **end**: End position of the feature, using a 1-based index. * **score**: A confidence score for the assembled transcript. Currently this field is not used, and StringTie reports a constant value of 1000 if the transcript has a connection to a read alignment bundle. * **strand**: If the transcript resides on the forward strand, '+'. If the transcript resides on the reverse strand, '-'. * **frame**: Frame or phase of CDS features. StringTie does not use this field and simply records a \".\". * **attributes**: A semicolon-separated list of tag-value pairs, providing additional information about each feature. Depending on whether an instance is a transcript or an exon and on whether the transcript matches the reference annotation file provided by the user, the content of the attributes field will differ. The following list describes the possible attributes shown in this column: * *gene_id*: A unique identifier for a single gene and its child transcript and exons based on the alignments' file name. * *transcript_id*: A unique identifier for a single transcript and its child exons based on the alignments' file name. * *exon_number*: A unique identifier for a single exon, starting from 1, within a given transcript. * *reference_id*: The transcript_id in the reference annotation (optional) that the instance matched. * *ref_gene_id*: The gene_id in the reference annotation (optional) that the instance matched. * *ref_gene_name*: The gene_name in the reference annotation (optional) that the instance matched. * *cov*: The average per-base coverage for the transcript or exon. * *FPKM*: Fragments per kilobase of transcript per million read pairs. This is the number of pairs of reads aligning to this feature, normalized by the total number of fragments sequenced (in millions) and the length of the transcript (in kilobases). * *TPM*: Transcripts per million. This is the number of transcripts from this particular gene normalized first by gene length, and then by sequencing depth (in millions) in the sample. A detailed explanation and a comparison of TPM and FPKM can be found here_, and TPM was defined `by B. Li and C. Dewey here`_. **Gene abundances in tab-delimited format** If StringTie is run with the -A option, it returns a file containing gene abundances. The tab-delimited gene abundances output file has nine fields; below is an example of a gene abundance file produced by StringTie using reference annotation: **Gene ID** **Gene Name** **Reference** **Strand** **Start** **End** **Coverage** **FPKM** **TPM** ----------- ------------- ------------- ---------- --------- ------- ------------ -------- -------- NM_000451 SHOX chrX \\+ 624344 646823 0.000000 0.000000 0.000000 NM_006883 SHOX chrX \\+ 624344 659411 0.000000 0.000000 0.000000 * **Gene ID**: The gene identifier comes from the reference annotation provided with the -G option. If no reference is provided this field is replaced with the name prefix for output transcripts (-l). * **Gene Name**: This field contains the gene name in the reference annotation provided with the -G option. If no reference is provided this field is populated with '-'. * **Reference**: Name of the reference sequence that was used in the alignment of the reads. Equivalent to the 3rd column in the .SAM alignment. * **Strand**: '+' denotes that the gene is on the forward strand, '-' for the reverse strand. * **Start**: Start position of the gene (1-based index). * **End**: End position of the gene (1-based index). * **Coverage**: Per-base coverage of the gene. * **FPKM**: normalized expression level in FPKM units (see previous section). * **TPM**: normalized expression level in RPM units (see previous section). **Fully covered transcripts matching the reference annotation transcripts (in GTF format)** If StringTie is run with the use reference guide option (-G), it will also return a file with all the transcripts in the reference annotation that are fully covered, end to end, by reads. The output format is a GTF file as described above. Each line of the GTF is corresponds to a gene or transcript in the reference annotation. **Ballgown Input Table Files** An option to output files for Ballgown can be selected under **Output files for differential expression?** above. If selected, StringTie will return Ballgown input table files containing coverage data for the reference transcripts given with the -G option. These tables have these specific names: (1) e2t.ctab, (2) e_data.ctab, (3) i2t.ctab, (4) i_data.ctab, and (5) t_data.ctab. A detailed description of each of these five required inputs to Ballgown can be found at `this link`. With this option StringTie can be used as a direct replacement of the tablemaker program included with the Ballgown distribution. **DESeq2/edgeR/limma-voom Input Table Files** DESeq2_, edgeR_ and limma_ are three popular Bioconductor_ packages for analyzing differential expression, which take as input a matrix of read counts mapped to particular genomic features (e.g., genes). This read count information can be extracted directly from the files generated by StringTie (run with the -e parameter) by selecting DESeq2/edgeR/limma-voom under **Output files for differential expression?** above. This uses the StringTie helper script ``prepDE.py`` to convert the GTF output from StringTie into two tab-delimited (TSV) files, containing the count matrices for genes and transcripts, using the coverage values found in the output of StringTie -e. ----- **More Information** *Evaluating transcript assemblies:* A simple way of getting more information about the transcripts assembled by StringTie (summary of gene and transcript counts, novel vs. known etc.), or even performing basic tracking of assembled isoforms across multiple RNA-Seq experiments, is to use the **gffcompare** program. Basic usage information for this program can be found on the `GFF utilities page`_. *Differential expression analysis:* Together with HISAT and Ballgown (or DESeq2/edgeR/limma-voom), StringTie can be used for estimating differential expression across multiple RNA-Seq samples and generating plots and differential expression tables as described in our `protocol paper`_ and shown in a diagram in the `StringTie manual here`_. Our recommended workflow includes the following steps: 1. For each RNA-Seq sample, map the reads to the genome with HISAT2 using the --dta option. It is highly recommended to use the reference annotation information when mapping the reads, which can be either embedded in the genome index (built with the --ss and --exon options, see HISAT2 manual), or provided separately at run time (using the --known-splicesite-infile option of HISAT2). The SAM output of each HISAT2 run must be sorted and converted to BAM using samtools as explained above. 2. For each RNA-Seq sample, use this StringTie tool to assemble the read alignments obtained in the previous step; it is recommended to run StringTie with the -G option if the reference annotation is available. 3. Run the separate **StringTie merge** tool in order to generate a non-redundant set of transcripts observed in all the RNA-Seq samples assembled previously. ``StringTie merge`` takes as input a list of all the assembled transcripts files (in GTF format) previously obtained for each sample, as well as a reference annotation file (-G option) if available. 4. For each RNA-Seq sample, run this StringTie tool selecting to output files for Ballgown (or DESeq2/edgeR/limma-voom), which will generate tables of transcript and gene estimated abundances (count files). The option -e (*Use Reference transcripts only*) is not required but is recommended for this run in order to produce more accurate abundance estimations of the input transcripts. Each StringTie run in this step will take as input the sorted read alignments (BAM file) obtained in step 1 for the corresponding sample and the -G option with the merged transcripts (GTF file) generated by ``stringtie merge`` in step 3. Please note that this is the only case where the -G option is not used with a reference annotation, but with the global, merged set of transcripts as observed across all samples. (This step is the equivalent of the *Tablemaker* step described in the original Ballgown pipeline.) 5. Ballgown (or DESeq2/edgeR/limma-voom) can now be used to load the coverage tables generated in the previous step and perform various statistical analyses for differential expression, generate plots etc. An alternate, faster differential expression analysis workflow can be pursued if there is no interest in novel isoforms (i.e. assembled transcripts present in the samples but missing from the reference annotation), or if only a well known set of transcripts of interest are targeted by the analysis. This simplified protocol has only 3 steps (depicted in the `StringTie manual here`_) as it bypasses the individual assembly of each RNA-Seq sample and the \"transcript merge\" step. This simplified workflow attempts to directly estimate and analyze the expression of a known set of transcripts as given in the reference annotation file. .. _StringTie: http://ccb.jhu.edu/software/stringtie/ .. _Ballgown: https://www.biorxiv.org/content/early/2014/09/05/003665 .. _Cuffdiff: http://cole-trapnell-lab.github.io/cufflinks/cuffdiff/ .. _DESeq2: https://bioconductor.org/packages/release/bioc/html/DESeq2.html .. _edgeR: https://bioconductor.org/packages/release/bioc/html/edgeR.html .. _limma: https://bioconductor.org/packages/release/bioc/html/limma.html .. _Bioconductor: https://www.bioconductor.org/ .. _SAM: http://samtools.github.io/hts-specs/SAMv1.pdf .. _HISAT2: http://ccb.jhu.edu/software/hisat2 .. _`GTF/GFF3`: http://ccb.jhu.edu/software/stringtie/gff.shtml .. _`this link`: https://github.com/alyssafrazee/ballgown#ballgown-readable-expression-output .. _`Ensembl site here`: http://useast.ensembl.org/info/website/upload/gff.html .. _here: http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/ .. _`by B. Li and C. Dewey here`: http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-323 .. _`GFF utilities page`: http://ccb.jhu.edu/software/stringtie/gff.shtml#gffcompare .. _`protocol paper`: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5032908/ .. _`StringTie manual here`: http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "gtf",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "gtf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/rgrnastar/rna_star/2.7.8a+galaxy1",
    "name": "RNA STAR",
    "description": "Gapped-read mapper for RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.7.8a+galaxy1",
    "help": "**What it does** STAR_ is an ultrafast universal RNA-seq aligner. **Compatibility Notes** STAR has a huge amount of options to filter alignments and to configure the exact format of its output. Some tools you may plan to use in your downstream analysis of the results are known to be sensitive to these settings or combinations of them. *STAR-Fusion* STAR-Fusion_ can use the chimeric junctions output of STAR as input, but you need to enable **chimeric alignment detection** by STAR for that dataset to be generated. Hence, be sure to select: **Report chimeric alignments?**: `As separate tabular \"Junctions\" output (Junctions)`. In addition, for best results it is recommended_ that you - use **2-pass mapping** for more sensitive novel splice junction discovery - under *BAM output format specification*, **Read alignment tags to include in the BAM output**: select `XS` as an additional tag to generate (this is the equivalent of using `--outSAMstrandField intronMotif` on the command line) - under *Algorithmic settings*, **Configure seed, alignment and limits options**: `use parameters suggested for STAR-Fusion`. *Arriba* Arriba_ can use the BAM with chimeric junctions or both files separately, generated by STAR, as input, but you need to enable **chimeric alignment detection** by STAR for those datasets to be generated. Hence, be sure to select either: **Report chimeric alignments?**: `As separate tabular \"Junctions\" output (Junctions)` or **Report chimeric alignments?**: `Within the BAM output (together with regular alignments; WithinBAM)`. In addition, the following parameters_ related to chimeric alignment are recommended for improved sensitivity - under *Output filter criteria*, **Would you like to set additional output filters?**: select `Yes' to set **Maximum number of alignments to output a read's alignment results, plus 1** to 50 - under *Algorithmic settings*, **Configure seed, alignment and limits options**: `use parameters suggested for Arriba`. *Cufflinks* .. class:: infomark Cufflinks is not considered to be the best tool for use downstream of STAR anymore. Consider using *Stringtie* instead, which also should pose no compatibility issues. To avoid compatibility issues with Cufflinks you should: - select **XS** as a *Read alignment tag to include in the BAM output* if (and only if) your sequenced reads come from an unstranded library prep - *not* select the *jM* and *jI* tags for inclusion - keep the **HI** tag selected and - select *HI tag values should be* **zero-based** - exclude **All alignments across non-canonical junctions** under *Output filter criteria -> Exclude the following records from the BAM output* ----- Attribution Minor tweaks to output names to suit downstream purposes, toolshed automated dependencies and odds and ends of other code and documentation comprising this tool were originally written by Ross Lazarus and have been licensed under the creative commons `BY-NC_ND 3.0 license ` . .. _STAR: https://github.com/alexdobin/STAR .. _STAR-Fusion: https://github.com/STAR-Fusion/STAR-Fusion .. _Arriba: https://github.com/suhrig/arriba .. _recommended: https://github.com/STAR-Fusion/STAR-Fusion/wiki#alternatively-kickstart-mode-running-star-yourself-and-then-running-star-fusion-using-the-existing-outputs .. _parameters: https://arriba.readthedocs.io/en/latest/workflow/",
    "input_formats": [
      "fastq",
      "fasta",
      "fastq.gz",
      "fastqsanger.gz",
      "gff3",
      "gtf",
      "interval"
    ],
    "output_formats": [
      "txt",
      "interval",
      "bam",
      "unsorted.bam",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/seurat/seurat/4.2.0+galaxy0",
    "name": "Seurat",
    "description": "- toolkit for exploration of single-cell RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "4.2.0+galaxy0",
    "help": ".. class:: infomark **What it does** Seurat_ is a toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. It is developed and maintained by the `Satija Lab`_ at NYGC. Seurat aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See the `Seurat Guided Clustering tutorial`_ for more information. ----- **Inputs** * Gene count matrix in TAB-separated format ----- **Outputs** * HTML of plots Optionally you can choose to output * R commands used to generate plots printed alongside figures .. _Seurat: https://www.nature.com/articles/nbt.4096 .. _Satija Lab: https://satijalab.org/seurat/ .. _Seurat Guided Clustering tutorial: https://satijalab.org/seurat/pbmc3k_tutorial.html",
    "input_formats": [
      "tabular",
      "tsv"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/seurat/seurat/4.3.0+galaxy0",
    "name": "Seurat",
    "description": "- toolkit for exploration of single-cell RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "4.3.0+galaxy0",
    "help": ".. class:: infomark **What it does** Seurat_ is a toolkit for quality control, analysis, and exploration of single cell RNA sequencing data. It is developed and maintained by the `Satija Lab`_ at NYGC. Seurat aims to enable users to identify and interpret sources of heterogeneity from single cell transcriptomic measurements, and to integrate diverse types of single cell data. See the `Seurat Guided Clustering tutorial`_ for more information. ----- **Inputs** * Gene count matrix in TAB-separated format ----- **Outputs** * HTML of plots Optionally you can choose to output * R commands used to generate plots printed alongside figures .. _Seurat: https://www.nature.com/articles/nbt.4096 .. _Satija Lab: https://satijalab.org/seurat/ .. _Seurat Guided Clustering tutorial: https://satijalab.org/seurat/pbmc3k_tutorial.html",
    "input_formats": [
      "tabular",
      "tsv"
    ],
    "output_formats": [
      "html"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/salmon/salmon/1.9.0+galaxy2",
    "name": "Salmon quant",
    "description": "Perform dual-phase, reads or mapping-based estimation of transcript abundance from RNA-seq reads",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.9.0+galaxy2",
    "help": "Salmon is a lightweight method for quantifying transcript abundance from RNAseq reads, combining a dual-phase parallel inference algorithm and feature-rich bias models with an ultra-fast read mapping procedure. The salmon package contains 4 tools: * Index: creates a salmon index * Quant: quantifies a sample (Reads or mapping-based) * Alevin: Single-cell analysis * Quantmerge: Merges multiple quantifications into a single file Galaxy divides these four into three separate tools in the IUC toolshed: * Salmon quant * Salmon quantmerge * Alevin",
    "input_formats": [
      "fasta",
      "fastq",
      "fastq.gz",
      "fastq.bz2",
      "fastqsanger",
      "fastqsanger.gz",
      "fastqsanger.bz2",
      "qname_input_sorted.bam",
      "qname_sorted.bam",
      "fa",
      "tabular",
      "gff",
      "gtf"
    ],
    "output_formats": [
      "tabular",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/feelnc/feelnc/0.2.1+galaxy0",
    "name": "FEELnc",
    "description": "FlExible Extraction of LncRNA",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.2.1+galaxy0",
    "help": "**What it does** FEELnc pipeline is used to annotate long non-coding RNAs (lncRNAs) based on reconstructed transcripts from RNA-seq data (either with or without a reference genome). -------- **Project links:** https://github.com/tderrien/FEELnc",
    "input_formats": [
      "gtf",
      "fasta"
    ],
    "output_formats": [
      "gtf",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/featurecounts/featurecounts/2.0.3+galaxy1",
    "name": "featureCounts",
    "description": "Measure gene expression in RNA-Seq experiments from SAM or BAM files",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.3+galaxy1",
    "help": "featureCounts ############# Overview -------- FeatureCounts is a light-weight read counting program written entirely in the C programming language. It can be used to count both gDNA-seq and RNA-seq reads for genomic features in in SAM/BAM files. FeatureCounts is part of the Subread_ package. Input formats ------------- Alignments should be provided in either: - SAM format, http://samtools.sourceforge.net/samtools.shtml#5 - BAM format Annotations for gene regions should be provided in the GFF/GTF format: - http://genome.ucsc.edu/FAQ/FAQformat.html#format3 - http://www.ensembl.org/info/website/upload/gff.html Alternatively, the featureCounts built-in annotations for genomes hg38, hg19, mm10 and mm9 can be used through selecting the built-in option above. These annotation files are in simplified annotation format (SAF) as shown below. The GeneID column contains Entrez gene identifiers and each entry (row) is taken as a feature (e.g. an exon). Example - **Built-in annotation format**: GeneID Chr Start End Strand 497097 chr1 3204563 3207049 - 497098 chr1 3411783 3411982 - 497099 chr1 3660633 3661579 - These annotation files can be found in the `Subread package`_. You can see the version of Subread used by this wrapper in the tool form above under `Options > Requirements`. To create the files, the annotations were downloaded from NCBI RefSeq database and then adapted by merging overlapping exons from the same gene to form a set of disjoint exons for each gene. Genes with the same Entrez gene identifiers were also merged into one gene. See the `Subread User's Guide`_ for more information. Gene names can be obtained for these Entrez identifiers with the Galaxy **annotateMyIDs** tool. Output format ------------- FeatureCounts produces a table containing counted reads, per gene, per row. Optionally the last column can be set to be the effective gene-length. These tables are compatible with the DESeq2, edgeR and limma-voom Galaxy wrappers by IUC. .. _Subread: http://subread.sourceforge.net/ .. _`Subread User's Guide`: https://bioconductor.org/packages/release/bioc/vignettes/Rsubread/inst/doc/SubreadUsersGuide.pdf .. _`Subread package`: https://sourceforge.net/projects/subread/files/",
    "input_formats": [
      "bam",
      "sam",
      "gff",
      "gtf",
      "gff3",
      "fasta"
    ],
    "output_formats": [
      "tabular",
      "bam"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/dexseq/1.44+galaxy0",
    "name": "DEXSeq",
    "description": "Determines differential exon usage from count tables",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.44+galaxy0",
    "help": ".. class:: infomark **What it does** Inference of differential exon usage in RNA-Seq. **Inputs** DEXSeq_ takes count tables generated from the dexseq_count as input. Count tables must be generated for each sample individually. DEXSeq_ is capable of handling multiple factors that affect your experiment. The first factor you input is considered to be the primary factor that affects gene expressions. You can also input several secondary factors that might influence your experiment but the final output will be changes in genes due to primary factor in the presence of secondary factors. Each factor has two levels/states. You need to select an appropriate count table from your history for each factor level. The following table gives some examples of factors and their levels: Factor Factor level 1 Factor level 2 --------- -------------- --------------- condition Knockdown Wildtype --------- -------------- --------------- treatment Treated Untreated --------- -------------- --------------- timePoint Day4 Day1 --------- -------------- --------------- SeqType SingleEnd PairedEnd --------- -------------- --------------- Gender Female Male *Note*: Output log2 fold changes are based on primary factor level 1 vs. factor level 2. Here the order of factor levels is important. For example, for the factor 'condition' given in the above table, DEXSeq computes fold changes of 'Knockdown' samples against 'Wildtype', i.e. the values correspond to up or down regulations of genes in Knockdown samples. **Output** DEXSeq_ generates a tabular file containing the different columns and an optional html report. It can also ouput the DEXSeqResults R object that can be used with the plotDEXSeq tool to visualise individual genes. Column Description ------ ---------------------------------------------------------- 1 Gene and exon Identifiers 2 group/gene identifier 3 feature/exon identifier 4 mean of the counts across samples in each feature/exon 5 exon dispersion estimate 6 LRT statistic 7 LRT p-value 8 BH adjusted p-values 9 exon usage coefficient factorLevel 2 10 exon usage coefficient factorLevel 1 11 relative exon usage fold changes 12 GRanges object of the coordinates of the exon/feature 13 matrix of integer counts, of each column containing a sample 14 list of transcripts overlapping with the exon .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "gtf",
      "gff",
      "tabular"
    ],
    "output_formats": [
      "tabular",
      "html",
      "rds"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/dexseq_count/1.44+galaxy0",
    "name": "DEXSeq-Count",
    "description": "Prepare and count exon abundancies from RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.44+galaxy0",
    "help": ".. class:: infomark **What it does** The main goal of this tool is to count the number of reads/fragments per exon of each gene in RNA-seq samples. In addition, it also prepares your annotation GTF file, making it compatible for counting. **Inputs** Mode-preprare: Takes a normal GTF file as input. For example from Ensembl database. Mode-count: Inputs are flattened GTF file and BAM file. The flattened GTF file can be generated from 'prepare' mode of this tool. **Output** Mode-prepare: Flattened GTF file that contains only exons with corresponding gene ids from the input GTF file. Sometimes two or more genes sharing an exon will be merged into an 'aggregate gene' if the aggregate option was used. Mode-count: Two column tab-delimited file with exon ids and their read counts. .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "gff",
      "bam"
    ],
    "output_formats": [
      "tabular",
      "gtf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/dexseq/plotdexseq/1.44+galaxy0",
    "name": "plotDEXSeq",
    "description": "Visualization of the per gene DEXSeq results",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.44+galaxy0",
    "help": ".. class:: infomark **What it does** This tool enables visualization of DEXSeq results for individual genes. The input is a DEXSeqResults rds file, which can be output from the DEXSeq tool, and a single gene ID or list of IDs to plot. .. _DEXSeq: http://master.bioconductor.org/packages/release/bioc/html/DEXSeq.html",
    "input_formats": [
      "rdata",
      "tabular"
    ],
    "output_formats": [
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie_merge/2.2.1+galaxy1",
    "name": "StringTie merge",
    "description": "transcripts",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.2.1+galaxy1",
    "help": "**What it does?** This is a special usage mode of StringTie_, distinct from the assembly usage mode. In the merge mode, StringTie takes as input a list of GTF/GFF files and merges/assembles these transcripts into a non-redundant set of transcripts. This mode is used in the new differential analysis pipeline to generate a global, unified set of transcripts (isoforms) across multiple RNA-Seq samples. If a reference annotation is provided, StringTie will assemble the transfrags from the input GTF files with the reference transcripts. .. _StringTie: http://ccb.jhu.edu/software/stringtie/",
    "input_formats": [
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "gtf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/stringtie/stringtie/2.2.1+galaxy1",
    "name": "StringTie",
    "description": "transcript assembly and quantification",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.2.1+galaxy1",
    "help": ".. class:: infomark **What it does** StringTie_ is a fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional *de novo* assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus. Its input can include not only the alignments of raw reads used by other transcript assemblers, but also alignments of longer sequences that have been assembled from those reads. In order to identify differentially expressed genes between experiments, StringTie's output can be processed by specialized software like Ballgown_, Cuffdiff_ or other programs (DESeq2_, edgeR_, limma_ etc.). ----- **Inputs** StringTie takes as input a BAM (or SAM) file of paired-end RNA-seq reads, which must be sorted by genomic location (coordinate position). This file contains spliced read alignments and can be produced directly by programs such as HISAT2_. We recommend using HISAT2 as it is a fast and accurate alignment program. Every spliced read alignment (i.e. an alignment across at least one junction) in the input BAM file must contain the tag XS to indicate the genomic strand that produced the RNA from which the read was sequenced. Alignments produced by HISAT2 (when run with --dta option) already include this tag, but if you use a different read mapper you should check that this XS tag is included for spliced alignments. *NOTE: be sure to run HISAT2 with the --dta option for alignment (under Spliced alignment options), or your results will suffer.* Also note that if your reads are from a stranded library, you need to choose the appropriate setting under **Specify strand information** above. As, if Forward (FR) is selected, StringTie will assume the reads are from a --fr library, while if Reverse (RF) is selected, StringTie will assume the reads are from a --rf library, otherwise it is assumed that the reads are from an unstranded library (The widely-used, although now deprecated, TopHat had a similar --library-type option, where fr-firststrand corresponded to RF; fr-secondstrand corresponded to FR). If you don't know whether your reads are from are a stranded library or not, you could use the tool **RSeQC Infer Experiment** to try to determine. As an option, a reference annotation file in `GTF/GFF3`_ format can be provided to StringTie. In this case, StringTie will prefer to use these \"known\" genes from the annotation file, and for the ones that are expressed it will compute coverage, TPM and FPKM values. It will also produce additional transcripts to account for RNA-seq data that aren't covered by (or explained by) the annotation. Note that if option -e is not used the reference transcripts need to be fully covered by reads in order to be included in StringTie's output. In that case, other transcripts assembled from the data by StringTie and not present in the reference file will be printed as well. *NOTE: we highly recommend that you provide annotation if you are analyzing a genome that is well-annotated, such as human, mouse, or other model organisms.* ----- **Outputs** StringTie's primary output is * a GTF file containing the **Assembled transcripts** Optionally, it can output * a TSV (tab-delimited) file of **Gene abundances** If a reference GTF/GFF3 file is used as a guide, StringTie can also output: * a GTF file containing all **fully-covered reference transcripts** in the provided reference file that are covered end-to-end by reads * Files (tables) for **Ballgown** and/or **DESeq2/edgeR/limma-voom**, which can use them to estimate differential expression **StringTie's primary GTF output** The primary output of StringTie is a Gene Transfer Format (GTF) file that contains details of the transcripts that StringTie assembles from RNA-Seq data. GTF is an extension of GFF (Gene Finding Format, also called General Feature Format), and is very similar to GFF2 and GFF3. The field definitions for the 9 columns of GTF output can be found at the `Ensembl site here`_. The following is an example of a transcript assembled by StringTie as shown in a GTF file: **seqname** **source** **feature** **start** **end** **score** **strand** **frame** **attributes** ----------- ---------- ----------- --------- ------- --------- ---------- --------- ------------------------------------------------------------------------------------------- chrX StringTie transcript 281394 303355 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"101.256691\"; FPKM \"530.078918\"; TPM \"705.667908\"; chrX StringTie exon 281394 281684 1000 \\+ . gene_id \"ERR188044.1\"; transcript_id \"ERR188044.1.1\"; exon_number \"1\"; reference_id \"NM_018390\"; ref_gene_id \"NM_018390\"; ref_gene_name \"PLCXD1\"; cov \"116.270836\"; * **seqname**: Denotes the chromosome, contig, or scaffold for this transcript. Here the assembled transcript is on chromosome X. * **source**: The source of the GTF file. Since this example was produced by StringTie, this column simply shows 'StringTie'. * **feature**: Feature type (e.g., exon, transcript, mRNA, 5'UTR). * **start**: Start position of the feature (exon, transcript, etc), using a 1-based index. * **end**: End position of the feature, using a 1-based index. * **score**: A confidence score for the assembled transcript. Currently this field is not used, and StringTie reports a constant value of 1000 if the transcript has a connection to a read alignment bundle. * **strand**: If the transcript resides on the forward strand, '+'. If the transcript resides on the reverse strand, '-'. * **frame**: Frame or phase of CDS features. StringTie does not use this field and simply records a \".\". * **attributes**: A semicolon-separated list of tag-value pairs, providing additional information about each feature. Depending on whether an instance is a transcript or an exon and on whether the transcript matches the reference annotation file provided by the user, the content of the attributes field will differ. The following list describes the possible attributes shown in this column: * *gene_id*: A unique identifier for a single gene and its child transcript and exons based on the alignments' file name. * *transcript_id*: A unique identifier for a single transcript and its child exons based on the alignments' file name. * *exon_number*: A unique identifier for a single exon, starting from 1, within a given transcript. * *reference_id*: The transcript_id in the reference annotation (optional) that the instance matched. * *ref_gene_id*: The gene_id in the reference annotation (optional) that the instance matched. * *ref_gene_name*: The gene_name in the reference annotation (optional) that the instance matched. * *cov*: The average per-base coverage for the transcript or exon. * *FPKM*: Fragments per kilobase of transcript per million read pairs. This is the number of pairs of reads aligning to this feature, normalized by the total number of fragments sequenced (in millions) and the length of the transcript (in kilobases). * *TPM*: Transcripts per million. This is the number of transcripts from this particular gene normalized first by gene length, and then by sequencing depth (in millions) in the sample. A detailed explanation and a comparison of TPM and FPKM can be found here_, and TPM was defined `by B. Li and C. Dewey here`_. **Gene abundances in tab-delimited format** If StringTie is run with the -A option, it returns a file containing gene abundances. The tab-delimited gene abundances output file has nine fields; below is an example of a gene abundance file produced by StringTie using reference annotation: **Gene ID** **Gene Name** **Reference** **Strand** **Start** **End** **Coverage** **FPKM** **TPM** ----------- ------------- ------------- ---------- --------- ------- ------------ -------- -------- NM_000451 SHOX chrX \\+ 624344 646823 0.000000 0.000000 0.000000 NM_006883 SHOX chrX \\+ 624344 659411 0.000000 0.000000 0.000000 * **Gene ID**: The gene identifier comes from the reference annotation provided with the -G option. If no reference is provided this field is replaced with the name prefix for output transcripts (-l). * **Gene Name**: This field contains the gene name in the reference annotation provided with the -G option. If no reference is provided this field is populated with '-'. * **Reference**: Name of the reference sequence that was used in the alignment of the reads. Equivalent to the 3rd column in the .SAM alignment. * **Strand**: '+' denotes that the gene is on the forward strand, '-' for the reverse strand. * **Start**: Start position of the gene (1-based index). * **End**: End position of the gene (1-based index). * **Coverage**: Per-base coverage of the gene. * **FPKM**: normalized expression level in FPKM units (see previous section). * **TPM**: normalized expression level in RPM units (see previous section). **Fully covered transcripts matching the reference annotation transcripts (in GTF format)** If StringTie is run with the use reference guide option (-G), it will also return a file with all the transcripts in the reference annotation that are fully covered, end to end, by reads. The output format is a GTF file as described above. Each line of the GTF is corresponds to a gene or transcript in the reference annotation. **Ballgown Input Table Files** An option to output files for Ballgown can be selected under **Output files for differential expression?** above. If selected, StringTie will return Ballgown input table files containing coverage data for the reference transcripts given with the -G option. These tables have these specific names: (1) e2t.ctab, (2) e_data.ctab, (3) i2t.ctab, (4) i_data.ctab, and (5) t_data.ctab. A detailed description of each of these five required inputs to Ballgown can be found at `this link`. With this option StringTie can be used as a direct replacement of the tablemaker program included with the Ballgown distribution. **DESeq2/edgeR/limma-voom Input Table Files** DESeq2_, edgeR_ and limma_ are three popular Bioconductor_ packages for analyzing differential expression, which take as input a matrix of read counts mapped to particular genomic features (e.g., genes). This read count information can be extracted directly from the files generated by StringTie (run with the -e parameter) by selecting DESeq2/edgeR/limma-voom under **Output files for differential expression?** above. This uses the StringTie helper script ``prepDE.py`` to convert the GTF output from StringTie into two tab-delimited (TSV) files, containing the count matrices for genes and transcripts, using the coverage values found in the output of StringTie -e. ----- **More Information** *Evaluating transcript assemblies:* A simple way of getting more information about the transcripts assembled by StringTie (summary of gene and transcript counts, novel vs. known etc.), or even performing basic tracking of assembled isoforms across multiple RNA-Seq experiments, is to use the **gffcompare** program. Basic usage information for this program can be found on the `GFF utilities page`_. *Differential expression analysis:* Together with HISAT and Ballgown (or DESeq2/edgeR/limma-voom), StringTie can be used for estimating differential expression across multiple RNA-Seq samples and generating plots and differential expression tables as described in our `protocol paper`_ and shown in a diagram in the `StringTie manual here`_. Our recommended workflow includes the following steps: 1. For each RNA-Seq sample, map the reads to the genome with HISAT2 using the --dta option. It is highly recommended to use the reference annotation information when mapping the reads, which can be either embedded in the genome index (built with the --ss and --exon options, see HISAT2 manual), or provided separately at run time (using the --known-splicesite-infile option of HISAT2). The SAM output of each HISAT2 run must be sorted and converted to BAM using samtools as explained above. 2. For each RNA-Seq sample, use this StringTie tool to assemble the read alignments obtained in the previous step; it is recommended to run StringTie with the -G option if the reference annotation is available. 3. Run the separate **StringTie merge** tool in order to generate a non-redundant set of transcripts observed in all the RNA-Seq samples assembled previously. ``StringTie merge`` takes as input a list of all the assembled transcripts files (in GTF format) previously obtained for each sample, as well as a reference annotation file (-G option) if available. 4. For each RNA-Seq sample, run this StringTie tool selecting to output files for Ballgown (or DESeq2/edgeR/limma-voom), which will generate tables of transcript and gene estimated abundances (count files). The option -e (*Use Reference transcripts only*) is not required but is recommended for this run in order to produce more accurate abundance estimations of the input transcripts. Each StringTie run in this step will take as input the sorted read alignments (BAM file) obtained in step 1 for the corresponding sample and the -G option with the merged transcripts (GTF file) generated by ``stringtie merge`` in step 3. Please note that this is the only case where the -G option is not used with a reference annotation, but with the global, merged set of transcripts as observed across all samples. (This step is the equivalent of the *Tablemaker* step described in the original Ballgown pipeline.) 5. Ballgown (or DESeq2/edgeR/limma-voom) can now be used to load the coverage tables generated in the previous step and perform various statistical analyses for differential expression, generate plots etc. An alternate, faster differential expression analysis workflow can be pursued if there is no interest in novel isoforms (i.e. assembled transcripts present in the samples but missing from the reference annotation), or if only a well known set of transcripts of interest are targeted by the analysis. This simplified protocol has only 3 steps (depicted in the `StringTie manual here`_) as it bypasses the individual assembly of each RNA-Seq sample and the \"transcript merge\" step. This simplified workflow attempts to directly estimate and analyze the expression of a known set of transcripts as given in the reference annotation file. .. _StringTie: http://ccb.jhu.edu/software/stringtie/ .. _Ballgown: https://www.biorxiv.org/content/early/2014/09/05/003665 .. _Cuffdiff: http://cole-trapnell-lab.github.io/cufflinks/cuffdiff/ .. _DESeq2: https://bioconductor.org/packages/release/bioc/html/DESeq2.html .. _edgeR: https://bioconductor.org/packages/release/bioc/html/edgeR.html .. _limma: https://bioconductor.org/packages/release/bioc/html/limma.html .. _Bioconductor: https://www.bioconductor.org/ .. _SAM: http://samtools.github.io/hts-specs/SAMv1.pdf .. _HISAT2: http://ccb.jhu.edu/software/hisat2 .. _`GTF/GFF3`: http://ccb.jhu.edu/software/stringtie/gff.shtml .. _`this link`: https://github.com/alyssafrazee/ballgown#ballgown-readable-expression-output .. _`Ensembl site here`: http://useast.ensembl.org/info/website/upload/gff.html .. _here: http://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/ .. _`by B. Li and C. Dewey here`: http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-323 .. _`GFF utilities page`: http://ccb.jhu.edu/software/stringtie/gff.shtml#gffcompare .. _`protocol paper`: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5032908/ .. _`StringTie manual here`: http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
    "input_formats": [
      "sam",
      "bam",
      "cram",
      "gtf",
      "gff3",
      "tabular"
    ],
    "output_formats": [
      "gtf",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/rgrnastar/rna_star/2.7.10b+galaxy3",
    "name": "RNA STAR",
    "description": "Gapped-read mapper for RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.7.10b+galaxy3",
    "help": "**What it does** STAR_ is an ultrafast universal RNA-seq aligner. **Compatibility Notes** STAR has a huge amount of options to filter alignments and to configure the exact format of its output. Some tools you may plan to use in your downstream analysis of the results are known to be sensitive to these settings or combinations of them. *STAR-Fusion* STAR-Fusion_ can use the chimeric junctions output of STAR as input, but you need to enable **chimeric alignment detection** by STAR for that dataset to be generated. Hence, be sure to select: **Report chimeric alignments?**: `As separate tabular \"Junctions\" output (Junctions)`. In addition, for best results it is recommended_ that you - use **2-pass mapping** for more sensitive novel splice junction discovery - under *BAM output format specification*, **Read alignment tags to include in the BAM output**: select `XS` as an additional tag to generate (this is the equivalent of using `--outSAMstrandField intronMotif` on the command line) - under *Algorithmic settings*, **Configure seed, alignment and limits options**: `use parameters suggested for STAR-Fusion`. *Arriba* Arriba_ can use the BAM with chimeric junctions or both files separately, generated by STAR, as input, but you need to enable **chimeric alignment detection** by STAR for those datasets to be generated. Hence, be sure to select either: **Report chimeric alignments?**: `As separate tabular \"Junctions\" output (Junctions)` or **Report chimeric alignments?**: `Within the BAM output (together with regular alignments; WithinBAM)`. In addition, the following parameters_ related to chimeric alignment are recommended for improved sensitivity - under *Output filter criteria*, **Would you like to set additional output filters?**: select `Yes` to set **Maximum number of alignments to output a read's alignment results, plus 1** to 50 - under *Algorithmic settings*, **Configure seed, alignment and limits options**: `use parameters suggested for Arriba`. *Cufflinks* .. class:: infomark Cufflinks is not considered to be the best tool for use downstream of STAR anymore. Consider using *Stringtie* instead, which also should pose no compatibility issues. To avoid compatibility issues with Cufflinks you should: - select **XS** as a *Read alignment tag to include in the BAM output* if (and only if) your sequenced reads come from an unstranded library prep - *not* select the *jM* and *jI* tags for inclusion - keep the **HI** tag selected and - select *HI tag values should be* **zero-based** - exclude **All alignments across non-canonical junctions** under *Output filter criteria -> Exclude the following records from the BAM output* ----- Attribution Minor tweaks to output names to suit downstream purposes, toolshed automated dependencies and odds and ends of other code and documentation comprising this tool were originally written by Ross Lazarus and have been licensed under the creative commons `BY-NC_ND 3.0 license ` . .. _STAR: https://github.com/alexdobin/STAR .. _STAR-Fusion: https://github.com/STAR-Fusion/STAR-Fusion .. _Arriba: https://github.com/suhrig/arriba .. _recommended: https://github.com/STAR-Fusion/STAR-Fusion/wiki#alternatively-kickstart-mode-running-star-yourself-and-then-running-star-fusion-using-the-existing-outputs .. _parameters: https://arriba.readthedocs.io/en/latest/workflow/",
    "input_formats": [
      "fastq",
      "fasta",
      "fastq.gz",
      "fastqsanger.gz",
      "gff3",
      "gtf",
      "fasta.gz",
      "interval"
    ],
    "output_formats": [
      "txt",
      "interval",
      "bam",
      "unsorted.bam",
      "tabular",
      "bedgraph"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/gffcompare/gffcompare/0.12.6+galaxy0",
    "name": "GffCompare",
    "description": "compare assembled transcripts to a reference annotation",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.12.6+galaxy0",
    "help": ".. class:: infomark **GffCompare Overview** GffCompare is designed to systematically compare one or more sets of transcript predictions to a reference annotation at different levels of granularity (base level, exon level, transcript level etc.), and in the process to provide a way to \"annotate\" such transcript predictions based on their overlaps or proximity to reference annotation transcripts. When multiple transcript files (samples) are provided, GffCompare generates a non-redundant combined set of transcripts, tracking structurally equivalent transcripts across multiple samples and classifying them according to their relationship to reference transcripts. GffCompare has the following main functions: - Merge structurally equivalent transcripts and transcript fragments (transfrags) across multiple samples - Assess the accuracy of the assembled transcripts from an RNA-Seq sample by comparing it to known annotation - Track, annotate, and report all structurally distinct transfrags across multiple samples The last two purposes require the user to provide a known reference annotation file that GffCompare then uses to classify all the transcripts in the input samples according to the reference transcript that they most closely overlap. To assess the accuracy of transcriptome assemblies, GffCompare reports several accuracy metrics previously employed for gene prediction evaluation. These metrics include sensitivity and precision as well as the number of novel or missed features, and the metrics are computed at various levels (base, exon, intron chain, transcript, or locus). ---- .. class:: infomark **Annotation mode** When a single query GTF/GFF file is given as input for analysis, along with a reference annotation (-r option), GffCompare switches into annotation mode and it generates a *annotated transcripts* file, allowing annotate transcripts by using a reference annotation. It should be noted that this file is not generated when options to remove \"duplicated\"/redundant transfrags are given (-D, -S, -C, -A, -X). ---- .. class:: infomark **Merging structually equivalent transcripts** When multiple input GTF/GFF files are provided, GffCompare reports a GTF file named *combined transcripts* that containing the union of all transfrags in each sample. If a transfrag with the same exact intron chain is present in both samples, it is thus reported only once in the output file. **The \"super-locus\" concept** A super-locus is a region of the genome where predicted transcripts and reference transcripts get clustered together by exon overlaps. When multiple GFF files are provided as input to GffCompare, this clustering is performed across all the input files. Due to the transitive nature of this clustering, these super-loci can occasionally get very large, sometimes merging a few distinct reference gene regions together, especially if there is a lot of transcription or alignment noise around the individual gene regions. For each super-locus, GffCompare assigns a unique identifier with the XLOC prefix. ---- .. class:: infomark **Transcript accuracy estimation** GffCompare can be used to assess the accuracy of transcriptome assemblies produced by programs like StringTie 19 with respect to a known reference annotation. To this end, GffCompare reports various statistics related to the accuracy of the input transcripts compared to the reference annotation in the *accuracy stats* file. Among these statistics are sensitivity and precision values computed at various levels (base, exon, intron chain, transcript, locus), which are calculated as: * Sensitivity = TP/(TP+FN) * Precision = TP/(TP+FP) where TP stands for \"true positives\", or query features (bases, exons, introns, transcripts, etc.) that agree with the corresponding reference annotation features; FN means \"false negatives\", i.e. features that are found in the reference annotation but are not present in the input data; FP (false positives) are features present in the input data but not confirmed by any reference annotation data. Notice that FP+ TP amounts to the whole input set of query features in the input file. If multiple query GTF/GFF files are given as input, these metrics are computed separately for each sample. Sensitivity and Precision values are estimated at various levels, which are largely an increasingly stringent way of evaluating the accuracy/correctness of a set of predicted transcripts (transfrags), when compared to the reference annotation. The six different levels that GffCompare uses are described below: * **Base level**: At the base level, TP represents the number of exon bases that are reported at the same coordinate on both the query transcripts and any reference transcript, FN is the number of bases in reference data exons that are not covered at all by any of the query exons, and FP is the number of bases which are covered by predicted transcripts' exons but not covered by any reference transcript exons. * **Exon level**: We define the TP, FN, and FP values at the exon level similar to the base level, but now the unit of comparison is the exon interval on the genome, i.e. if an exon of the predicted transcript overlaps and matches the boundaries of a reference transcript exon, then it is counted as a TP. * **Intron Level**: Intron intervals are the units that are matched at the intron level, therefore each intron of the predicted transcript is checked against any introns of the reference transcripts in the same region and if there is one with the same exact start-end coordinates, it is counted as a TP. * **Intron chain level**: At this level we count as a TP any query transcript for which all of its introns can be found, with the same exact intron coordinates as in a reference transcript that has the same number of introns. Matching all the introns at this level implies that all the internal exons also match, but this might not be true for the external boundaries of the terminal exons. * **Transcript level**: Note that intron chain level values are calculated only by looking at multi-exon transcripts, so it completely ignores the single-exon transcripts, which can be quite numerous in a RNA-Seq experiment (possibly due to a lot of transcriptional and alignment noise). The transcript level considers single-exons as well. A TP at this level is defined as a full exon chain match between the predicted transcript and a reference transcript, where all internal exons match and the outer boundaries of the terminal query exons can only slightly differ from the reference exons (with at most 100 bases by default). Also GffCompare considers single-exon transcripts as matching an overlapping single-exon reference transcript if there is a significant overlap between the two (more than 80% of the longer transcript by default). * **Locus level**: At this level GffCompare considers that an observed locus, defined as a cluster of exon-overlapping transcripts, matches a similarly built reference locus if at least one predicted transcript has a transcript level match with a reference transcript in the corresponding reference locus. ---- .. class:: infomark **Tracking transcripts** GffCompare can also be used to track all transcripts that are structurally equivalent among the different input files. GffCompare considers transcripts matching (or structurally equivalent) if all their introns are identical. Note that matching transcripts are allowed to differ on the length of the first and last exons, since these lengths can usually vary across samples for the same biological transcript. A list of all matching transcripts is reported in a file called *tracking file* in which each row represents a transcript. The first column in this file represents a unique id assigned to that transcripts. The second file represents the super-locus that contains that transcript. If a reference annotation is provided, the 3 rd and 4 th columns contain the reference annotation transcript that was found to be closest to the transcript and the classification code that specifies the relationship between these two transcripts, respectively. The rest of the columns show the corresponding transcript from each input file in order. **RefMap and TMAP files** In order to quickly see which reference transcripts match which transcripts from a sample file, two other files, called *RefMap* and *TMAP* are also created for each query. The RefMap file is a tab-delimited file that has a row for each reference transcript that either fully or partially matches a transcript from the given input file. Conversely, the TMAP file has a row for each input transcript, while the columns in this file describe the most closely matching reference transcript for that transcript.",
    "input_formats": [
      "gtf",
      "gff3",
      "fasta"
    ],
    "output_formats": [
      "gtf",
      "tabular",
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/ruvseq/ruvseq/1.26.0+galaxy1",
    "name": "Remove Unwanted Variation",
    "description": "from RNA-seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.26.0+galaxy1",
    "help": ".. class:: infomark **What it does** RUVSeq normalizes RNA-seq data using factor analysis of control genes or samples. RUVSeq has been designed for detecting unwanted variation using replicate sample information. The current RUVSeq Galaxy tool only implements estimating unwanted variation for primary factors. RUVSeq implements 3 different methods for the estimation of unwanted variation: RUVg estimates the factors of unwanted variation using control genes RUVs estimates the factors of unwanted variation using replicate samples RUVr estimating the factors of unwanted variation using residuals. This tool runs all RUV methods and outputs diagnostic plots and tables with covariates that may be used for differential expression analsys. ----- **Inputs** **Count Files** RUVSeq_ takes count tables generated from **featureCounts**, **HTSeq-count** or **StringTie** as input. Count tables must be generated for each sample individually. One header row is assumed, but files with no header (e.g from HTSeq) can be input with the *Files have header?* option set to No. RUVSeq_ can also take transcript-level counts from quantification tools such as, **kallisto**, **Salmon** and **Sailfish**, and this Galaxy wrapper incorporates the Bioconductor tximport_ package to process the transcript counts for DESeq2. **Salmon or Sailfish Files** Salmon or Sailfish ``quant.sf`` files can be imported by setting type to *Salmon* or *Sailfish* respectively above. Note: for previous version of Salmon or Sailfish, in which the quant.sf files start with comment lines you will need to remove the comment lines before inputting here. An example of the format is shown below. Example: Name Length EffectiveLength TPM NumReads ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 2.47415 109.165 NR_015380 2129 2139.53 1.77331 85.5821 NM_001198818 9360 7796.58 2.38616e-07 4.19648e-05 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 0.0481114 8.37255 **kallisto Files** kallisto ``abundance.tsv`` files can be imported by setting type to *kallisto* above. An example of the format is shown below. Example: target_id length eff_length est_counts tpm ------------ ---------- --------------- ----------- ----------- NR_001526 164 20.4518 0 0 NR_001526_1 164 20.4518 0 0 NR_001526_2 164 20.4518 0 0 NM_130786 1764 1956.04 109.165 2.47415 NR_015380 2129 2139.53 85.5821 1.77331 NM_001198818 9360 7796.58 4.19648e-05 2.38616e-07 NM_001198819 9527 7964.62 0 0 NM_001198820 9410 7855.78 0 0 NM_014576 9267 7714.88 8.37255 0.0481114 ----- **Output** RUVSeq_ generates a tabular file for each method and each k of variation as well as a summary PDF. RUVSeq can also generate RUVSeq normalized count tables. However, *these counts should be used only for exploration. It is important that subsequent DE analysis be done on the original counts, as removing the unwanted factors from the counts can also remove part of a factor of interest*. .. _RUVSeq: http://master.bioconductor.org/packages/release/bioc/html/RUVSeq.html .. _tximport: https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html",
    "input_formats": [
      "tabular",
      "gtf",
      "gff3"
    ],
    "output_formats": [
      "pdf"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_run_de_analysis/trinity_run_de_analysis/2.15.1+galaxy0",
    "name": "Differential expression analysis",
    "description": "using a Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool performs differential expression analyses on a transcriptome assembled with Trinity. **Inputs** This tool uses the matrix produced by 'Build expression matrix for a de novo assembly of RNA-Seq data by Trinity' tool. You must describe your samples and replicates with a tabular file looking like this: ConditionA CondA_replicate1 ----------- ---------------- ConditionA CondA_replicate2 ----------- ---------------- ConditionB CondB_replicate1 ----------- ---------------- ConditionB CondB_replicate2 ----------- ---------------- ConditionC CondC_replicate1 ----------- ---------------- ConditionC CondC_replicate2 ----------- ---------------- ConditionC CondC_replicate3 This file can be generated with the 'Describe samples and replicates' tool. It will probably be the same file as used in the tool 'RNASeq samples quality check for transcript quantification'. The names in column 2 must match the names given in the tool 'Build expression matrix for a de novo assembly of RNA-Seq data by Trinity'. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "tabular"
    ],
    "output_formats": []
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_super_transcripts/trinity_super_transcripts/2.15.1+galaxy0",
    "name": "Generate SuperTranscripts",
    "description": "from a Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "SuperTranscripts provide a gene-like view of the transcriptional complexity of a gene. SuperTranscripts were originally defined by Nadia Davidson, Anthony Hawkins, and Alicia Oshlack as described in their publication \"SuperTranscripts: a data driven reference for analysis and visualisation of transcriptomes\" Genome Biology, 2017. SuperTranscripts are useful in the context of genome-free de novo transcriptome assembly in that they provide a genome-like reference for studying aspects of the gene including differential transcript usage (aka. differential exon usage) and as a substrate for mapping reads and identifying allelic polymorphisms. A SuperTranscript is constructed by collapsing unique and common sequence regions among splicing isoforms into a single linear sequence. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "fasta",
      "gtf",
      "clustal"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity/trinity/2.15.1+galaxy0",
    "name": "Trinity",
    "description": "de novo assembly of RNA-Seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "fasta",
      "fastqsanger",
      "fastqsanger.gz",
      "bam"
    ],
    "output_formats": [
      "fasta",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_gene_to_trans_map/trinity_gene_to_trans_map/2.15.1+galaxy0",
    "name": "Generate gene to transcript map",
    "description": "for Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool produces a file containing correspondance between gene ids and transcript ids based on the name of transcripts assembled by Trinity. The output file is intended to be used by the \"Align reads and estimate abundance\" tool. The same file is automatically generated when running Trinity, this tool is only intended to be used when you don't (or no longer) have access to the one produced by Trinity. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_abundance_estimates_to_matrix/trinity_abundance_estimates_to_matrix/2.15.1+galaxy0",
    "name": "Build expression matrix",
    "description": "for a de novo assembly of RNA-Seq data by Trinity",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool will combine abundance estimations (produced by 'Align reads and estimate abundance on a de novo assembly of RNA-Seq data' tool) from multiple samples into a single tabular file. This matrix can then be used by 'RNASeq samples quality check for transcript quantification' and 'Differential Expression Analysis using a Trinity assembly' tools. **Inputs** It takes as input multiple results from 'Align reads and estimate abundance on a de novo assembly of RNA-Seq data' tool/ Each sample must have a name, that should be used in subsequent tools. **Output** This tool will produce a single matrix file. More details on this page: .. _Trinity manual: https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Transcript-Quantification .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_contig_exn50_statistic/trinity_contig_exn50_statistic/2.15.1+galaxy0",
    "name": "Compute contig Ex90N50 statistic and Ex90 transcript count",
    "description": "from a Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool computes the N50 statistic limited to the top most highly expressed transcripts that represent x% of the total normalized expression data. This requires that you have first performed transcript abundance estimation with 'Align reads and estimate abundance for a de novo assembly of RNA-Seq data by Trinity' tool and that you have built the expression matrix with 'Build expression matrix for a de novo assembly of RNA-Seq data by Trinity' tool. **Inputs** It takes as input a transcriptome assembled with Trinity and the matrix of normalized expression values produced by 'Build expression matrix for a de novo assembly of RNA-Seq data by Trinity' tool. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "tabular",
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_align_and_estimate_abundance/trinity_align_and_estimate_abundance/2.15.1+galaxy0",
    "name": "Align reads and estimate abundance",
    "description": "on a de novo assembly of RNA-Seq data",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool estimates the abundance of isoforms and genes of a transcriptome assembled with Trinity, using FastQ of a specific sample. **Inputs** It takes as input a transcriptome assembled with Trinity and the reads from a RNASeq sample. You have to choose between several counting methods. If you dont align on a Trinity assembly, you need to provide a file of the following (tabular) format to map gene ids to transcript ids: gene1 transcript1 ----------- ---------------- gene2 transcript2 **Output** This tool will produce 2 tabular files, with counts for isoforms and genes respectively. More details on this page: .. _Trinity manual: https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Transcript-Quantification .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "fasta",
      "fastqsanger",
      "fastqsanger.gz",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/trinity_filter_low_expr_transcripts/trinity_filter_low_expr_transcripts/2.15.1+galaxy0",
    "name": "Filter low expression transcripts",
    "description": "from a Trinity assembly",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.15.1+galaxy0",
    "help": "Trinity_ assembles transcript sequences from Illumina RNA-Seq data. This tool filters a Trinity assembly using an expression matrix built with \"Build expression matrix for a de novo assembly of RNA-Seq data by Trinity\" tool. It discards transcripts/isoforms having a low expression level. .. _Trinity: https://github.com/trinityrnaseq/trinityrnaseq/wiki",
    "input_formats": [
      "fasta",
      "tabular"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/mirdeep2_mapper/rbc_mirdeep2_mapper/2.0.0",
    "name": "MiRDeep2 Mapper",
    "description": "process and map reads to a reference genome",
    "categories": [
      "RNA-seq"
    ],
    "version": "2.0.0",
    "help": "**What it does** The MiRDeep2 Mapper module is designed as a tool to process deep sequencing reads and/or map them to the reference genome. The module works in sequence space, and can process or map data that is in sequence FASTA format. A number of the functions of the mapper module are implemented specifically with Solexa/Illumina data in mind. **Input** Default input is a file in FASTA format, seq.txt or qseq.txt format. More input can be given depending on the options used. **Output** The output depends on the options used. Either a FASTA file with processed reads or an arf file with with mapped reads, or both, are output. Arf format: Is a proprietary file format generated and processed by miRDeep2. It contains information of reads mapped to a reference genome. Each line in such a file contains 13 columns: 1. read identifier 2. length of read sequence 3. start position in read sequence that is mapped 4. end position in read sequence that is mapped 5. read sequence 6. identifier of the genome-part to which a read is mapped to. This is either a scaffold id or a chromosome name 7. length of the genome sequence a read is mapped to 8. start position in the genome where a read is mapped to 9. end position in the genome where a read is mapped to 10. genome sequence to which a read is mapped 11. genome strand information. Plus means the read is aligned to the sense-strand of the genome. Minus means it is aligned to the antisense-strand of the genome. 12. Number of mismatches in the read mapping 13. Edit string that indicates matches by lowercase 'm' and mismatches by uppercase 'M'",
    "input_formats": [
      "fastq",
      "fasta"
    ],
    "output_formats": [
      "fasta",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/targetfinder/targetfinder/1.7.0+galaxy1",
    "name": "TargetFinder",
    "description": "plant small RNA target prediction tool",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.7.0+galaxy1",
    "help": ".. class:: infomark **What it does** TargetFinder will computationally predict small RNA binding sites on target transcripts from a sequence database. This is done by aligning the input small RNA sequence against all transcripts, followed by site scoring using a position-weighted scoring matrix. ---- .. class:: infomark **Input** This tool requires two fasta files: :: -f Input small RNA sequences file (FASTA-format). -d Target sequence database file (FASTA-format) ---- .. class:: infomark **Original TargetFinder Output** Each predicted target site is printed out separately. The output consists of two parts. The first is a description line and the second is a base-pairing diagram of the target and small RNA (query) sequence. The description line contains the query name, the description line from the target sequence database, and the target prediction score. :: query=miR399a, target=AT2G33770.1 | Symbol: None | ubiquitin-conjugating enzyme family protein, low similarity to u, score=1.5 The base-pairing diagram has the target site sequence on top in 5'-3' orientation and the query sequence on the bottom in 3'-5' orientation. Between the target site sequece and the query sequence are base pair symbols. A ':' (colon) symbol represents an ordinary Watson-Crick base pair, a '.' (period) represents a G:U base pair, and a ' ' (space) represents a mismatch. :: target 5' UAGGGCAAAUCUUCUUUGGCA 3' .:::::::::::.:::::::: query 3' GUCCCGUUUAGAGGAAACCGU 5' If a small RNA is predicted to target a sequence more than once, each target site will be output as separate output. ---- .. class:: infomark **Additional output formats** In addition to the output described above ('classic' output), three new output format options were added to TargetFinder. Generic Feature Format (GFF3): :: AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN targetfinder rna_target 607 627 1.5 + . smallRNA=miR399a;target_seq=UAGGGCAAAUCUUCUUUGGCA;base_pairs=.:::::::::::.::::::::;miR_seq=GUCCCGUUUAGAGGAAACCGU AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN targetfinder rna_target 740 760 1.5 + . smallRNA=miR399a;target_seq=UAGGGCAUAUCUCCUUUGGCA;base_pairs=.:::::: :::::::::::::;miR_seq=GUCCCGUUUAGAGGAAACCGU AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN targetfinder rna_target 829 849 1.5 + . smallRNA=miR399a;target_seq=UUGGGCAAAUCUCCUUUGGCA;base_pairs=. :::::::::::::::::::;miR_seq=GUCCCGUUUAGAGGAAACCGU Tab-deliminated Format: :: miR399a AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN 607 627 + 1.5 UAGGGCAAAUCUUCUUUGGCA .:::::::::::.:::::::: GUCCCGUUUAGAGGAAACCGU miR399a AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN 740 760 + 1.5 UAGGGCAUAUCUCCUUUGGCA .:::::: ::::::::::::: GUCCCGUUUAGAGGAAACCGU miR399a AT2G33770.1 | Symbols: UBC24 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN 829 849 + 1.5 UUGGGCAAAUCUCCUUUGGCA . ::::::::::::::::::: GUCCCGUUUAGAGGAAACCGU JavaScript Object Notation Format (JSON): :: { 'miR399a': { 'hits' : [ { 'Target accession': 'AT2G33770.1 | Symbols: UBC24, ATUBC24, PHO2 | phosphate 2 | chr2:14277558-14283040 REVERSE LEN', 'Score': '1.5', 'Coordinates': '607-627', 'Strand': '+', 'Target sequence': 'UAGGGCAAAUCUUCUUUGGCA', 'Base pairing': '.:::::::::::.::::::::', 'amiRNA sequence': 'GUCCCGUUUAGAGGAAACCGU' } ] } } ---- .. class:: infomark **Method** TargetFinder searches for potential miRNA target sites in a FASTA-formated sequence database using three main steps. 1. The small RNA query sequence is aligned to every sequence in the FASTA-formated sequence database using `Smith-Waterman (SW) alignments `_ implemented in the FASTA package (ssearch35_t). 2. The SW alignments are converted into RNA duplexes. 3. Each duplex is scored using a position-dependent scoring matrix. SW alignments are used to identify the best complementary regions between the small RNA query sequence and every sequence in the FASTA-formated sequence database.",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "txt"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/chira_collapse/chira_collapse/1.4.3+galaxy0",
    "name": "ChiRA collapse",
    "description": "deduplicate fastq reads",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.4.3+galaxy0",
    "help": ".. class:: infomark **What it does** This tool deduplicates the reads from the FASTQ file and writes into a fasta each read once with it's read count. **Inputs** * Quality and adapter trimmed FASTQ file **Outputs** * FASTA file with unique sequences. The headers of the sequence are in the following format: >sequence_id|UMI|read_count",
    "input_formats": [
      "fastq"
    ],
    "output_formats": [
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/chira_extract/chira_extract/1.4.3+galaxy0",
    "name": "ChiRA extract",
    "description": "extrat the chimeras",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.4.3+galaxy0",
    "help": ".. class:: infomark **What it does** This tool extracts the best chimeric alignments for each read. User can optionally hybridize the loci where the chimeric arms are mapping to. **Inputs** * Tabular file containing CRLs information * Annotation GTF file * Reference fasta files. Provide both in case of split reference. * If your alignments are merged at genomic level in previous step (chira merge), then provide a reference genomic fasta fille. **Output** * Tabular file containing chimeras information",
    "input_formats": [
      "tabular",
      "gtf",
      "gff",
      "fasta"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/chira_map/chira_map/1.4.3+galaxy0",
    "name": "ChiRA map",
    "description": "map reads to trascriptome",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.4.3+galaxy0",
    "help": ".. class:: infomark **What it does** This tool handles the mapping of the reads to reference transcriptome. User can choose between the bwa-mem and CLAN alignment tools. **Inputs** * A fasta file containing reads * A reference fasta file containing transcript sequences * An optional second reference fasta file, incase if you split your reference into two **Output** * BED file containing the alignments * Optional unmapped FASTA file",
    "input_formats": [
      "fasta"
    ],
    "output_formats": [
      "bed",
      "fasta"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/chira_merge/chira_merge/1.4.3+galaxy0",
    "name": "ChiRA merge",
    "description": "merge aligned positions",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.4.3+galaxy0",
    "help": ".. class:: infomark **What it does** This tool merges the overlapping aligned positions to define the read concentrated loci. If an annotation GTF file produced, the transcriptomic alignment positions are first converted to their corresponding genomic positions. **Inputs** * Alignments in BED format * An annotation GTF file contaning reference genomic positions. **Output** * BED file containing the alignments with reads categorized into segments depending on which part of the read is aligned. * Tabular file containing merged alignments. 4th column contains all the alignments merged into that location.",
    "input_formats": [
      "bed",
      "gtf",
      "gff",
      "fasta"
    ],
    "output_formats": [
      "bed",
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/chira_quantify/chira_quantify/1.4.3+galaxy0",
    "name": "ChiRA qauntify",
    "description": "quantify aligned loci to score the alignments",
    "categories": [
      "RNA-seq"
    ],
    "version": "1.4.3+galaxy0",
    "help": ".. class:: infomark **What it does** This tool first creates CRLS from merged BED file and quantifies them based on the mapped reads. **Inputs** * A BED file containing alignment segments * A BED file containing merged alignments **Output** * Tabular file containing the reads and their CRLs with TPM values.",
    "input_formats": [
      "bed",
      "tabular"
    ],
    "output_formats": [
      "tabular"
    ]
  },
  {
    "tool_id": "toolshed.g2.bx.psu.edu/repos/rnateam/blockbuster/blockbuster/0.1.2",
    "name": "blockbuster",
    "description": "detects blocks of overlapping reads using a gaussian-distribution approach",
    "categories": [
      "RNA-seq"
    ],
    "version": "0.1.2",
    "help": "**What it does** Blockbuster_ detects blocks of overlapping reads using a gaussian-distribution approach. Once short read sequences are mapped to a reference genome, one will face the problem of dividing consecutive reads into blocks to detect specific expression patterns. Due to biological variability and sequencing inaccuracies, the read arrangement does not always show exact block boundaries. The blockbuster tool automatically assigns reads to blocks and gives a unique chance to actually see the different origins where the short reads come from. .. _Blockbuster: http://hoffmann.bioinf.uni-leipzig.de/LIFE/blockbuster.html **Input** Input file can be a BED file or an Segemehl output file.",
    "input_formats": [
      "bed"
    ],
    "output_formats": [
      "bed"
    ]
  }
]